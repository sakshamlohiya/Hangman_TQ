{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d15f318a-198e-468d-8859-c67e8403ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dimension: 40\n",
      "Example state: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]... (truncated)\n",
      "State contains 5 values for the word + 26 for alphabet + 1 for wrong_guesses_ratio\n",
      "Initializing PPO with state_dim=40, action_dim=26\n",
      "State tensor shape: torch.Size([1, 40])\n",
      "Forward pass successful. Action probs shape: torch.Size([1, 26])\n",
      "Test action selection successful: action=5 (f)\n",
      "Test environment step successful: reward=-0.2, done=False\n",
      "Environment info: {'message': 'Valid move'}\n",
      "\n",
      "Starting training...\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "Episode 10/500, Reward: -0.70\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "Episode 20/500, Reward: -0.70\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([31, 40])\n",
      "Actions shape: torch.Size([31])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "Episode 30/500, Reward: -0.20\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 40/500, Reward: 0.30\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([30, 40])\n",
      "Actions shape: torch.Size([30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([24])) that is different to the input size (torch.Size([24, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n",
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([25])) that is different to the input size (torch.Size([25, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n",
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([23])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n",
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n",
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n",
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n",
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([26])) that is different to the input size (torch.Size([26, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n",
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([30])) that is different to the input size (torch.Size([30, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "Episode 50/500, Reward: -0.20\n",
      "Episode 50/500, Win Rate: 0.01, Avg Reward: -0.70\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "Episode 60/500, Reward: -1.20\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "Episode 70/500, Reward: -1.20\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "Episode 80/500, Reward: -0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([22])) that is different to the input size (torch.Size([22, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n",
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([28])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "Episode 90/500, Reward: 0.30\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "Episode 100/500, Reward: 0.30\n",
      "Episode 100/500, Win Rate: 0.00, Avg Reward: -0.71\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "Episode 110/500, Reward: -1.20\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "Episode 120/500, Reward: -0.70\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "Episode 130/500, Reward: -1.20\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 140/500, Reward: -1.20\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "Episode 150/500, Reward: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([29])) that is different to the input size (torch.Size([29, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 150/500, Win Rate: 0.02, Avg Reward: -0.57\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "Episode 160/500, Reward: -0.70\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 170/500, Reward: -0.70\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "Episode 180/500, Reward: -0.70\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([30, 40])\n",
      "Actions shape: torch.Size([30])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "Episode 190/500, Reward: 0.30\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "Episode 200/500, Reward: -1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200/500, Win Rate: 0.02, Avg Reward: -0.36\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "Episode 210/500, Reward: -0.70\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 220/500, Reward: 0.80\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "Episode 230/500, Reward: -1.20\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "Episode 240/500, Reward: 2.30\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 250/500, Reward: 0.80\n",
      "Episode 250/500, Win Rate: 0.00, Avg Reward: -0.30\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "Episode 260/500, Reward: 1.80\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "Episode 270/500, Reward: -1.70\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "Episode 280/500, Reward: -0.20\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "Episode 290/500, Reward: -0.70\n",
      "States shape: torch.Size([31, 40])\n",
      "Actions shape: torch.Size([31])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "Episode 300/500, Reward: 2.80\n",
      "Episode 300/500, Win Rate: 0.03, Avg Reward: -0.20\n",
      "States shape: torch.Size([32, 40])\n",
      "Actions shape: torch.Size([32])\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 310/500, Reward: -1.20\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 320/500, Reward: -1.70\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "Episode 330/500, Reward: -1.20\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "Episode 340/500, Reward: -1.20\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([30, 40])\n",
      "Actions shape: torch.Size([30])\n",
      "Episode 350/500, Reward: -1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zc/nd9_xst93xl4q86nmrbwyx_r0000gn/T/ipykernel_66987/2693252379.py:392: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(state_values, returns.detach())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 350/500, Win Rate: 0.01, Avg Reward: 0.03\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([30, 40])\n",
      "Actions shape: torch.Size([30])\n",
      "Episode 360/500, Reward: 0.80\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "Episode 370/500, Reward: 0.80\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 380/500, Reward: 0.30\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "Episode 390/500, Reward: 0.30\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "Episode 400/500, Reward: -0.20\n",
      "Episode 400/500, Win Rate: 0.04, Avg Reward: 0.24\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "Episode 410/500, Reward: 1.80\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([26, 40])\n",
      "Actions shape: torch.Size([26])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "Episode 420/500, Reward: -1.20\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "Episode 430/500, Reward: 1.80\n",
      "States shape: torch.Size([30, 40])\n",
      "Actions shape: torch.Size([30])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "Episode 440/500, Reward: -1.20\n",
      "States shape: torch.Size([30, 40])\n",
      "Actions shape: torch.Size([30])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "Episode 450/500, Reward: 0.80\n",
      "Episode 450/500, Win Rate: 0.05, Avg Reward: 0.33\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([28, 40])\n",
      "Actions shape: torch.Size([28])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "Episode 460/500, Reward: 1.30\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "Episode 470/500, Reward: 1.30\n",
      "States shape: torch.Size([21, 40])\n",
      "Actions shape: torch.Size([21])\n",
      "States shape: torch.Size([23, 40])\n",
      "Actions shape: torch.Size([23])\n",
      "States shape: torch.Size([31, 40])\n",
      "Actions shape: torch.Size([31])\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "Episode 480/500, Reward: 0.30\n",
      "States shape: torch.Size([22, 40])\n",
      "Actions shape: torch.Size([22])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([25, 40])\n",
      "Actions shape: torch.Size([25])\n",
      "Episode 490/500, Reward: -1.20\n",
      "States shape: torch.Size([24, 40])\n",
      "Actions shape: torch.Size([24])\n",
      "States shape: torch.Size([27, 40])\n",
      "Actions shape: torch.Size([27])\n",
      "States shape: torch.Size([20, 40])\n",
      "Actions shape: torch.Size([20])\n",
      "States shape: torch.Size([29, 40])\n",
      "Actions shape: torch.Size([29])\n",
      "Episode 500/500, Reward: 2.30\n",
      "Episode 500/500, Win Rate: 0.01, Avg Reward: 0.42\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAHqCAYAAADrpwd3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdB3wb5fkH8MfbTjwynenY2ZuExElIQhJG2BTov8yWFWjYo01LCy2UWVKgUChQApS9yyiUQoEkZAIZzg7Zw07iDDtxvLet/+d9pZPvTnfSnXynW7/v5+NYluXTe9JJOT333O+N8/l8PgIAAAAAAAAAAAAAgBDxoVcBAAAAAAAAAAAAAACDIjoAAAAAAAAAAAAAgAoU0QEAAAAAAAAAAAAAVKCIDgAAAAAAAAAAAACgAkV0AAAAAAAAAAAAAAAVKKIDAAAAAAAAAAAAAKhAER0AAAAAAAAAAAAAQAWK6AAAAAAAAAAAAAAAKlBEBwAAAAAAAAAAAABQgSI6AEAMPPDAAxQXFxfT+ywsLOT3+frrr8f0fp3u2muvpby8PKuHAQAAAAAutnjxYr6vzr4DAID9oYgOACDDis5sh1bta8WKFeRV8sciMzOTZsyYQV988YXVQwMAAAAAiIl//etffF/43//+d8jvxowZw3+3aNGikN/169ePpkyZYtq4WCOIeF+9Y8eONHHiRHrzzTejXuaXX37JG4IAALwu0eoBAADY1UMPPUT9+/cPuX7QoEG6l3XvvffS3XffTW5wxhln0NVXX00+n4+KiorohRdeoJ/85Cf0v//9j8466yyrhwcAAAAAYKqTTz6Zf1++fDn99Kc/DV5fWVlJmzdvpsTERPruu+/o1FNPDf5u//79/Ovyyy/nP0+fPp3q6uooOTnZ0LGNHTuWfvOb3/DLhw4don/+8590zTXXUENDA82ePTuqIvrzzz+PQjoAeB6K6AAAKs455xzKz883ZFlsR5p9ucGQIUPoyiuvDP78s5/9jEaMGEHPPPOMI4ro9fX1/MNKfDxOxgIAAAAA/Xr37s2bbVgRXeyHH37gjSaXXHJJyO+En4UCPNsXTU1NNXxsffr0keyrs6jCAQMG0N/+9reoiugAAOCHCgIAQDszx//617/yndLc3FxKS0vj8SasAyVSJvr8+fP5TnSnTp0oPT2dhg4dSn/4wx8ktykpKaHrr7+eevTowXey2emhb7zxRshYysvL+Q5yVlYWXx7rNmHXKdm2bRtdfPHF1KVLF75MdqDgP//5T9SPw/Dhw6lbt260e/duyfWs2+X+++/nnfspKSmUk5NDv/vd7/j1gv/7v/+jcePGSf6OdbWzx0o8ppUrV/LrWLc7U1ZWRr/97W9p9OjR/LFjsTLsoMeGDRsUsybff/99fjYA+1DRoUMH3iXEfPrppzRq1Cj+OLDvSqfkMuzvx48fTxkZGfy+2P2ygwYAAAAA4E1sP37dunW8m1zAus9HjhzJ90tZBGRra6vkd2y/dOrUqaqZ6KeccgrfJ92yZQvvYmf7rWz/9fHHH496nN27d6dhw4aF7KsvW7aMF/tZxIywr/7rX/9asj7s8wXrQmfEMTECtn5PP/00X2e2P80+s9x44410/PjxqMcLAGBX7miLBAAwQUVFBR09elRyHdtp7Nq1q+Q6ljFYVVVFt956K+9yZsXV0047jTZt2sR3JJX8+OOPdP7559MJJ5zAY2PYjuuuXbv4zrWA7cCyHWl2/W233ca7XT788EO+M8sK5HfeeSe/Het2ufDCC3l3y0033cSL2qwYzArpSvfLdtzZzjiLl2E5iSzT8aKLLqKPP/5YcjqqnseJ7SgPHDhQskN9wQUX8DHdcMMNfEzs8WAHG3bs2MGL18y0adPos88+40VtVpxm68IeA9aZw3bs2TIYdpldJ3zo2LNnD18G2/Fnj8uRI0foxRdf5Acw2IcO1h0k9vDDD/Puc1Z4Z0V8dvmbb74JdtHPnTuXjh07RrNmzaK+ffuGHOy44oor6PTTT6fHHnuMX7d161Y+TuE5AAAAAADvFdHfeust3uzB9tkZtn/IMs/ZF9tHZo01bH9f+B0rZss/S8ix/eqzzz6bN5tceuml9NFHH9Hvf/973sTBivN6NTc304EDB6hz586S69nnitraWrr55pv5mFatWkXPPvssvy37HcMK4gcPHuT7w2xd5djv2XxSbB/6jjvuoL1799Jzzz3HDy6w9U1KStI9XgAA2/IBAIDEa6+95mNvj0pfKSkpwdvt3buXX5eWluY7cOBA8PqVK1fy63/9618Hr7v//vv5dYK//e1v/OfS0lLVcTz99NP8Nm+//XbwusbGRt/kyZN96enpvsrKSn7dp59+ym/3+OOPB2/X3NzsmzZtGr+erY/g9NNP940ePdpXX18fvK61tdU3ZcoU3+DBgyM+Nmx5119/PR93SUmJr6CgwHf22Wfz65944ong7d566y1ffHy8b9myZZK/nzdvHr/td999x39evXo1//nLL7/kP2/cuJH/fMkll/gmTZoU/LsLLrjAd+KJJwZ/ZuNvaWmRLJs9H+z5eeihh4LXLVq0iC9vwIABvtraWsntx44d6+vVq5evvLw8eN0333zDb5+bmxu87s477/RlZmbyxxQAAAAAgPnxxx/5fuPDDz/Mf25qavJ17NjR98Ybb/Cfe/To4Xv++ef5ZbbfnpCQ4Js9e3bIfir7LpgxYwa/7s033wxe19DQ4OvZs6fvZz/7WcQxsX3YM888k++rs69Nmzb5rrrqKr7MW2+9VXJb+b4xM3fuXF9cXJyvqKgoeB37O6XSEdvPZ9e/8847kuu/+uorxesBAJwOcS4AACrYqYus60L8JcSJiLEubtbZLZg4cSJNmjSJT8KjhkWuMKwLW3yapxj7+549e/IuaAHr5mBdHtXV1bRkyZLg7VjeOusiESQkJNDtt98uWR6LQPn22295RwvrnGdd9uyLdWCzLPOdO3dScXFxxMfllVde4aeFZmdn8yiYhQsX8piWOXPmBG/DuldY9znrthHuh32xDn1m0aJF/PuJJ57I41iWLl0a7DhnneBs4tK1a9fy7hhWu2cd7axrXcA694VM85aWFr4OQiQO+zs51pXPonYEbJKl9evX8+tZBI540lTWmS5/rmpqavjzDwAAAADAsH1d1sEtZJ2zWEG2z8i60Bn2XTjLlGWls31WIQ89HLZPK840Z2dQss8X7ExMLdjZlmxfnX2x7nXWQc46xZ944gnJ7cT7xmzcbF+djZnte7NO8kjY/j7bj2b7z+L9fRaByNZB2N8HAHALxLkAAKhgO6taJhYdPHiw4uSbLCZFzWWXXUb//Oc/6Ze//CWPVWFRIeyUTZZVLhSHi4qK+LLlE2CyHXbh98L3Xr168Z1VMVZQFmOxMGyn+L777uNfSlgGu/iAgBIWHcPiZRobG2n16tX06KOP8mK3eJysIM8iT9jOu9r9CMX+yZMn8+I5w76zYjn7gME+aLAsSRaJww4AiIvo7MADi835xz/+wU8bZbcVKJ0iyyJfxITHTum5kxfib7nlFv5cstNn2WNz5pln8gMR7DRbAAAAAPAmFvPIis6sGYTtm7KCOWsyYfMBMex3LNqEEYrpWororKFEPpcSi2LZuHGjpnGxZp5HHnmE7x+zOBl2mUXEsGK82L59++hPf/oTn4dInmHOomgiYfv77HZsncPt7wMAuAWK6AAAFmCdH2yHm3VofPHFF/TVV1/RBx98wDu1WfcIKy4bTeh4Z7ngrPNcibDTH2nHfubMmfzyueeeyycVZUV1NvkROxAg3BfrfHnqqacUl8EmLhKwDxN//vOfeZ48K6L/8Y9/5N3fbFIl9rOQKy8uorPCPTsQcN111/G8czZJKivi/+pXv1Ls7Bd32ujFPhiwrvWvv/6an4nAvl577TXeLa80ySsAAAAAeAPbj/3888/53D9CHrqAXb7rrrv4mZ6sW53N2TNgwICIy1T7HOBPVoyM7ZsL++psn5+dGcrmYmINKMKZo6zAzjrIWaMKy1tnt2FzJbGxsvmX1M6UFWO3YfvJ77zzjuLv1ZppAACcCkV0AIB2Yl0YcmzyzLy8vLB/x4q+rAOdfbFiMysMswIyK6yzHd/c3FzeccJ2UMVd3tu2bePf2e+F7yxShUW8iLvRt2/fLrk/YaedRcIIO9ZGYBMKsQlD7733Xj4xKeucYZOMslNa2brJO2nkWHGcdbW/9957fMddKJZPnz49WERnnf3iSVrZBEusaM+iZcTYhKvsg0MkwmOn9NzJHzeGde785Cc/4V/s+WDd6WwiU1bI13LgAQAAAADcR+gsZ0VyVkRnDR0CFmvCIggXL17MJx9lzSdWOO+882jGjBn8swbbb2fFclb0Z59XWEMIawwRKMUXqu3Ls/39BQsW0NSpU9vVsAIA4BTIRAcAaKdPP/1UkiXOZrZnO8os/kMN6/qQGzt2LP/e0NDAv7Md7cOHD/MOdUFzczM9++yzvFjOdoaF27HrX3jhheDtWHcJu50Y6xQ55ZRTePGXZYLLlZaWUjRYHvtvfvMbHt/CMt4ZFnfCHpOXX3455PZ1dXU8d1F8yikr7D/22GO8o3zkyJH8elZMZ3EuLPtd3IUudOjIu3FYLqOWTHeGxd+wx5t9cBCfrso+OGzZskVyW5a3LsYOaJxwwgmS5woAAAAAvIdFP6ampvJubLYfKu5EZwX0cePG8XmW2L6vligXs7Buc7ZPK+ybC93u4v1pdpl1q8uxorvQrCLG9vfZZw52Vqgc+2wivz0AgNOhEx0AQAWL7RC6vsXYzrH4VEzWicx2itnEnqyo+vTTT/NcbjbZppqHHnqIx7mwzhDWFc0yA1m+N4tKEXawb7jhBl7wZqdUrlmzhne2sw5s1uXC7iMjI4PfjnVHsw4Qlq1eWFjIJ8b85JNPFLMM2U48Wz6LWpk9ezZfjyNHjvDJjg4cOMC7x6PBxsgyFVkhnE20etVVV/Ec8Ztuuol31rPxsZ1s9niy61k0ipA336FDB96pwwrmbF2EbhfWic4+cLAveRGdnZLKHkM2SRJ7Plg3DfvwouUUWcHcuXP5488eDxYLww5ssAMPrIjPuvoFLLee/Y5F7bDnh+Wps9uxIryQTw8AAAAA3sPOVpwwYQI/e5IVzdk+rRjbT33yySf5ZSuL6Ky5h0UlsrNfb731Vh7fwjrJWcwjK/5nZmbSxx9/HJKNzgjrdMcdd/B4GFaAv/zyy3lDD+tsZ/vULPqQzRvEGmPYmZ6suYUV5Nl8TwAAruEDAACJ1157jbVkqH6x3zN79+7lPz/xxBO+J5980peTk+NLSUnxTZs2zbdhwwbJMu+//35+W8HChQt9F154oa93796+5ORk/v2KK67w7dixQ/J3R44c8c2aNcvXrVs3frvRo0cH71/s2LFjvquuusqXmZnpy8rK4pfXrVsnGa9g9+7dvquvvtrXs2dPX1JSkq9Pnz6+888/3/fRRx9FfGzY8m699VbF3z3wwAP894sWLeI/NzY2+h577DHfyJEj+ePSuXNn3/jx430PPvigr6KiQvK3d911F/9bdnuxQYMG8evZmMXq6+t9v/nNb3y9evXypaWl+aZOner74YcffDNmzOBfAjYW9vcffvih4pg//vhj3/Dhw/n4RowY4fvkk09811xzjS83Nzd4G/a4nHnmmb7s7Gz+HPTr18934403+g4dOhTx8QIAAAAAd7vnnnv4/uaUKVNCfsf2LdnvMjIyfM3NzZLfCfupwr4zw/Zj2b6znHz/VA27zXnnnaf4u9dff13y2WDLli2+mTNn+tLT0/lnjdmzZ/PPMPLPD2zct99+u6979+6+uLg4yWca5qWXXuL7+GyfnK0n+7zyu9/9znfw4MGI4wUAcJI49o/VhXwAACdiXd/9+/enJ554gndxAAAAAAAAAACA+yATHQAAAAAAAAAAAABABYroAAAAAAAAAAAAAAAqUEQHAAAAAAAAAAAAAFCBTHQAAAAAAAAAAAAAABXoRAcAAAAAAAAAAAAAUIEiOgAAAAAAAAAAAACAikTykNbWVjp48CBlZGRQXFyc1cMBAAAAAJdjyYlVVVXUu3dvio9H/0o42FcHAAAAALvur3uqiM52ynNycqweBgAAAAB4zP79+6lv375WD8PWsK8OAAAAAHbdX/dUEZ11tQgPSmZmptXDAQAAAACXq6ys5IVhYT8U1GFfHQAAAADsur/uqSK6cFoo2ynHjjkAAAAAxAriSSLDvjoAAAAA2HV/HcGMAAAAAAAAAAAAAAAqUEQHAAAAAAAAAAAAAFCBIjoAAAAAAAAAAAAAgAoU0QEAAAAAAAAAAAAAVKCIDgAAAAAAAAAAAACgAkV0AAAAAAAAAAAAAAAVKKIDAAAAAAAAAAAAAKhAER0AAAAAAAAAAAAAQAWK6AAAAAAAAAAAAAAAKlBEBwAAAAAAAAAAAABQgSI6AAAAAAAAAAAAAIAKFNEBAAAAADzo+eefp7y8PEpNTaVJkybRqlWrwt7+ww8/pGHDhvHbjx49mr788kvJ76+99lqKi4uTfJ199tkmrwUAAAAAgPlQRAcAAAAA8JgPPviA5syZQ/fffz+tXbuWxowZQ2eddRaVlJQo3v7777+nK664gq6//npat24dXXTRRfxr8+bNktuxovmhQ4eCX++9916M1ggAAAAAwDxxPp/PRx5RWVlJWVlZVFFRQZmZmVYPBwAAAABczq77n6zzfMKECfTcc8/xn1tbWyknJ4duv/12uvvuu0Nuf9lll1FNTQ3997//DV530kkn0dixY2nevHnBTvTy8nL69NNPXfVYAQAAAIB7ad0HRSc6AAAAQIzUNbbQmqLj1NrqmR4GsKHGxkZas2YNzZw5M3hdfHw8//mHH35Q/Bt2vfj2DOtcl99+8eLFlJ2dTUOHDqWbb76Zjh07ZtJaAAAAADhXU0srrdpbxr+DM6CIDgAAABAjj3+9jX72wvc0f+sRq4cCHnb06FFqaWmhHj16SK5nPx8+fFjxb9j1kW7PolzefPNNWrhwIT322GO0ZMkSOuecc/h9KWloaOCdP+IvAAAAALdrbG6l615fTZe++AO9/l2h1cMBjRK13hAAAAAA2udwRb3kO4CbXH755cHLbOLRE044gQYOHMi7008//fSQ28+dO5cefPDBGI8SAAAAwDotrT769b/W07KdR/nPS3eW0uzpA6weFjipE33p0qX0k5/8hHr37k1xcXEhWYosuv1Pf/oT9erVi9LS0vjppDt37rRsvAAAAAB6CTPReGhKGrChbt26UUJCAh05Ij0jgv3cs2dPxb9h1+u5PTNgwAB+X7t27VL8/T333MOzJ4Wv/fv3R7U+AAAAAE7APgPc99lm+mLjIYqL81+3tug4NSPSxRFsU0RnExWNGTOGnn/+ecXfP/744/T3v/+dT1y0cuVK6tixI89hrK9HJxcAAAA4g4/8xXOU0MFKycnJNH78eB67ImATi7KfJ0+erPg37Hrx7Zn58+er3p45cOAAz0RnTTBKUlJS+ORN4i8AAAAAt3rymx307sp9vID+98tPpIyURKppbKFth6usHho4qYjO8hIfeeQR+ulPf6p4pObpp5+me++9ly688EJ+aijLWzx48GBIxzoAAACA/TvRrR4JeN2cOXPo5ZdfpjfeeIO2bt3KJwFlTS2zZs3iv7/66qt5p7jgzjvvpK+++oqefPJJ2rZtGz3wwANUUFBAt912G/99dXU13XXXXbRixQoqLCzkBXe23z5o0CDe+AIAAADgZf9ctoeeW+Q/O+/PF42mn4zpTSfmduY/ryk6bvHowFFF9HD27t3LJy1iES6CrKwsmjRpEv3www+Wjg0AAADap6G5hRZuPUI1Dc3kdkLtHDV0sNpll11Gf/3rX3lc4tixY2n9+vW8SC5MHrpv3z46dOhQ8PZTpkyhd999l1566SV+9uhHH33Em1lGjRrFf8/iYTZu3EgXXHABDRkyhK6//nre7b5s2TLecQ4AAADgVR+tOUCPfLGVX77rrKH080n9+OX8QBG9AEV0R3DExKKsgM4IO/UC9rPwOyUNDQ38S1BZWWniKAEAACAaHxYcoHs/3Ux3nDaI5pw5lNwMmehgJ6yLXOgkl2OTgcpdcskl/EsJm7Po66+/NnyMAAAAAE42f8sR+v3HG/nl2dP60y2nDAz+Tiiirykss2x84LJO9GjNnTuXd6wLXzk5OVYPCQAAAGSOVvsPeJdWN5L7oXgOAAAAAOAFK/Yco1vfXUstrT66eHxf+sO5wylOmFGUiMb260QJ8XF0sKKeDpbXWTpWcEkRvWfPnvz7kSNHJNezn4XfKWE5jhUVFcGv/fv3mz5WAAAA0KetKdv9BWZkogMAAAAAuN/m4gr65RsF1NjcSmeM6EF/+b/RkgI60yE5kUb08k+sjkgX+3NEEb1///68WM4mKBJHs6xcuZImT56s+ncsfzEzM1PyBQAAADbNCfdAYbktE90DKwsAAAAA4EF7SqvpmldXUXVDM500oAs9e8WJlJigXIIdj0gXx7BNJnp1dTXt2uWfpVaYTJRNcNSlSxfq168f/epXv6JHHnmEBg8ezIvq9913H/Xu3ZsuuugiS8cNAAAA7RSonnuiiO6hdQUAAAAA8JpDFXV01Sur6FhNI43qk0kvX51PqUkJqrefkNeFXv++kFYXohPd7mxTRC8oKKBTTz01+POcOXP492uuuYZef/11+t3vfkc1NTV0ww03UHl5OZ188sn01VdfUWpqqoWjBgAAgPbyUne2sIat7l9VAAAAAABPKatp5AX04vI6GtCtI70+ayJlpCaF/Zv8PH8n+rbDlbxzPT3FNqVakLHNM3PKKacEu7OUsNyghx56iH8BAACAe3gpJzy4rh44YAAAAAAA4BWsAD7rtVW0q6SaemWl0lu/nETd0lMi/l2PzFTq2zmNDhyvo3X7jtO0wd1jMl5waSY6AAAAuJdQUPZCWdlL+e8AAAAAAF7Q0NxCN75VQBsOVFDnDkn01vUTqU+nNM1/nx/IRS9ApIutoYgOAADgEkt2lNJ3u46S0wgF5VYPVJbDnXUHAAAAAADO0tLqo1+9v56+23WMOiYn8AiXQdkZupYxPq8L/76mCEV0O0MRHQAAwAXqm1po9psF9Ms3Cqi5pZWcJFhW9lB9GcV0AAAAAADn79P/8d+b6H+bD1NyQjy9dHU+jcnppHs5Qic6i3Nx2mc5L0ERHQAAwAUamlupsbmV6ppaqNlhs1a25YS7n5fy3wEAAAAA3Ozxr7fT+6v3U3wc0d+vGEtTB3WLajlDemRQRkoi1TS20LbDVYaPE4yBIjoAAIAb+FyQie6ByrKX8t8BAAAAANzqpaW76YXFu/nluf83ms4e1SvqZSXEx9G4YC56mWFjBGOhiA4AAOCi4qwjs8XRiQ4AAAAAAA7xr9X76dEvt/HLd58zjC6b0K/dywxOLopcdNtCER0AAMAFxEVZpxVofQ4dd/uiazywsgAAAAAALvPV5sN09ycb+eUbZwygm2YMNGS54/P8RXRMLmpfKKIDAAC4gLgk67TyrBDj4rRxty+6xuqRAAAAAACAHt/vOkp3vLeO2BRUl+Xn0N1nDzNs2WNzOvFYl0MV9VRcXmfYcsE4KKIDAAC4gDhP3GlxLm0RJ84adzS8NIkqAAAAAIBbbDxQTrPfLKDGllY6e2RP+vNPR1FcXJxhy++QnEgje2fyy8hFtycU0QEAANzWie7UOBdyP59TnyQAAAAAAI/aVVJN1762mmoaW2jqoK70zBVjKTHB+JLq+EAuOiJd7AlFdAAAANdlojurQBscrrOGHR10ogMAAAAAOAaLVrnqlZVUVtNIY/pm0YtX5VNKYoIp95Wf24V/LyhEEd2OUEQHAABwAfFElQ6roQfjZ7ww2SYy0QEAAAAAnOFYdQMvoLOc8oHdO9JrsyZSekqiafeXH5hcdNvhSqqqbzLtfiA6KKIDAAC4gbgTnZyptZU8lInu1GcJAAAAAMD9WBGbRbjsKa2h3lmp9Nb1k6hLx2RT77NHZirldEnjE5eu21du6n2BfiiiAwAAuIC4JOu8iUW91Inux3aMAQAAAADAfuqbWuiGN9fQpuIKXjh/65eTqHentJjcdzDSBbnotoMiOgAAgOsy0clRfA4dd7sOGHhgXQEAAAAAnKa5pZXueG8d/bDnGI9ueWPWRBrYPT1m9982uWhZzO4TtEERHQAAwG2Z6A7r6G6LOHG/tjlUvbC2AAAAAADOani555NN9M2WI5ScGE8vX51Po/tmxXQMQi46i3NhBX2wDxTRAQAAXMDZneje6c4OrqMH1hUAAAAAwEkF9Ln/20YfrjlA8XFEz15xIk0e2DXm4xiSnUEZqYlU29hC2w5Xxfz+QR2K6AAAAC4grsk6rRjdNl6HDTwKqKEDAAAAANjPC0t200tL9/DLj/3sBDprZE9LxhEfH0fj+vm70QsKEeliJyiiAwAAuIzTokK8lIkurKSQjQ4AAAAAANZ6b9U+evyr7fzyvecNp0vycywdz4RApMtqTC5qKyiiAwAAuIC4KNvqsPqsJzPRvbCyAAAAAAA29+WmQ/THf2/il285ZSD9ctoAq4dE43O78O9rCo+j+cZGUEQHAABwXSa603a0vNOd7aUDBgAAAAAAdrZsZynd+f463oR0xcR+dNdZQ8kOxuZ0osT4ODpcWU/F5XVWDwcCUEQHAABwGafVor1UWPbSJKoAAAAAAHa1bt9xuvGtNdTU4qPzRveiRy4aRXFxcWQHackJNLJ3Jr+8BpEutoEiOgAAgOs60cmZRXSHjbt9Bww8sLIAAAAAADa080gVzXp9NdU2ttC0wd3oqcvGUEK8PQro8kiXgkIU0e0CRXQAAAAXEBdlnVagFcbb6oEqupcOGAAAAAAA2M2B47V01SurqLy2icemzLtyPKUkJpDd5AcmFy1AJ7ptoIgOAADgAm7oRPcCD60qAAAAAICtlFY18AI6yxofnJ1Or107gTqmJJId5ef6i+jbD1dSZX2T1cMBFNEBAADcV5x1Wke3MFqHDTsqwuSpXphEFQAAAADALlgh+trXVtHeozXUp1MavXX9JOrcMZnsKjszlfp16cAnPV23r9zq4QCK6AAAAO4gLso6rTzrxZxw76wpAAAAAIC16pta6JdvFNCPByupW3oyvf3LSdQzK5XsTuhGX1NYZvVQAEV0AAAA9xVlndbkLBTPnTbuaAhnCTjtbAEAAAAAACdqbmml295dS6v2llFGSiK9Pmsi9e/WkZxgPHLRbQVFdAAAANdlojusQOuhyTYxsSgAAAAAQGy0tvrodx9vpAVbSyglMZ7+eU0+jeqTRU6Rn9uFf1+/v5wfDABroYgOAADgCg6Ocwl+d9rI27OuAAAAAABgFtZY9MgXW+mTtcWUEB9Hz/98HE0a0JWchE1+mpmaSLWNLbT1UJXVw/E8FNEBAABc14lODp1sk1zPS+sKAAAAAGCV5xftole/28svP3HxCTRzRA9ymvj4OBoXyEUvKEIuutVQRAcAAHABcU3WaXnbXurOdu75AgAAAAAAzvDWiiL66zc7+OU/nT+C/m9cX3IqYXLRgkLkolsNRXQAAAAXcHYnunCB3A+Z6AAAAAAApvl8w0H602eb+eXbTxtE153cn5wsP69LsBPdcXNfuQyK6AAAAC4gzhN3Wra4JzPR3b+qAAAAAAAxtWRHKc3513q+r33lSf1ozhlDyOnG9O1EifFxdKSygQ4cr7N6OJ6GIjoAAIALOLsT3T/gVoeNu12Z6B44YAAAAAAAECtrio7TTW+toaYWH51/Qi968IJRFBcXR06XlpxAI/tkBdcRrIMiOgAAgAs4uogufHfawKOATnQAAAAAAGNtP1xF172+muqaWmjGkO701KVjKSHe+QX0kFx0TC5qKRTRAQAAXMDJcS7BnHByP5+H1hUAAAAAwGz7jtXSVa+spIq6JhrXrxO9cOU4Sk50V7kTk4vag7u2KgAP+vvCnXTR899RbWOz1UMBAAuJO5udFovSKkScOGzc0RAOcHhhXQEAAAAAzFRSVU9XvbqSSqoaaGiPDHr12gnUITmR3GZ8nr+Ivv1IFVXWN1k9HM9CER3A4T5ee4DW7y+nrYcqrR4KANiE02JRvNSd3bauXlhbAAAAAABzsM7za15dTUXHaimnSxq9ef1E6tQhmdwoOyOV+nXpwD9LrEUuumVQRAdwOKGD02mdpwBgYiY6OUuwoOyw4n80gqvo/lUFAAAAADBFXWML/fKN1byZsFt6Cr113STqkZlKbpYf6EbH5KLWQREdwC1djSjIAHiaJBPdYW8IXupEF3hpXQEAAAAAjNLU0kq3vruWVhcep4zURHrzuomU160juV1+bhf+Hbno1kERHcA1RXSUZAC8TNKJ7rC3A59Dxx0N4b1aOIsIAAAAAAC0aW310V0fbqBvt5VQalI8z0Af0TuTvEDoRGdxvuxAAsQeiugALoE4FwBvE78FOO3twEs54V46YAAAAAAAYGQzykP/3UKfrj9IifFx9MIvxtOEPH93thcM6p5OmamJVNfUgjnxLIIiOoBLuhq9UHwCAHXis1FYh4azBN7HnDbsKHgxugYAAAAAoL2eWbiTXv++kF/+6yVj6NRh2eQl8fFxND7X342OSBdroIgO4HDoagQA13SiO23gURAOeCKCCwAAAABAmze+L6SnF+zklx+8YCRddGIf8qL8QOc9Jhe1BoroAA7npeITAFibiW5W4VdYqhdywtGJDgAAAACg3Wfri+n+//zIL/9q5mC6ZkoeeZXQib66sAxNORZAER3A4YSiE+JcALyu7T3AjB2qv83fQRP+vJCKy+sMX7aXdgCDa+qdVQYAAAAAiMqibSX0m39t4JevmZxLd54+mLxsTN9OlJQQRyVVDXTguPGfyyA8FNEBHK6tg9PigQCAfTrRTVj+0p2ldLS6gTYdqDB82V6KpfLSJKoAAAAAANFi3dY3v7OGmlt9dOHY3nT/T0ZSXFwceVlacgKN7J3FLxcUlVk9HM9xTBG9paWF7rvvPurfvz+lpaXRwIED6eGHH/ZU9xpA+DgXvBbA/VpwtEhbJroJD1PbQ2/8wr1VWPbOJKoAAAAAANHYeqiSrnt9NdU3tdKpQ7vziUTZxJpAlI/JRS3jmCL6Y489Ri+88AI999xztHXrVv7z448/Ts8++6zVQwOwmBDnAuBuO49U0dgHv6HnvvVPKANS4qKsKdniQnSUGYuW3oWrYR4LAAAAAAB1Rcdq6KpXVlFVfTMvGP/jF+MpKcEx5UvT5ef5i+iYXDT2HLMVfv/993ThhRfSeeedR3l5eXTxxRfTmWeeSatWrbJ6aACWQic6eMXGAxVU1dBMK/bgtDUl4vcAM94NfGYuOzi3g/u1PY5eWFsAAAAAAO2OVNbTla+s5DGSw3pm0CvXTuARJtBmfG4X/n37kSqqqGuyejie4pgi+pQpU2jhwoW0Y8cO/vOGDRto+fLldM4551g9NABLeamDE7wNxUc9cS4+8yYxNvHh98LBwOABA/evKgAAAACAZhW1TXT1K6tof1kd5XbtQG9eP5Gy0pKsHpbtdM9I4Y8P+zyxbh+60WMpkRzi7rvvpsrKSho2bBglJCTwjPQ///nP9Itf/EL1bxoaGviXgP09gFsLMoiKBrdD8VHHxKLmpbmYchCjbdnuZ2ZHPwAAAACAE9U2NtOs11fx7ursjBR6+/pJlJ2RavWwbGt8bmcqOlbLc9FPGZpt9XA8wzGd6P/617/onXfeoXfffZfWrl1Lb7zxBv31r3/l39XMnTuXsrKygl85OTkxHTNALAjFcy90cIK34ayL8MTFbVML3aZkonunio5MdAAAAACANo3NrXTz22tp7b5yykxN5B3oOV06WD0sW5uQ5490KShC1GksOaaIftddd/Fu9Msvv5xGjx5NV111Ff3617/mhXI199xzD1VUVAS/9u/fH9MxA8SCl7KEweNM7IR2m9ZWp2Wim7dsu2k74OmFtQUAAAAAUNfS6qPffLiBluwopbSkBHpt1kQa1jPT6mHZHptwlVm/v5yaWkz48AfOjnOpra2l+HhpzZ/FurSGqRSkpKTwLwBvdOeiIAPuFotMbkcTx7mYsfjg429el7vwHLsZzqgAAAAAAPB/rrj/P5vp8w0HKSkhjl64chyPKYHIBnZP53nxbGLRLQcraUxOJ6uH5AmO6UT/yU9+wjPQv/jiCyosLKR///vf9NRTT9FPf/pTq4cGYC1EA4BHoH/X2olFTZ1QNDB6T7yPeeiAAQAAAACAmr/N30Fvr9hHcXFET146FtneOsTHxwUPOBQUYXLRWHFMEf3ZZ5+liy++mG655RYaPnw4/fa3v6Ubb7yRHn74YauHBmApFBbBK5CCEZ64JmvGRMNmFrrNnLTUbrAZg508//zzlJeXR6mpqTRp0iRatWpV2Nt/+OGHNGzYMH57Fq/45Zdfqt72pptuori4OHr66adNGDkAAAA42avL99Lfv93FLz904Si6YExvq4fkOEIRfQ1y0WPGMUX0jIwMvhNeVFREdXV1tHv3bnrkkUcoOTnZ6qEBWEroOEVXI7idUGDFtq5MWoA2cWJRM5Ytuw83a4vFsXok4HUffPABzZkzh+6//35au3YtjRkzhs466ywqKSlRvP33339PV1xxBV1//fW0bt06uuiii/jX5s2bQ27LzhhdsWIF9e6ND8QAAAAg9cnaA/TQf7fwy785YwhddVKu1UNydC56QeFxxPvGiGOK6ACgTOg4xXsmuJ2XJp+Mhvg9wIz3A1Mz6T30PoZOdLALFos4e/ZsmjVrFo0YMYLmzZtHHTp0oFdffVXx9s888wydffbZdNddd/GzQtnZoOPGjaPnnntOcrvi4mK6/fbb6Z133qGkpKQYrQ0AAAA4wYItR+iujzbyy7Om5tFtpw2yekiOxXLQWZZ8SVUD7S+rs3o4noAiOoDDoTsXvMLMiS3dQPyomBPnEviuYdktrT4qqazXsWyf9w4GYTsGCzU2NtKaNWto5syZwevi4+P5zz/88IPi37DrxbdnWOe6+Patra101VVX8UL7yJEjI46joaGBKisrJV8AAADgThsPlNOt767lnxX+78Q+dN95I3j0G0QnNSmBRvXJ4pcLEOkSEyiiAzgc6jDgFejgDU9clDWlKK3jTID7PttMEx9dSJsOVGhbtIcKy146YAD2dfToUWppaaEePXpIrmc/Hz58WPFv2PWRbv/YY49RYmIi3XHHHZrGMXfuXMrKygp+5eTkRLU+AAAA4Iwc9IbmVjplaHd67OIT+OSYYFCkCyYXjQkU0QEczktZwuBtbYVWq0diT5JEdFM70SMvfHdJNf++91iNvmWT+2E7Brdine0s8uX111/X3FV2zz33UEVFRfBr//79po8TAAAAYq+ppZW+3eafd+WWUwZRUgLKkUYYn9uFf19TiCJ6LGCrBXC6QCEGcS7gmTgXqwdiV6IHxoz3Az2Z6HoK7nqX7XRtBww8sLJgW926daOEhAQ6cuSI5Hr2c8+ePRX/hl0f7vbLli3jk5L269ePd6Ozr6KiIvrNb35DeXl5istMSUmhzMxMyRcAAAC4z+rCMqqsb6YuHZNpfKB7GtpPeCx3lFRRRV2T1cNxPRTRARxOKMR4ofgE3hbcxLGxKzK7KNs2sWvk+9Eby6Jn2Y6HTnSwgeTkZBo/fjwtXLhQkmfOfp48ebLi37Drxbdn5s+fH7w9y0LfuHEjrV+/PvjVu3dvno/+9ddfm7xGAAAAYGfzt/gPxJ82LJsSEONimO4ZKZTXtQP/bLF2H7rRzZZo+j0AgKnaik8A7iZMlmnGpJluIC7KmhPnov2AXdtzpW0gXoqlwoFPsIs5c+bQNddcQ/n5+TRx4kR6+umnqaamhmbNmsV/f/XVV1OfPn14bjlz55130owZM+jJJ5+k8847j95//30qKCigl156if++a9eu/EssKSmJd6oPHTrUgjUEAAAAO2ANNkIR/YwR0vlVwJhIl8JjtTzS5dSh2VYPx9VQRAdwOKFIhTgX8E6cC7Z1JeK3ADPeD/QcsAs+V1qHEXwfI9fzVNc92Npll11GpaWl9Kc//YlPDjp27Fj66quvgpOH7tu3j+Lj205anTJlCr377rt077330h/+8AcaPHgwffrppzRq1CgL1wIAAADsbtvhKjpwvI5SEuNp2uBuVg/HdfLzOtPHaw/wyBwwF4roAK6JuLB2HACxguNFFk0sqiOGRCiGax1H283c/+R6qese7O+2227jX0oWL14cct0ll1zCv7QqLCxs1/gAAADA+YQudFZA75CMMqTRJuT5c9E3HCjnE7hi0lbz4JEFcDihEINOdHA7PUVcLxLnkPssPhNAuK3mOBcPPbeYIBcAAAAAvARRLuYa0C2dOnVIovqmVvrxYKXVw3E1FNEBXAIFGfBMlrTVA7Ep8eNiSpyL8N2n47aal+2d5xZnDwEAAACAVxyqqKNNxRUUF8cmFUUR3Qzx8XE0vp+/G70AkS6mQhEdwC2dpyjIgMu1RYRgY1cieVjMjHPRcNtgEV9rnIuHnlucPQQAAAAAXrFgawn/fmJOJ+qekWL1cFxrfCDSZU3RcauH4mooogM4mNkTCQLYCTbxSMRxLsY/WG2F8cjLbm2V/U0EOmvuruCldQUAAAAAr0e59LR6KK6Wn9uFfy8oOu6JxiSroIgO4GDiAhXeJsHthMIwDhhpOahmwvJl3426reT2Pi+dPeTylQUAAAAAT6uqb6Ifdh/ll5GHbq4T+mZRUkIclVY10P6yOquH41ooogM4mKQEg4IMuJyXJp+MhiTNxcw4F5+OyTM1x7kIt3f3kytePXevKQAAAAB43ZIdpdTU4qMB3TrSoOx0q4fjaqlJCTSqTxa/vBq56KZBER3AwczuPAWwI2zqWgq0ZjxK2gvdwtkCes8acPtza/aBDgAAAAAA+0W5oAs9FibktUW6gDlQRAdwMHGhzO0dnACtgSNF2NYjvx+YcVAtOLGrCRnnwafUS3Eulo4EAAAAAMA8TS2ttGibf1JRFNFjY3yuMLkoOtHNgiI6gIOhEx28xCN11qhJji2YcKBBT0SL0IGu9YCHcADA7c8tIrgAAAAAwAtW7y2jyvpm6toxmU7s5y/uQmyK6DuOVFNFbZPVw3ElFNEBXALlGHA7r3QrR0tSQzdx+bo60TVnopMnJo1FJjoAAAAAeME3gSiX04ZlU0J8nNXD8YRu6SnUv1tHfnntPkS6mAFFdAC3FGRcXnwC8Eq3crTE7wFC9I2xyw+9H9XbKoxJ2+3JQxFclg4FAAAAAMAU7DMA8tCt7UYvQKSLKVBEB3AwcdcmCjLgdnqKuF5nxiPUFtGi/bZaa/nBqBiXHyIxf/JXAAAAAABrbT1URcXldZSaFE/TBne3ejiekh8ooq8uRCe6GVBEB3BNfAMKMuBuQqEV+f9azkwx4w6Ebz7tBXd9i/bUwUAvrSsAAAAAeIfQhX7yoO6Ulpxg9XA8JT/PX0TfsL+cGptbrR6O66CIDuBg4o5cFGTA7doyubGxKxE/LmZki+spdOs+ayBYoHc3O549tGxnKW0urojJfS3aXkLbDlfG5L4AAAAAwBrztx7m389ElEvMDeyeTp07JFFDcyv9eDA2+/hegiI6gIOJazDozgW30ztZpdeY/bi0Ra5oH4vOGrrrq+h2m1i0rKaRrnl1Fc1+s8D0+zpUUUezXltNt7y91vT7AgAAAABrHCyvo83FlRQXR3Ta8Gyrh+M5cXFxwVz0NUWIdDEaiugADoZ8XfDkxKLY1C2JcxEO1OnJRNf6vuSZTHTxZRtsyFX1Tfx5PV7baPp9VdQ18e+xuC8AAAAAsMbCrf4ol3H9OlO39BSrh+NJ43O78O8FyEU3HIroAE5mdgYygI1gG9dzZooZcS7aC93RdqK7/Tm2WwSXcGAkFmcytQYiGXHWFAAAAIB7fRPIQz8DUS6W56IXFB23ReOOm6CIDuBg4mIW3hzB7do6obGtRyzQmrJ86fdwhCK+1oJpcNnkbnabDDq4zfhieSaJ9esNAAAAAMarrG+iFXuO8csooltndJ8sSk6Ip6PVDbSvrNbq4bgKiugADiYuUKEuAW7X1gkNkaNCTFi+L4oDHlrjXDxSYDU7cif6TnTzB4M5DQAAAADcbcn2Umpq8dGA7h35BJdgjdSkBBrVJ5NfXo1IF0OhiA7gYOKCE06RB9eLYcHPkXwxinPRtGx9+fVe6USXRHCRHcTuwJRnnmMAAAAAj5qPKBfbyM/z56KvKSqzeiiugiI6gIPZLRoAwExeyc2OltnvAfriXITb+gxftpPZLYIrlhFJwclmbbDeAAAAAGCsppZWWrS9hF8+E0V0y+XnBnLR0YluKBTRARxMXItAJzq4nVB8w6YemRmFyuBBDB33r70T3V7F5ZjEuZD19GbXO+W+AAAAACC2Vu4po6r6ZuqWnkxjc/wFXLDO+EARfWdJNZXXNlo9HNdAER3ALZ2nLi48AUi7Zq0eiTcPqrV1Emu5bWBMNslztwvJqvnsltFu8pkMwe82WHEAAAAAMNSCrf4ol9OGZVNCfJzVw/G8rukpNKBbR3557T50oxsFRXQAJ7NZVyOAmdpqfNjarZxYVEsRtK3rWF+ci3/57iXpuCfriZ8fsw9eCOuOTnQAAAAAd2H7eW156D2tHg7IutER6WIcFNEBHExcjMBki+B2bRNbWj0Se5IWos17kHTMK6o9zsVmWeGxOdBh/XrG8uBF8L6sX20AAAAAMNCWQ5VUXF5HqUnxdPKgblYPBwLy8wJF9CIU0Y2CIjqAg0kLT5YOBcB0bZ3QEOn9wOhuX72Z5cHoF83LF10m97LbekojgMwdkbBN4oAvAAAAgLsIXejTBnentOQEq4cDAeNzu/DvG/aXU2Nzq9XDcQUU0QEczG4FGYBYsEMHrx1JHhaDHyNxUd6nK79eY5yL+LKLn167HfiM5XgwMTAAAACAO7VFufSweiggMrB7R+rcIYkamltp88EKq4fjCiiiAziYuBiB7j5wu7acbatHYk+SQrTRy9aZna03eidWUTSWs9l6xjISDJ3oAAAAAO7DYlx+PFhJbC7R04dlWz0cEImLiwt2o69BLrohUEQHcDBJlyfqEuCVOBcXFeF2HKmix77aRhV1Te1fmOhxMbpQKS3Qa4lz0X5b+T246Om1fcd9LAvawU50G6w3AAAAABhjQaALnU1i2TU9xerhgGouepnVQ3EFFNEBHCyWebYAVgt2N5N7zFu8m15YvJu+2nzI1gVayfE6LZ3oOs8a8Mrbl97H0U3/h9htUlUAAAAAaL8FWxHlYmf5uf4i+pqi49gHNwCK6AAugfdD8Mw27qJtva6phX+vb2r/RC9mnpgiLrD6dJ014MwObbPYIcKlPTE9hm1D9noYAAAAACAKlfVNtGLPMX555nAU0e1oVJ8sSk6Ip6PVjVR0rNbq4TgeiugADqa3sAXgZG0RIW7MefcZWhA1s6tYy6KF+9daNI7V2K1mt7OHYjmvht3WHQAAAADaZ/H2Umpq8fEJLAd0T7d6OKAgNSmBRvfN4pcLipCL3l4oogM4GIoS4C1CprJ7tnW9Hdthl6X6gwHL1jkhZmt7OtHJvezWcd8qytsxezg46AsAAADgLvMDeehnjOhp9VBAQ6RLQSFy0dsLRXQAB7NbQQYgJgVncg8jE2rMPKgmKZz79ESEaO1EV/57t5E8NjbYksWZ9b72JwqFhYO+AAAAAO7R2NxKi7eV8MvIQ7c3Nukrg0709kMRHcDB3FxsApATNvdWV3aiGxDnorBcU4qtJkyeKS0uu5ftJhal2BX1Jfdlg3UHAAAAgOit3HuMqhqaqVt6Cp2Y08nq4YCGIvqukmoqr220ejiOhiI6gIPFMs8WwGpCEc5Nm7pQPDYkzsXEQrSe7nLxe5G4+B52+ZL7Ik+ww2pKu8PNva9WkzvdAQAAACD2US4zh2dTfHyc1cOBMLqmp9CA7h355TXoRm8XFNEBHMxuXY0AZnLjxKI+kw6CGR/nIrocKc5Fchmh6HZ+z45ljA4O+gIAAAC4A9tvXBDMQ0eUi6Ny0VFEbxcU0QEcTFz0QFEC3C64ibuxE92QZSlfNn5iUR0TSEZVQ3fREywjXTfr1zOWk31Gs10AAAAAgP38eLCSDlbUU1pSAk0d1M3q4YAG+bld+Pc1hSiitweK6AAOZq9yDECM4lxctLUHu+uNiHMx8XGRxrlEuq3y3xm1fCezXSe66LLZB2IxsSgAAACAu6Jcpg3uRqlJCVYPBzQYn+fvRN9woJwamlusHo5joYgO4GB2K8gAmMrAgrMb41zMLFJKO9F9hnWtK93ORU+v7ddTsp2YPCCvTB4LAAAA4JUiOqJcnGNAt47UpWMyNTS30ubiSquH41iOKqIXFxfTlVdeSV27dqW0tDQaPXo0FRQUWD0sAMuIi1lm59kCWM2FaS6Gvm7NnJxTz7KjinOJYTa3lfRM0Br7SDBz70u8fB8mGQUAAABwpAPHa2nLoUpic4mePhxFdKeIi4uj8YFc9DVFZVYPx7EcU0Q/fvw4TZ06lZKSkuh///sfbdmyhZ588knq3Nm/EQB4ETrRwUuE4qwboyCMKKjq6RY3s/grfn60PleSA4LkXnbrRDdzmwn/HNth7QEAAABAL2FCUZaxzTqbwYGTiyIXPWqJ5BCPPfYY5eTk0GuvvRa8rn///paOCcBLBRAAu2zvbqqhtx0YaP+yxO8BRncVS7qII45D+229lpdttwOf4uc1lp3oZt8XAAAAAJhj/lZEuThVfiAXfU3Rcd4YxbrTwaWd6P/5z38oPz+fLrnkEsrOzqYTTzyRXn755bB/09DQQJWVlZIvADcxs2gGYDdu3MSNPDBgZoFWGh0V4baiqA7NcS6qP7iNfeNczB6P3aJsAAAAAECfiromWrnHHwUyE0V0xxnVJ4uSE+PpWE0jFR6rtXo4juSYIvqePXvohRdeoMGDB9PXX39NN998M91xxx30xhtvqP7N3LlzKSsrK/jFOtkB3MRuXY0AZnJjEU5YDeO7r80LRY901os0E11/Fd0dz6yyGM7jqf8MA9MnFlW+XwAAAABwhsXbS6i51UeDstOpf7eOVg8HdEpJTKAT+mTxywWFyEV3dRG9tbWVxo0bR48++ijvQr/hhhto9uzZNG/ePNW/ueeee6iioiL4tX///piOGcBsXpmMD8DsiTOtIhScfUZPEtlq3WMfzfOkp9Pdyey3DcfucUcmOgAAAICzzQ/koSPKxbnGiyJdwMVF9F69etGIESMk1w0fPpz27dun+jcpKSmUmZkp+QJwE69MxgcQ0olO7hBcD5tPLCrpLtd1W40Ti3pkfge7HfiU5pSbOx7xgR0brDoAAAAA6NDY3EpLtpfyyyiiOxebEJZZjU50dxfRp06dStu3b5dct2PHDsrNzbVsTABWs1tBBsBMrtzeg3Euhi3Kf9noNBcdsR/RxHZII2DItex24FPPwRFD78sOKw8AAAAAmq3Yc4yqGpqpe0YKje3byerhQJTG5/o70XeX1tDxmkarh+M4jimi//rXv6YVK1bwOJddu3bRu+++Sy+99BLdeuutVg8NwDLiOgQyZsHt7JYnbWyci7Gd6Ea/H0gX59ORXa9/+W55bp0wj4V0mzF5YlGK3X0BAAAAgDlRLjOHZ1N8fJzVw4EodemYTAO7+/PsEeni4iL6hAkT6N///je99957NGrUKHr44Yfp6aefpl/84hdWDw3AMm6MtwBQIy40u6UIJ6yFEatjZua0nsK4ZLLKaOJcXPLcOiG2Jpbd4fj/CgAAAMCZ2H7cgq3IQ3dbpEsBiui6JWq50d///nfNC7zjjjvILOeffz7/AgCl+AaUJcDd7NbFawThdWtInIuJ7dy64lzaOVmlW55bp02gavb/IV45UAIAAADgNj8erKRDFfWUlpRAUwZ2s3o4YMDkoh8U7Kc1RchFN6WI/re//U3yc2lpKdXW1lKnTv4cpPLycurQoQNlZ2ebWkQHgPbHJgA4lRsji4Kd6EbEuYguG92pr6eDWtKJrmEcXiqo2i2SKLaZ6G2XPfSUAwAAADjeN4Eol+lDulFqUoLVw4F2yg/kom84UEENzS2Ukojn1NA4l7179wa//vznP9PYsWNp69atVFZWxr/Y5XHjxvGIFQDwbjQAgLncd9BIKCwasj4mFkT1dFC3iqqlWg58yJfnluc2Is9lorvv9QsAAADgpTz0M0b0tHooYID+3TpS147J1NjcSpuLK60ejrsz0e+77z569tlnaejQocHr2GXWrX7vvfcaPT4A0Np52mrhQABiwJUHjYSJRQ2oKkrjnchQ0pxz7XxR3MYtefdO2IZj2R0uvi83P8cAAAAAbrK/rJa2HqokNpfoacOyrR4OGCAuLo7GBbrRCwoR6WJqEf3QoUPU3Nwccn1LSwsdOeI/OgUA3izIAJjJzCKxKyYWNbFIqW9iUV+74lxc8tQ6ohsbE4sCAAAAQDjChKL5eV2oS8dkq4cDBpmQFyiiY3JRc4vop59+Ot144420du3a4HVr1qyhm2++mWbOnKl3cQDQDshEBy9xYxGu1ciJRcUF2vYvTrZs0eUIbzZ6u5t9HspIt1smOsUyzgWd6AAAAACOjXI5c0QPq4cCBhqf24V/X1t03NWfvywvor/66qvUs2dPys/Pp5SUFP41ceJE6tGjB/3zn/80Z5QAoGEiQQsHAhADboyDEFbD8DNJfNYVf6UHO7R0ost+JvfSczAiFmL5Oopl1zsAAAAAtF9FbROt3OuP+zgDRXRXGdUnk5IT4+lYTSPtPVpj9XAcI1HPjdkHvrq6Ovr444/pwIEDfEJRZtiwYTRkyBCzxggAmgogqEqAu7kyzsXnxDgXozvRZXEuLnlunXA2hfRAbOw60e1wAAEAAAAAwlu8o4RaWn00pEc65XbtaPVwwEApiQk0pm8WrS48ziNdBnRPt3pI7iyiDxo0iH788UcaPHgw/wIAC8VwUjgAq0kKb67LRLf3xKJ6DteJ10VLYTb0Ji55ch1wICiW3eGS+zL3rgAAAADAAN8EolzQhe7eSBdWRF9TeJwuzc+xejjui3OJj4/nhfNjx46ZNyIAsGUXIYCduGUiXaHg7LP5RMPSLuIIt1X5u2juy21ComssXlmrcsrx/xUAAACAvTU0t9CS7aX88szhKKK7UX6uf3LR1UX+yB4wIRP9L3/5C9111120efNmvX8KAAZzYWMugCGFXKcQ1sOIoqK4cG70HAl6Ji3V23HspUx0+dpZvR3HMl4GmegAAAAAzrFiTxlVNzRTdkYKjenbyerhgAnGB4roe0prqKym0erhuC/Ohbn66quptraWxowZQ8nJyZSWlib5fVkZjmAAxIqZRTMAu3FjHITwGjakqGjiQYbWVtKeia7jtvw2Nissm8luBwyk+fXmjsaNEwMDAAAAuNX8LYf599OH96D4+DirhwMm6NwxmQZlp9OukmpaU3QcsT1mFNGffvppvX8CACbBRG3gJW7c3oXCosE1dMPLs3o60SW39UVTWHbHc6tEvmb+7di6DyXSCWPNvi/ly2Ct559/np544gk6fPgwb5B59tlnaeLEiaq3//DDD+m+++6jwsJCHvH42GOP0bnnnhv8/QMPPEDvv/8+7d+/nzfbjB8/nv785z/TpEmTYrRGAAAAYMQ+4oItJfzymSisuj7ShRXRC4rKUEQ3o4h+zTXX6P0TADAJ6hDgJXoKuY7LRDcizkUyoWe7FydbtvgH7bfVFOcSppPdbezciW722UyIc7GfDz74gObMmUPz5s3jRW7WKHPWWWfR9u3bKTs7O+T233//PV1xxRU0d+5cOv/88+ndd9+liy66iNauXUujRo3itxkyZAg999xzNGDAAKqrq6O//e1vdOaZZ9KuXbuoe/fuFqwlAAAA6LWpuIIOV9ZTh+QEmjywq9XDAZMjXd5fvZ9PLgomZKKL1dfXU2VlpeQLAGJHXJTA6fHgdlZNgmgmYS2MWJ1YdepH6hTX+74kH6urO9F9NstEF1+O4WDc/Bw7yVNPPUWzZ8+mWbNm0YgRI3gxvUOHDvTqq68q3v6ZZ56hs88+m8+NNHz4cHr44Ydp3LhxvGgu+PnPf04zZ87kRfSRI0fy+2CfDzZu3BjDNQMAAID2WLDlCP8+Y0h3Sk1KsHo4YKL8vC78+8biCj6ZLBhcRK+pqaHbbruNd6h07NiROnfuLPkCgBjC6fHgIZJN3C3bu8/AIrrK5Vh3EeuN7QiNOCHXCllXizdkM89ekGsV3YGbn2OnaGxspDVr1vCCtyA+Pp7//MMPPyj+DbtefHuGda6r3Z7dx0svvURZWVk8KgYAALxh++EqFOMc7ptAER3xHu6X17UDde2YTI3NrbS5uMLq4biviP673/2Ovv32W3rhhRcoJSWF/vnPf9KDDz5IvXv3pjfffNOcUQKAIdnDAE4myW8mdxCK00Z01ks79du9ONVlRxqq3glgvfTeFRLnYvG6S58rTCzqJUePHqWWlhbq0UP64Zj9zPLRlbDrtdz+v//9L6Wnp1NqaiqPc5k/fz5169ZNcZkNDQ04qxUAwEW+/vEwnfX0Urr7401WDwWitL+slrYdrqKE+Dg6dWhovBu4S1xcHI90YVYj0sX4Ivrnn39O//jHP+hnP/sZJSYm0rRp0+jee++lRx99lN555x1zRgkAnom3APDSxITBOBfDD6oZPbGo8v1EKpZqGofNCstmsrrz3MrXlBvnNABlp556Kq1fv55nqLP4l0svvZRKSvyTk8mxfHXWqS585eTkxHy8AABgnH+vLebfP11fTIVHa6weDkRhfqALnU042bljstXDgRjIz/MX0QtQRDe+iF5WVsZzDpnMzEz+M3PyySfT0qVL9S4OANpB7wR+AE6mp5DrtNew0Z3opp4FEPF+9J0hI38u3fLcOqMTPXZj0X1wBUzFOsMTEhLoyBH/B2UB+7lnz56Kf8Ou13J7Fvc4aNAgOumkk+iVV17hTTfsu5J77rmHKioqgl/79+9v97oBAIA16ptaaOnOUn6Z/Vf/0rI9Vg8J2lFER5SL93LR1+47jv10o4vorIC+d+9efnnYsGH0r3/9K9ih3qlTJ72LAwAHTgoHYAV9hVxnCBbPDV4fo89MkRRAdd1Wy8Si4X92k5B1tToTXXT/pp/N5MLXr5MlJyfT+PHjaeHChcHrWltb+c+TJ09W/Bt2vfj2DItqUbu9eLkstkUJi4ZkTTniLwAAcKbvdx+l2sYWSk3yl5k+WnOASquU3//BnsprG2lVob9R9swRygfVwX1G9c6ilMR4KqtppD04g8TYIvqsWbNow4YN/PLdd99Nzz//PM88/PWvf0133XWX3sUBQDu4sagIYMXEmVYxsoZu7vuB9qgY8QSSra16lqz8s5uEdN37vHM2kzQT3eQ7A03mzJlDL7/8Mr3xxhu0detWuvnmm6mmpobv6zNXX3017xQX3HnnnfTVV1/Rk08+Sdu2baMHHniACgoK6LbbbuO/Z3/7hz/8gVasWEFFRUV84tLrrruOiouL6ZJLLrFsPQEAILYdzJeMz6ExOZ34RIVvfF9o9bBAh0XbS6il1UdDe2RQv64drB4OxEhyYjyN6etvil6DSJewEkknViwXzJw5k+9Es51kdtrmCSecoHdxABCj7lAAp5MU4VxWhTMkzkV82cKJRfXG7siL8m4+qya0E91a0gMv5o7GzMx+iM5ll11GpaWl9Kc//YlPDjp27FheJBcmD923bx/Fx7f120yZMoXeffddPhcSK5YPHjyYPv30Uxo1ahT/PYuHYZ8LWFGeTVzatWtXmjBhAi1btoxGjhxp2XoCAID52L75gq0lwRiQqYO60k1vr6U3fyikm08ZSB1TdJeewAILtrQ9h+At4/M687MQCorK6NIJmKNGje53svr6et55LsjNzeVfAGCFGJ6KD2A1F27jwuvWiFUzc6JhPWcBiO87inlFLS8smylkXS3epq3KRHfZMTBHY13kQie53OLFi0OuYx3lal3l7PPBJ598YvgYAQDA/jYcKOfRLRkpiXTSgK6UEB9H/bt1pL1Ha+i9Vfvol9P88+qBfTU0t9Di7SiiexWbSJYpKEInuqFxLiz3fPr06XTffffxXMS6ujq9iwAAC7pDAZzOzE5rV8S5iDt9yVjizv9IhV+970vygr9bnltNXfdkLckBD5NHE8v7AgAAAGuiXGYM7c6jIVgRfXagcP7K8r3U1KIh4w8s9cPuY1TT2ELZGSk0uk+W1cOBGBsfKKLvKa2hY9WYy8CwIvqCBQvo7LPPppUrV9KFF15InTt3ppNPPpn++Mc/8smFACB23JgRDaAtv9kdW7ywHobEuZj4hqBn0bqfp5CJRd3x3GrqRLf486Tk7AWzx4KDvoZg0ShXXnkln8yTZY0zb731Fi1fvtzqoQEAgIcJRXRxB/P/jetD3dJT6FBFPX2+4aCFowM9z+HMET0oPj7O6uFAjHXqkEyDstP55TXoRjeuiM4K5iwH8ZtvvqHy8nJatGgRz0N//PHHeXEdAGJH2vGJqgS4mzRTmVwhuB5GxLmQiXEuOgqgiHMJIyQT3WefTHST70vvdgGhPv74YzrrrLMoLS2N1q1bRw0N/i6hiooKevTRR60eHgAAeFTh0RraWVJNifFxdMrQ7OD1qUkJNGtqHr/84pI9+Lxq+0z70AMh4C0T8vzd6CiiG1hEZ3bs2EEvvfQSXX311fSzn/2MPv/8czr//PPpqaeeimZxABAlNxYVAdSIO2XdsrkLKSlGd6Ib/fjoiYrRW8wPmWzTLU+uAnnR3Op1NfPASywz+73ikUceoXnz5tHLL79MSUlJweunTp1Ka9eutXRsAADgXUIHM8tCz0pr+/+JuXJSLnVMTqDtR6po8fZSi0YIkWwqrqAjlQ38uZoysKvVwwGLjM/twr8jF93AiUX79OnDc9BPOeUU/vX73/+eTjjhBIqLw+keALEmnagNRQnwUia6W7Z34yYWNXOiYT1nvUizr6MpLLvludVwwICsFcvucMkkpubelWtt376dz0skl5WVxc8OBQAAsDQGZHhbF7ogq0MSXTGxH/1z+V6at2Q3nTos9DZgr0z7lMQEq4cDFk8uuulABdU3tfCzSaCdnejdu3en2tpaOnz4MP86cuQIJhcFsMOp+KhKgIe2d3FBzh0TixrciW50JrrPvPcluxWWzRTadW91nIv4si+GZ065+Vk2T8+ePWnXrl0h17M89AED/JO3AQAAxFJZTSMVFJUFs7SVXD+tP496Wbm3jNbtQ4erHSHKBZjcrh2oW3oyNba00ubiCquH444i+vr163nx/O677+ZZjCwfvVu3bjRlyhQ+uSgAWAMlCfAWd2zxQiewEQcFYhbn4jO2MBuSie6Op9YR+e+x7A438yCPV8yePZvuvPNOWrlyJT8D9ODBg/TOO+/Qb3/7W7r55putHh4AAHjQt9tK+P7EiF6Z1LdzB8Xb9MpKowvH9glmo4O97C+rpW2HqyghPo5OFWXag/ew/cvxgW50RLoYFOfCdOrUiS644AKewciK55999hm99957fKf+z3/+czSLBIAoYGJR8BI3FuGC84r67N3pKy3QR4pzEd9Wy7JlcS6Wl5bNE7KuPjud3WHuYKQxP+59js3EGlhaW1vp9NNP52eFsmiXlJQUXkS//fbbrR4eAAB40PwthzV1MN84YwB9vPYAfb3lMO0praYB3dNjNEKI5JtAlAubVLJTh2SrhwMWy8/tQl//eIQKCsuIZgy0ejjO70T/5JNP6I477uA56D169OCdL9XV1fTkk09iUiOAGMPEouAlerO2naBtlewd56InO1tvznbIbdzy5CoIXVWL41zEl00eimRiUdEkwaCvO4id9VlWVkabN2+mFStWUGlpKT388MNWDw0AADyIZSYv3XFUUxF9SI8MOn1YNt8feHnZ3hiNEPQdCOlp9VDABsbn+TvR1xQdR6OmEUX0m266iZ8+esMNN9C6deuopKQkWFgfM2aM3sUBQIy6QwGcLpYFv1jxGRnnIrlscCe6+LKOOJdouptd8tQ64oBBa6tVnegQjeuuu46qqqooOTmZRowYQRMnTqT09HSqqanhvwMAAIil73YdpbqmFurTKY1G9s6MePsbA12trCO9pKo+BiOESMprG2l1oT+240zkoQMRjeqdRSmJ8XS8tol2l9ZYPRznF9FZ0fyjjz6i2267jUaPHm3OqABAE2mxysqRAJhPMmGlS8pwwYlFDShgmtrpq+OAXbsnFnXHU6tCHl1jLZ9F92V2wd6t3njjDaqrqwu5nl335ptvWjImAADwrvmBGJCZw7P52VKRsLiQE/t1osbmVnr9u8IYjBC0ZNq3tPpoWM8MyuminGkP3pKcGE9jcjrxy2sCkwZDO4rozO7du+nee++lK664ghfVmf/973/0448/RrM4AIiSNDYBRQlwN1d2oge+G9OJbl6nr57oKN2Z6CGFZZc8uQ44YCD+P8TswrbegyvQprKykioqKvhjyDrR2c/C1/Hjx+nLL7+k7GxMBAYAALE9m23BVn8taKbGDmZWaL9xur8b/a0VRVTd0GzqGEH7gZBIcTzgLfnC5KKBsxSgHUX0JUuW8A50Nokoi3FheejMhg0b6P7779e7OABoBzcWFQE8NbFoYEUMWR0TJxoWd7ZHjHPROcGp/CZuPqvGdpnoMXxNYSLs6HXq1Im6dOnCiw9Dhgyhzp07B7+6devGo1xuvfVWq4cJAAAesm5/OR2tbqCMlESa1L+r5r9jkSEDunWkqvpmen/VPlPHCJEz7ZfsKOWXUUQHsXxRLjpIJZJOd999Nz3yyCM0Z84cysjICF5/2mmn0XPPPad3cQDQHjo7PgGcTFx4c0scRKuRcS7iywY/PHry1iWd6FriXOQ/u+S5dUInuvQ1Ze59IRM9eosWLeLPFdvX/vjjj3lBXcDy0XNzc6l3796WjhEAALxlwVZ/B/Mpw7J5/INW8fFxdMP0AXT3J5von8v20tWT83T9PRjnhz3HqLaxhXpmptLoPllWDwdsZFw/fxF9z9EaOlbdQF3TU6weknOL6Js2baJ333035Hp2GunRo/6ZmQEgNvR2fAI4mc/Fr2EjXr5mZsbrieLQOw75e5cbn2f16BprSQ94mD2xqPiy1WvuLDNmzODf9+7dSzk5ORQfj2IDAAA4NwbkohP70JPzd9Dhynr6z4aDdPH4viaMEDRn2o/QlmkP3tGpQzINzk6nnSXVVFB0nM4a2dPqIdlGfDSnlB46dCjk+nXr1lGfPn2MGhcAaICJRcFL3BnnEvhOTupEN/Z9KeQmLnluNUXXWPzGrSfrvt335cLXb6yxjnNWQK+traVt27bRxo0bJV8AAACxsPdoDe0qqaakhDg6ZWh33X+fmpRA103tzy+/tHS35ftDns20D04MiygXCIVIF4OK6Jdffjn9/ve/p8OHD/OjVa2trfTdd9/Rb3/7W7r66qvNGSUAtDtiAcDppBNnumN7F9bCmE508zp9pZ3okeJc2peJ7pbnVond1kw6CWzsJhZFJ3p0SktL6fzzz+dxiiNHjqQTTzxR8gUAABAL87cc5t9PGtCVMlOTolrGzyf1o/SURNpxpJoWbfdPUAqxs7G4gkqqGvhzMHmg9kx78I78XH98YEFhmdVDcXYR/dFHH6Vhw4bx00nZpKIjRoyg6dOn05QpU+iPf/yjOaMEAA3FKkuHAmA6PZNbOoVQWDSiqKinW1z3snXMvyAtzGpauup9uU1IdI3lmejKl025L3MX7wm/+tWvqLy8nFauXElpaWn01Vdf0RtvvEGDBw+m//znP1YPDwAAPKI9US6CrLQkXkhnXlyyx7Cxgb4DITOGdKeUxASrhwM27kTfXFzJJ6GFKDPR2QRGL7/8Mv3pT3/i+eiskM66X9gOPADEFk6PB69yy+YejHMxOBPd6AdIT1SMnvx0pdt46b3M6q57qyYWRSd6dL799lv67LPPKD8/n8e6sHiXM844gzIzM2nu3Ll03nnnWT1EAABwOTbJoBDvcHo7Y0BYpMtr3+2lVYVlfJnjc/1FO3DGgRBwt35dOlC39BQ6Wt1Am4oraEJe28T2Xhb1zESsE/3cc8+lSy+9lBfQP/nkEzrhhBOMHR0A6ChsoSgB7qYnUsSLcS5iRhcpJWe96Dq4pyHOJcLPbmK3Awa+mMa5KF8G7Wpqaig7O5tf7ty5M493YUaPHk1r1661eHQAAOAFC7eV8APvI3tnUp9Oae1aVs+sVLpobJ9gNjrERtGxGh6jkxAfR6cO9e9XAMix+O78wIGtgkLkokdVRH/xxRfp4osvpp///Of8VFKhK4Z1ol911VU0depUPYsDgPaKYRchgNXEm7hbtnehOG34xKLtXpps2Tpa0fUU3JUW55YDJErkz7PVayrtDo/dfbn4KTbV0KFDafv27fzymDFj+H55cXExzZs3j3r16mX18AAAwAMWGNzBfMP0Afz7N1uO0O7SakOWCdq60Cf170JZHaLLtAevTS6KXHTdRfS//OUvdPvtt1NhYSHPXTzttNN4PvovfvELuuyyy+jAgQP0wgsvaF0cABgAE4uCl0gLb+7Y3o2McxE/JEYXKfUU6KUHO3yOKyybyW4HDCSFc5PHYubEt15x55130qFDh/jl+++/n/73v/9Rv3796O9//zvfJwcAADATy0VetvOooUX0wT0yaObwbL6f8PJSZKPHAqJcQCshYqmg6Di1uqWLLVaZ6K+99hrPQr/mmmto2bJlNGPGDPr+++9p165d1LFjx/aOAwCigNPjwUvc1skqzaM2ohPdvMxpPTnnep8nu0WcmClkXa0aSPD+Y9eJLr4vq9fbqa688srg5fHjx1NRURFt27aNF9K7detm6dgAAMD9lu88SnVNLTzGZUSvTMOWe9OMgbRgawl9sraY5pwxhLIzUw1bNkgdr2mk1YX+ruKZ7cy0B/cb2TuLUhLjqby2ifYcraZB2RnkdZo70fft28e7z5lp06ZRUlISPfjggyigA3hkUjgAq5kZV2IFo+cBNfOgmp7sbPF7UXRFdDc8uxrz3+2UiW7yYFpbY3dfXtGhQwcaN24cpaen01//+lerhwMAAB7qYGZ5yUbJz+vCO14bW1rp1e8KDVsuhPo2kGk/rGcG5XTpYPVwwOaSE+NpbE4nfhm56DqL6A0NDZSa2nZEMDk5mbp0weysAFaSFs5RlAB3c9uZF0YnaZj5mEi6iHXMLKptYlEvxbnYaxrVWB6I1bUNQQg2ieh///tf+uabb6ilpYVf19TURM888wzl5eXx2EUAAACztLT6aOE282JAbgxko7+zooiq6psMXz5ID4SciSgX0JmLziJdQEecC3PffffxrhemsbGRHnnkEcrKypLc5qmnnjJ2hACgKoZxtgA2oK84a3fSiBS7x7koX47Yia5z2VqW72R260TX+1wZdV84c0qf5cuX0/nnn0+VlZW88y8/P5/HLF500UWUmJhIDzzwAI9bBAAAMMv6/cfpaHUjZaQm0sT+xjdTsmiRgd070u7SGnpv1T66YfpAw+/D61im/dKdpfzyGSN6Wj0ccIj8XPZ6301rUETX14k+ffp02r59O61bt45/TZkyhfbs2RP8mX2tX7+eYoV13LAPEr/61a9idp8Abs9UBvBS/Inb4mliF+cSnvi9SNPEoiE54W54dlXYLBNdml9v9sSi4kx0q9fcWe69914699xzaePGjTRnzhxavXo1/fSnP+WTiW7ZsoVuuukmSktLs3qYAADgYt8EOphPHZpNSQmay0iaxcfH0Y2Bwvkry/dSY7MoBw4M8cPuY1Tb2EK9slJpVB/jMu3B3cb183ei7z1aQ0erG8jrNHeiL168mOyCfXh48cUX6YQTTrB6KAC2gZIEuJ3bJhbVW2zWV5T3WVZs1VvMD4lzccFz65R1jeXZTOLloxNdn02bNtE//vEPGjFiBD300EP8rM/HH3+cLrzwQquHBgAAHrFAlIdulgtP7E1//WY7HalsoE/XF9Ol+Tmm3ZeXD4Swrn8jM+3B3bI6JNGQHum040g1z0U/e5S3z2Iw/hCiyaqrq+kXv/gFvfzyy9S5s/+ICIBXSYoSqEqAy0kLfs7f3o3uHDezSKmn2CopuGtZts26s81kt677WJ7NJFm+C16/sXT8+HHq1q0bv8w6zlm04qhRo6weFgAAeMSe0moes5KUEEenDO1u2v2kJCbQdSf355dfWroHn28NxB7LBVvNPxAC7jSeR7oQrSkqI69zXBH91ltvpfPOO49mzpxp9VAALCeZqM3SkQCYz21xLmLG1BRN7NSXPPZ6OtG1TCwq/3u3Pbtt5GvW2uqd15R4+fhMrB+LbWFxLuyLvUZYxKLws/AFAABg5mSUJw3oShmpSabe188n9aOMlETaVVJN324rMfW+vGTDgXIqrWqg9JREmjTA+Ex7cLf8XEwuGtXEolZ7//33ae3atTzORYuGhgb+JWATMgG4iaTWhKIEuJx0Ik5yPMPjXCSLMHhiUR0Fej239d/GBU+mQzvRjd4Gw9+XN59zo5x++umSx41NNMqw07HZ9ex7S0uLhSMEAAC3F9HPjEEHc2ZqEv38pH704pI9NG/JbpqJrmlDn8MZQ7vzjn8APSbk+Q+8bC6u4BPUpiZ5dxtyTBF9//79dOedd9L8+fMpNTVV09/MnTuXHnzwQdPHBmAVcVECE4uC25mZ+W0Fwyf/NLHTV1IANfC2Srdx81uZ7TLRY5iwIo2OMfe+3Gbv3r1WDwEAADyKTSS4Zp+/+zRWBe3rpvan15YX8q7XgsIyyg8U8MAZB0LAfXK6pFH3jBR+NsPGAxU0sb93X5OOKaKvWbOGSkpKaNy4ccHrWMfN0qVL6bnnnuMd5wkJ0qMh99xzD82ZM0fSiZ6Tg8kpwD0Q5wJe4rZIZaMndZR26hvcia6ji1iaze5zXHe2mey23cayO9zNcUxmy83NtXoIAADgUd9uLeH/h4/qk0m9stJicp89MlPppyf2oQ8K9tOLS/egiN5OhUdraGdJNSXGs0z7bKuHAw7EznhkkS7/23yYCorKPF1EjyoTfdmyZXTllVfS5MmTqbi4mF/31ltv0fLly8nM01g3bdpE69evD37l5+fzSUbZZXkBnUlJSaHMzEzJF4CbuK2oCKC5SEzOZ/SkjmamO+k5YCeZWFTTQOzVnW0mu3XdxzIiSbpduPhJBgAAcJFvAh3MZwzvGdP7nT19QLCDmuWjQ/SECUVZFnpWmrmZ9uBe4wO56GsKvZ2LrruI/vHHH9NZZ51FaWlptG7dumDmeEVFBT366KNkloyMDBo1apTkq2PHjtS1a1d+GcDrEOcCbift3Hb+9q439iQSSQe4wXkZeuZf0NsRL7+Jq6M+ZCtrddd9LKfVwEFfAAAAZ6lrbKHlu0r55TNiHAMyKDs9eJ8vLd0d0/t274EQRLlA9IQzQgqKjhv+WdPVRfRHHnmE5s2bRy+//DIlJbUdxZo6dSqf9BMAYsdtnbkAdi3CbT9cRc8v2sUnUjGMwXMamNqJruO9Ru/zFNqd7d53M7t1osd2YlHxNuTe5xgAAMAtlu86SvVNrdSnUxoN75UR8/u/aYa/G/3f64rpSGV9zO/fDcpqGnmuPINJWqE9RvbOpNSkeKqoa6Ldpd49O0R3Jvr27dtp+vTpIddnZWVReXk5xdLixYtjen8AdqMnpxjA6aSRIrHd3s96ein/3tDcSnPOGGLIMiXrYHAmutEPj56zAHRPLBqSie5edlvXmE4sKrrs4eYVAAAAx5i/5TD/zjrCWSZyrI3P7UIT8jrT6sLj9Op3e+mec4bHfAxO9+22Er7fNbxXJvXt3MHq4YCDJSXE05i+nWjl3jLejT64R+wPrDmyE71nz560a9eukOtZHvqAAf4jhQBgxaRwVo4EwBvb++biCtvGuUiXbeLEojruW1uci80qyyaSr6vVBz9jmVMey/x1AAAAaJ+WVh8t3FrCL59pYQfzjdMH8u/vrthHlfVNlo3DDQdCANprghDp4uFcdN1F9NmzZ9Odd95JK1eu5EcjDx48SO+88w799re/pZtvvtmcUQJAuyf7A3A8GxTRE+Lj7DuxqIlFeT0FUL0dxyERJy5+NwtdV/uIZSY65vCIzpEjR+iqq66i3r17U2JiIiUkJEi+AAAAjLJu33E6VtNImamJNKG/v3BmhdOGZdPg7HSqamimd1fus2wcTsRiKJfuOGr5gRBwj/F5gclFi/wRQV6kO87l7rvvptbWVjr99NOptraWR7ukpKTwIvrtt99uzigBQBGKEuAldjholJRgYBFdfNln8ONj8AMk7Zr36chP1z+xqJvfyuy2rlZlokN0rr32Wtq3bx/dd9991KtXL0tOrQcAAG+YH5iM8tRh2TzGwSrx8XF0w/QBdNdHG+nV5Xtp1tQ8SknEgWMtvtt1lOqaWqh3VirPswZor3H9OhPb/Sw8VkulVQ3UPSOFvEZ3EZ3tsP/xj3+ku+66i8e6VFdX04gRIyg9Pd2cEQJAzIpwAHZmhzkAEuKN+xAh7Rw3thPd8DgXlfuJHBGiZdmyiBNyr9B1szjOpbXtstkvKfGBmFaEokeFRScuW7aMxo4da/VQAADAI0V0O8SAXDi2D/31m+10pLKBPlt3kC6dkGP1kBxhwdYjwQlFceAdjJCVlkRDsjNo+5EqWlN0nM4e1ZO8JupqQHJyMi+eT5w4EQV0AKvYLF8XwEySQq5FY0g0K86l1YjliS63f3HRx7nojd2xWXd2bDPRLRuK//5FD77ZdW07vH6dLicnB//PAwCA6XaXVtOeozX8DMwZQ7pbPRxKToyn60/uzy/PW7obB+M1YI/RgkCmvR0OhID7Il0KCr0Z6aKpE/3//u//NC/wk08+ac94AKA9+bo+draIRYMBcNEkiDEpohu2JGF5JlbRxfcT4bHXE/3iv438Z+98MLJ6TfU+V3aaA8CLnn76aR6r+OKLL1JeXp7VwwEAAJd3oU8e2I0yUpPIDq6Y2I+e/XYX7Smt4R3WZ470XgesHusPlPO4jYyURJrUv6vVwwEXyc/tzOcnKCjy5uSimjrRs7Kygl+ZmZm0cOFCKigoCP5+zZo1/Dr2ewCwMF/XqoEAxIDuDmcTJBqZiW5w/IqZcS6SAxgRx6EzzsVTnejhf465GL6m7PD6dbrLLruMFi9eTAMHDqSMjAzq0qWL5AsAAMBtUS4CVsy/8qRcfvnFpXusHo5jnsMZQ7vzTn4Ao+Tn+vc5fzxYwSev9RpNneivvfZa8PLvf/97uvTSS2nevHmUkOCf0KGlpYVuueUWXmAHgNiRF8rYzwmEVnRwP+viXIzbCdWbHW5lXIaeAqj411qK+d7KRA99z/bK2R12OJPEDZ3oAAAAZmLdy2v3+TtMzxhunyI6M2tKHr2ybC/PYl5dWEYT8nAA2UkHQsAdcrqkUXZGCpVUNdCG/eU0aYC3znTQPbHoq6++yic2EgroDLs8Z84cmjJlCj3xxBNGjxEAdMS5ALiRXbKkE0yKczEkSsPEiVf1jFWcU+mLqjvbvW9kdutElx7wMPm+YpM25GrXXHON1UMAAACX+3bbEf5/9gl9s6hnVirZSXZmKv3fuD70/ur99OKS3Siiq9h7tIZ2lVTzGMpThmZbPRxwmbi4OMrP60xfbjrMI128VkTX3VLX3NxM27ZtC7meXddqxMxoANCOOBeUJsCdrNzWxUVhNsGSORnR9p4kUk8nuiRnW0ucS5j7chu75b8bfTaE1vuyugPfSSorKyWXw30BAAAY1cE802Zd6ILZ0wfwOcDYpJk7j1RZPRxbmr/lMP9+0oCulJVmj0x7cJfxgUgXdlaI1+juRJ81axZdf/31tHv3bpo4cSK/buXKlfSXv/yF/w4AYickBgF1CXApedEtltt6Y0vbAeLEhHjbZkSb+ZjoykQPeV/y8Y4F1duHPLfufSMLWTWLV1V8wMPswjYy0aPTuXNnOnToEGVnZ1OnTp0UX0vCa4zFKwIAAESrtrGZlu08ausYkIHd0+nMET3o6x+P0EtL99ATl4yxeki2s2BLia2fQ3DH5KJCEZ01nMUbeLa264rof/3rX6lnz5705JNP8p16plevXnTXXXfRb37zGzPGCABqbBYNAGAWK2uPkiK6kXEukpUwYGLRkOWHL15HfT+RMtEV3pfCDcNmdWVT2S7/PYb/aZh5poSbffvtt8FJQ9llM17TAAAAzPKdR6mhuZX6dk6jYT0zyK5unDGQF9E/XV9Mc84cQr2y0qwekm2U1TRSQVEZvzwTRXQwyYjemZSWlEAVdU20q7SahvSw7/uF0XQX0ePj4+l3v/sd/xJOHcWEogDWsFs0AIBZrMzNbmxuK6LHG1jAMrqoKH9M2DKNSp+RLjtCJrq8szziwuX3Ra5lt0z0WHaiS2J+8H+VZjNmzKC9e/dS//796ZRTTrF6OAAA4JHJKO180HZcv840sX8XWrW3jF77rpD+cO5wq4dkGwu3HuH7XCN7Z1KfTji4AOZISoinMTlZtGJPGRUUHvdUET3q89JLS0tp48aN/OvoUf8pPwAQW+KsZv4z6hLQDv/bdIjmfLCe6pvsFwlgZXSRuIhuZPFeGm9hTie6FVEc8t9HKs7arjvbRCHRNQav7bHqBrr9vXX0/S5t+2Xi+zf7NSVZdzc/ySYYOHAgL6Jfd9119Pbbb9OBAwesHhIAALhMS6uPvt3mnBiQm2YM4N/fXbmPd8NC6IEQADPlB3LRhTMfvEJ3Eb2mpobvxLMIl+nTp/MvdpnlpNfW1pozSgCIedEMvOeFJbvpk3XFvKvDbqycWFRcRG8x8DUmnWix/csLLV63f5lKy/IZnF9v5VkGbutEf/DzLfT5hoP083+u1HR78XzwZr+mxOuKiUX1YTEu11xzDe3Zs4dmz55Nubm5NHjwYLrxxhvp/fffpyNH/B+YAQAAorV233E6VtPIJ6KcmOcvjtnZKUOyaUiPdKpuaKZ3VhZZPRxbYI1QQqa9XSeGBffIz2vLRfcS3UX0OXPm0JIlS+jzzz+n8vJy/vXZZ5/x65CJDhBbZhbNwHuEYnGTKAPcLqyMwRBnohv5GpMEpJjRiW5gUVTasRwpzkXfOLz0vmV2/vu+Mn3NDL4YPg/S7d3c+3IbFuPywAMP0OLFi+n48eM0f/58uuKKK2jr1q107bXXUu/evWnkyJFWDxMAAFzQwXzasGxKTIg6sCBm2ESGN0wfyC+zSBc7nklrRaZ9XVMLj3FhcS4AZhqX25nPe1V0rJZKqxrIK3S/O3788cf0yiuv0DnnnMOz0NnXueeeSy+//DJ99NFH5owSABSFFKdQmIB2nsZp16KmXeJc5BFK7WF4uoXODvBoFx15sXo70a17bmPN7K57vUsT37/Zj7vRZ154VWpqKp122ml077330oMPPkh33HEHpaen07Zt26weGgAAOBTbHxCK6E7qYL5gTG/qlZXKC3ifrismr2t7DrNtnWkP7pCZmkRDA1noazwU6aK7iM4iW3r0CH1jzc7ORpwLgIciLsB9hKgSO0YthG7rsdMgLqIbmjNubgHT2CK69rGKI0K03N5LEySbnf+utygv3p7NjtGR3JeLn2OzNDY20tKlS3nh/NRTT6VOnTrRTTfdxDvTn3vuOT75KAAAQDR2l1bT3qM1lJwQTzOGdienSE6Mp+tP7s8vv7R0j6HNLk7D1n3hNiEPvafVwwGPGJ/rj3Rhk4t6he4i+uTJk+n++++n+vr64HV1dXV8p579DgCs4+H9BjCAsONpxx1QK/P/JZnorV6NcyEdcS76Js+0Mqon1kLWzeB11XuQR8+Ese0Vy/tyG9Z53rlzZ7rllluopKSEZ6Hv3r2btm/fzs8Eveqqq6hfv35WDxMAABxq/hb/hKKTB3al9JREcpLLJ/ajzNRE2nO0hr4JdGJ70br95XS0upEyUhNp0gD7Z9qDu3LRV3soF133O+QzzzxDZ511FvXt25fGjBnDr9uwYQM/vfTrr782Y4wAoDkGAZUJMKITney/rZNVmej2jXMxsxitZ6zy30fenqQ3sOP2ZxSzu+7lZwHoi1iJ3cSi+L9Kn2XLllGvXr14MZ3lo8+YMYO6du1q9bAAAMAl5m85zL+fMcI5US4CVvS/anIuPb9oN81bspvOGtnDk1EmQpTLqUOzKckBmfbgDvm5/gM2PxZXUF1jC6UlJ5Db6X51jRo1inbu3Elz586lsWPH8q+//OUv/DpMagQQW6ET+AG0vwBnxziXkG3dok50Q4voolesEcuVF2TNGmvEOBedB/c8FUtlcv677k50lctmEG8Hbj5QYoby8nJ66aWXqEOHDvTYY4/xiURHjx5Nt912G5+PqLS01OohAgCAQ7E8cdbF7NQiOnPNlDwe7bJ+fzmt9lCshFsOhIBz9e2cRtkZKdTc6qMNB/zvI24X1bk6bCd+9uzZxo8GAGxTNAMvTyxqw+3IwsgPaZyLz5SuYSPWx8zcePFq6y+K643qIdfS36Wvc/m+6G9v9utesg25+UCJCTp27Ehnn302/2Kqqqpo+fLltGjRInr88cfpF7/4BQ0ePJg2b95s9VABAMBhFm49wvcHxvTNoh6ZqeRE2Rmp9LNxfem9Vft4N/rE/t6KM9lTWk27S2soKSHOUZn24HxxcXE0Ia8LfbHpEK0pOk4nDXD/mZK6O9HfeOMN+uKLL4I//+53v+OTG02ZMoWKioqMHh8AWJivC95i64lFTZ6QMZzGlhbLu7sdFeci77aOEDFiw83NNKHPkbErr7c4LdmeTX4epNEx5t6XF4rqXbp04V8sKz0xMZG2bt1q9bAAAMDBMSBO72CePa0/sRSXb7eV0PbDVeTF55AVMDNTk6weDnh2ctEy8gLdRfRHH32U0tLS+OUffviBnnvuOd4F061bN/r1r39txhgBwKKuRvDqxKJkO1ZOPimJczFyYlGDO3PNnHxVX5yL+t9GWrZ/+e59IzP7YJDeMyVi2YkunZzW1LtyndbWVlq1ahXf3z7nnHOCzSv/+Mc/qGfPnvT888/Tnj17rB4mAAA4TG1jMy3fdZRfnunwIvqA7ul09sie/PJLS731f6JbDoSAsycXXVN0PFhPcDPdcS779++nQYMG8cuffvopXXzxxXTDDTfQ1KlT+WRHABA7nsoShph1ogvfvTQho+Y4F7MmFjWkE93EvG0dBX+98SxWHiCJNbPXVe/yxIXzWGaiu/lAiRlY0bympoYXzE899VT629/+xve5Bw4caPXQAADAwZbuOEoNza2U0yWNhvbIIKe7YfoA+t/mw/TZ+mL67VlDqFeWv/nTzY5VN9Caff4c+JnDUUSH2BveK5PSkhKosr6ZdpVW0xAXvJcY2omenp5Ox44d45e/+eYbOuOMM/jl1NRUqqurM36EABCGuZPUgbcIXax2LHCFTlYZu/tmHy6C42i178Siocs3jqTYqnNi0Ujr5qVUqtB1MzrOhdrRiW7oUMLelw3fYmztiSee4HEtxcXF9Pbbb9P111+PAjoAALTbgq2BDubhPXm2sdOd2K8zTerfhU9y+MqyveQFC7eV8P2qUX0yqXcn9x80APtJSoinsTmd+OXVHoh00V1EZ0XzX/7yl/xrx44ddO655/Lrf/zxR8rLyzNjjACgQl6IsGOWNTgwzsWGm5GZk2ZG0tgiKqKb1Ylu8PKsHGtIR7ze29tw+3NKJ7re5zyW3eHSTHQXP8kmuPHGG2nIkCGmLJtFwbD9d9YMM2nSJB4bE86HH35Iw4YN47cfPXo0ffnll8HfNTU10e9//3t+Pctt7927N1199dV08OBBU8YOAADta55h+eFuiwG56RT/QWY2yWhFbRN5JspluD/KBsDSSJdC/1kRbhYfzc725MmTqbS0lD7++GPq2tU/++qaNWvoiiuuMGOMAGDD7lxwcZyLDavoIREiMdzYG5rEcS72zYgOzRZv/zLblq32g8Jt2/lUuTmWyuxMdN1FdPFlszvRVS6DdT744AOaM2cO3X///bR27VoaM2YMnXXWWVRS4i+qyH3//fd8X591wq9bt44uuugi/rV582b++9raWr6c++67j3//5JNPaPv27XTBBRfEeM0AACASll9cVtNInTok0YRAAcwNThnSnUfT1DS20Nsri8jN6hpbaNnOUtcdCAEHTy5ahCK6Yi4jm0z0s88+o7PPPjt4/YMPPkh//OMfjR4fACg4Wt1A5zyzjP5VcMDqoYCLCJNm2jHORV51M7vOv/doDZ35tyX06bpiaSe6xjveXFxBM59aQgsC3SHaDoJpW3ZDcwv97IXvae7/tsr+3rxitJ5JUPWul5cy0eUP3S3vrKWnvtke/Lmkqp7OfnopvfZddKcg6534VpqJbnInuui14+rn2EGeeuopmj17Ns2aNYtGjBhB8+bNow4dOtCrr76qePtnnnmG7/vfddddNHz4cHr44Ydp3Lhx/HMBk5WVRfPnz6dLL72Uhg4dSieddBL/HWu02bdvX4zXDgAAwpm/5TD/ftrQbEpM0F0Wsi0WS3PjjAH88mvfFVJ9Uwu5FZsUtr6plfp0SqPhvdydQw32Ni63M7FEqH1ltfzzDHl9YtGNGzfSqFGjKD4+nl8O54QTTjBqbACg4tmFO2nrocqQ63GKPBjRiW7DRnSFySrNHeTvP9pIO45U068+WE/Xn9xf92tsyY5S2lVSTV/9eJhmqnSGKBWPtcRRsuWy7iG2k3LPOcPb/j7C8mOXiS4bh8Xd2XaitG4fry2mOWcO5ZdX7z1O2w5X0afrD9Ksqf31L1/nky5+rvQW4NuXie7mZ9kZGhsbeXH7nnvuCV7H9vNnzpxJP/zwg+LfsOtZ57oY61z/9NNPVe+noqKCFzRYE46ShoYG/iWorAzdtwGwQ7fnH/+9iYrLMf+XID4uji6fmEMXju1j9VAgCuz/4WAMiAs7mH8ypjf99evtdLCinj5ZW0w/n9SP3HwghD2Hbsi0B+fKTE3iZ4CwzzEs0uWc0b3I00X0sWPH0uHDhyk7O5tfZi9Q8Qcg4Wf2vaXFvUf6AOyCHXFWgroEtIcQ42LHOJeQ7maT76+yvi1DsVE0sajWx6Yp0L0e/vahE3DGU+QdYGGZ8q74WGWLR844J30Ti4YcTLDf9mcUpXVrFlWvaxub+fe6wHe99L509Zxh0F6Ic7GXo0eP8n32Hj2kxRP287Zt2xT/hn0WULo9u15JfX09z0hnETCZmZmKt5k7dy4/mxXAzt5ZWUSfrCu2ehi2w866O3VYNi+egLOwhozCY7WUnBBP04Z0JzdOdHj9tAH08H+30MvL9tBlE3IoId5dRWb2eWDhVvdl2oOzc9G3Ha7ikS6eL6Lv3buXunfvHrwMAPaETnSIlrgga8ftKNaRH+Lit7iIrrVIqeWAhN6O7ZBlRziwYGyci/YJKPUW870U56K0bk2ioP26wCnHtY3RNSTofc6lzyuZChOLegubZJTFurBt7IUXXlC9HeuEF3e3s070nJycGI0SIDK2D/DKcv/n39nT+tPYHPdkR7fHU/O30+7SGnp35T66aYZ/Ikdwjm8CXehTBnWl9BRNJSHHuXxCDv194U4e0cg6ts8e5a6i3vr9x+lYTSNlpibSxP5drB4OAOXndqG3V+xzfS66pnfM3NxcxcsAYA21s7VQloBoiQuydqxvhRaIY/d4SDLRNT44zRqK6NEWj4UxhCzbxNx4PV3Ees8aMLP4bze+MGctCJEBTLT5nbo70dvxt+2LczH3viCybt26UUJCAh05Ip23gf3cs2dPxb9h12u5vVBALyoqom+//Va1C51JSUnhXwB29fmGg3Soop66Z6TQb84cSqlJCVYPyRbYmVN3fbSRXl2+l2ZNzaOURDwuTrJgq3ujXAQdUxLpqpNy6blFu+iFJXvorJE9XRV5IhwIYWeDsM57ALtMLvpjcQX/TJOW7M7/F6J6tW3fvp1uu+02Ov300/kXu8yuAwCLi+goTECUxAVZeYezHYR2N8duEsRo4ly0dKLL10FrgV6ouYbEuURYfqwy0eW/jjQZa6xiaOxAad2aRZ3oQgd61J3oujPRYxeygk50e0lOTqbx48fTwoULg9e1trbynydPnqz4N+x68e0ZNpGo+PZCAX3nzp20YMEC6tq1q4lrAWAu9p764tLd/DIrFKOA3oZloffITKGSqgb6bN1Bq4cDOrBJ/9bvL+eXZw53bxGduXZqHiUnxtOG/eW0cm8ZuYmbM+3Bmfp2TuP/L7BmMuE9xo10F9E//vhjPskom4xozJgx/Gvt2rX8OvY7AIgF5Sq6m7OEgTxd4Ir1kIROcqahOYpO9EBhVLwcuWg7f1XjXEwsRuvJLW9PN7TSz26i1GUv7kQXOtBZrEs07+ftyUQ3vRNd5TJYh8WovPzyy/TGG2/Q1q1b6eabb6aamhqaNWsW//3VV18tmXj0zjvvpK+++oqefPJJnpv+wAMPUEFBAW+mEQroF198Mb/unXfe4ZnrLC+dfbGJTAGcZvH2Uj7JeMfkBPrFJJyNLcYKk8LE6+xAQ6QD5mAfLEeb/f8/JqcT9chMJTfrlp5Cl4zvyy+/uMR/QMwNdpdW057SGkpKiKMZLsy0B2eKi4vjkS7MmiJ3HbQS0x2A9bvf/Y7vUD/00EOS6++//37+u5/97GdGjg8AFCDOBYwm7pi2YQ1d92SVhnaiRxXn0hrx9vKCqtZlC7cTzUcZWJ7sZ5PiXIRlq58Ro7OY7/FMdHagRZicXehAZ7djB2/0dj3qfV1IzzAw94HXk6sPsXHZZZdRaWkp/elPf+KF7rFjx/IiuTB56L59+yg+vq3fZsqUKfTuu+/SvffeS3/4wx9o8ODB9Omnn/JGGqa4uJj+85//8MtsWWKLFi2iU045JabrB9BeLwSKbj+f1I+y0jB5ptwVE/vRs9/u4tnoLB7kzJHKUVBgzw7mMz3SwTx72gB6b9U+WrS9lLYdrqRhPdUjxpz2HJ40oCtlYGJfsNnkol9sOuTqXHTdneiHDh3inSlyV155Jf8dAJhPLc0NdQmIlrggqzWyJJbkBWfTJxYVZ6I3t+h+bIQO9HCd6NEWj9U70eWLN+5BCl229ttGKuyGPLcePBwobCfiGJdoIl30dgLGshNdvHz8X2UfrIucZZc3NDTQypUradKkScHfLV68mF5//XXJ7S+55BIe4chuv3nzZjr33HODv8vLy+MHSJS+UEAHp1m77zit2lvGOz2vC3RcgxQr3l15kr9D/8Wle6weDmhQ09BMy3cd9VQMSF63jnROYFLRl5a4Yzv12oEQcI78QCf62qLjrj1DSXcRne0EL1u2LOT65cuX07Rp04waFwCEodYBascYDnAGcUHWjtuRniKuEUTN55JMdK37Ai2BOJdwOw/RxpgIz5W8oG/mgQY9mfS6Jxb1UJ6L2uMmxP+IJxRlkS76lx/9eMx+2H02f48BABATim0s+7tXVprVw7GtWVPyKDkhntYUHaeCQveevu8Wy3aW8v3afl060ODsdPKKG6YP4N//s+EgFZfXkZOVVjXwg3zMTBTRwWaG98qgDskJVFnfTDtLqsmNdMe5XHDBBfT73/+eZ6KfdNJJ/LoVK1bQhx9+SA8++GDwNE7htgBgvDjVTPSYDwVcQlyQteNRYzOjSpS0iFrzJXEuujvRZZkrIvJCouY4F9lzFR8fZ3rkjZ6DGCFF9Iid6NqX7XRq68a2sTRKoNrG5uB1daLL5sW5iMZmdkQSOtEBwEF5w19vOSwpvoGy7MxU+r9xfej91ftp3pLd9M88fxci2NM3oskoWYycV7D898kDutIPe47Rq8v30n3njyCnWrTNn2k/uk8WDvCB7SQmxNPYnE70/e5jtLqwjIb2zCDyehH9lltu4d//8Y9/8C+l3zHsTZlNKAQAxkMnOpg7sSjZTmh3c+wKfuJOdHmESsRM9FY9k3XqP+DBxhMfOKhmZre+ni730GJ+hGWHPA423AANorZqzYEDNeLu87rGVv3L13372MyFIH9O7fgeAwAg+OeyPfw98fRh2TSkh/sKAEabPX0AfVCwnxZsLaGdR6poMB4zW2L7GqwA66UoF7EbZwzgRXSWj377aYOoU4dkcvqBEAA7ys/tzIvo7AwlIfLL03Eura2tmr5QQAcAcGgnug2LmNEWnA2ZWDSKOBctneghi4qmiB4uLsbQOBfZz6TnfvVloru5wKr2uAnbS50kEz22nehmvu71bhMAAFYpqaqnj9cU88s3nTLQ6uE4wsDu6cFs5peQjW5brKB1vLaJOnVI4kUur5kxpDsN65nB55x5e0URORHbT1y+q5RfRhEd7Gp84IykgiJ3RnzpLqIDgPUwsSgYTd7dbD+xHVOzWhFdY4VXyEQPfDM0zkX8/IifNz255XrJVzvcokPjXIxbttOprZuwjdW1MxNd9wGIGEWsyBft5gMlAOBsr39XyCO2xvXr5MlCY7RunOE/4PDp+mI6XFFv9XAgzGSUpw3L5pELXsOSEm4KbKevf18omYfGSZn29U2t1LdzGj8gAGBHJ/brxJMT9pfVUUml+/4/0Pzuee6551JFRUXw57/85S9UXl4e/PnYsWM0YoRzs6Wsxt7E3XwKOxhLLcPOjh3ESpy40+ImrBDc0Nyiuu3YcTMKiQjRUIVT2s4q6proUEVdxPdbcaFakomuOc5FmPwzXJ5L2B91H/AwM1tcT3yO7oJpjKN6rOSLsL2w7iiBuCtd8/J1d6LH5gwUpZx8o/4f0Loc9ngeOF5LR6sbDLlfAHCfqvomeivQocqKwl7KjG6vcf0608S8LtTU4qNXv9tr9XBAhv2/O3+rv4gunDXgReed0Iv6dEqjo9WN9NGaA+TUAyFey7QHZ8lMTaJhPTP55YIi/yS4niyif/3119TQ0PbB49FHH6Wysrb2/ObmZtq+fbvxI/QA9oFuwp8X0Jx/bbB6KOBwTig9PfbVNhrz4De040iV1UPxrFmvr6aTH1skiYtw3MSiEW6/q6Sab2ePfrk1eN2qvWU0/uH5NHnut3TLO2vD/r34MWgQZ6Jr7UQPFM9F9XcNMSY+/YVPSSe6bPnGVtE1L1tvfn3Ic2u/zS92meiSOBfzO9ElB89031t098Ms2l5Kw+77itbvb2vGiMb2w1V8Ofd9ujnibb/bdZS/713/RkG77hMA3Ov9Vfupqr6ZBnTvSGcM926hMVo3neKfhPXdlft40wLYx86Saio6VkvJifE0bXB38qqkhHj65bT+/PLLy/Zo3q+3AzbWb4VMe7w/gc3lB87kKij0cBHdzNPEvW53STXfYWvvh0nwDrUDz054Xa4tOs6LklsPVVo9FM9au+84lVY1UPHxOsUilx3jXPRGhLDti21n6/a1/ce9qbgi2PEb6f1WLTLFyE706CcWFV/2tbsoH91BDJ9h8Sw23NxMpLyywtkO7Y9z0fdg+mL0/4faov/yv7aDXNF49tud/LvQORqOMD9BYjw6twBAOVbrleX+Duobpw+geLxX6HbKEDYRazpVNzTzQjrYr4N56sCu1DElkbzssgk5PBeeHVT4+sfD5KTPb8dqGikzNZEm9PdnTgPYVX6ev4i+xoW56N4Lw7IhoVjjpCOhYK04lVR0J2xCQpEH27t1hO5lce63uDBrx6Kmnokt1bYzcdd2pO1PfH/SIrq28Ta3hD7GoWOU3afGXmDJeoSJ4THyedR1EENn1ruXDtKrd6L7+HpLiuhRxblEf3tTM9EjZMFHKyUxQfNthddiAgpjAKDgM5blXVlP3TNS6KIT+1g9HEdiBx5umO7PnGaRLohvtI9vgjEgPcnrOiQn0tUn5fLLLy7Z7Zj9zgWiTHvWUQ9gZ+MDneibD1ZKzn53A82vPpa5JM9dQg6TMYRGRRQVQSv1l579t6G2Dl37j9WthOdAKPRG220dS3oLxM0KE3s2R7mO4ptqnlg0cLtwtw8tHmsbj7hwLm5019Mt3v6DGGRcJ3qEnz1RRG9t5WdOiH8fTSe6vrGYd+ZCyH2pPKssO7c92GnpWgmvyaQE7LsCgBT7v/qlpXv45eum9td1gA6kLhjTm3plpfIzHj9dV2z1cICIT+y3IXAG5szh2VYPxxaunpJHKYnxtOFABf2w5xg5Kw8dB0LA/vp0SqOemal8/9ttiRuJej5sXXvttZSSksJ/rq+vp5tuuok6duzIfxbnpYM+wgdXpxwFBeuplQCcUJcWiop2LNR6hfDYC/EG4uvseoBDXoTzaSw0i4vY0kkUtd93NFE3wmMbrhM92izwFgs60UPH6jMuUsTEcdtNuGKyPAM9mkx0Mbbth4sjCD0TwjxqL4OmcJMGaMA+AGslHFhLiEf3FgBILdpewjOj01MS6Rcn9bN6OI7GDm5ef3J/euSLrfzAxKX5OYjGsdiCrf4c7bE5nSg7M9Xq4dhCt/QUvm2yOLgXl+yhKQO7kZ2xuZ72HK2h5IR4mjHUu5n24BxxcXE0Pq8zfbHxEK0pPG7715gemj9JXHPNNZSdnU1ZWVn868orr6TevXsHf2a/u/rqq00b6Ny5c2nChAmUkZHB7+uiiy5yzUSmwTgXN1cOICacsAm1daJbPRLvUjobIJrIEku37Qgbu7A+4vVS67zX1fmtMxNdVyc6tW9iUXkZ1NAieshYw92W9MW5hPxsww3QIL4wxWT5qY517Tz1UX+MTrvuTtd9GRbnkqS/Ex2Z6AAgx4pozC8m9aPM1CSrh+N4l0/sRxmpibzoN3+rv3sWrDN/iz/3+4wRmIxSjE0wynYJluwotf1cXUIX+uSBXfnBPgAnmCBMLlrkrslFNb8CX3vtNbLSkiVL6NZbb+WF9ObmZvrDH/5AZ555Jm3ZsiXYDe9UQhEERUXwwsSiweKmA8bqRuz9Rnjom1U7mu333OiJE5EUsVW6yLXGssjvO8w8oboz0UOLzdqWrXbwQ29uvFnd4nongY1lMddqvjDbizw7tr1xLpG2p9DYHfMeeLWxCBOqRitFRyZoU+DFi0x0ABBbU3ScVhWW8ainWVP7Wz0cV2BFvqtOyqV/LN5N85bspjNH9EAMrEVqGprpu93+uBL2PECb3K4d6ZzRvXinLMtGf/ryE8mucCAEnCg/r0twUtxIZ8g6iWPOaf3qq694nMzIkSNpzJgx9Prrr9O+fftozZo15HTCh0s7Fq7AnuJVdkTt2EEcTVY0mEdcSBZ3ZuuZdNMK8oJwpC7btoOT4vVSjq/RQ+tjE9zOw9yPnogUtTFIDn7Ibmfk0xgSpxNuvdoZE2K/rS9WnegGx7lEeo3oOLvAvp3oCZqXhUx0AFDCimfMT0/sQz2zEHVhlGun5vFol3X7yml1obu6EJ1k6Y5S/v9jXtcONCg73erh2M5NgYlwP994iA4cryU7YvMLrAtm2qOIDs4xrGcGdUhOoKr6ZtpRUkVu4ZgiulxFRQX/3qWL/+iGk6EzF3RT60R3QPlJKWYDYkcSbyIqKjstziXixKIK76tqnfd6tBqZiR5lFrhanEtoR7c1neh6D3iELtuGG2AMMtHrZEVzeWe62ROFmjqxaJiDB+3BskG1du4jEx0AlHKGhbiRG6YPsHo4rpKdkUo/G9dXcqACrIsBYcVXnA0QanTfLJo6qCv/HPTK8r1kRwu3HuH7USf0zcKBPnCUxIR4OrFfJ365wEUHUx35SaK1tZV+9atf0dSpU2nUqFGqt2OTnVZWVkq+7Ej44IqiImgVp15Ft73ghI8uLpTZmVoUiO3jXCL8rDqBrfjggAEHCrRut1oOFumNPWlbtuiyjk739tDTXR4aExJh2SZmuduOT/2gS21T+zrR5dta5DiX2D3uaq8bdvCgPcSnhcoPQsghEx0A5F5euoe/97EC46DsDKuH4zqzp/XnEZQLt5XQ9sPu6UJ0iuaWVvp2u39SUcSAqLsx0I3+/qr9dLymkexmQeBA3xnoQgcHGp/rb3ouKCwjt3BkEZ1lo2/evJnef//9iJORChOfsq+cnByyI+HDpasLB2AotUYCJxyHEboBcdDIGuLOaPFlcda3Hc+K0ZubHakTPdo4Ia3brVAcDHf70AMD2pYtyXkXd6LLl2fg8xhacA3XYa/vkEe0HflOpLZqSp3oeovo8rMeIm2r0WbyR0Nt0e3NRBe/juUTs8ohEx0AxI5U1tO/1xXzyzfNQBe6GQZ0T6ezRvTkl19a6p+8FWKHTeZXXttEnTsk0fjABH8QatrgbjSiVyY/o+2tFUVkJ2zfZtnOo/zyGSNRRAfnyXfh5KKOK6Lfdttt9N///pcWLVpEffv6TxFTc8899/DYF+Fr//79ZEeItwC91EoATohzCZ554eZKmY2pZZ9LJt204VMT0t0cYVsXtjPxwYFWQ+JcjHtfD43f0Lds+fqZWYzWUxbXW5yN9mCCE6kdfGDdYkIRXeiU1hvnIi+iRzqIoufAiFmd6O3NRBe/jiPFubQEDmyhEx0AmNe+K+QH8tgHfGHyMzDejYEDFJ+tL6ZDFXVWD8eTUS6nDevBYxVAGYu5EbbT178v1L3/ZSZWQG9obqWcLmk0tAfOlgHnObFfJ2K73geO1/GD127gmHdT9uGOFdD//e9/07fffkv9+0eePT0lJYUyMzMlX3YkfAZEvAW0lx2Ln2qFHkwsag1xoU2cRyyNOrHjc6MjT0TljAfxurNVjKZoqHW7DXbC68pE1xcVEymGx9Q4F59xMSHoRA9MLBr40Na5Y3J0cS4teuNcZGMzsxPdpGWLXwuR4lyE12QiJhYF8Lyq+iZ6J9BxeuMMf5QDmOPEfp1pUv8u/D34VZtmTrsR2ycUiuiIconsvNG9qE+nNCqraaQP1xwguwg+h8N7ItMeHCkjNYmG9cx0VS56vJMiXN5++2169913KSMjgw4fPsy/6uqcf0Rb+BBoz8IV2JFaF60ds6zVipDtPIsfoqQWBSLtbrbfdqQnk5tpCbRoSzvso+v8lv6N1kJ36P1HzAKPYgxKcS7CPraRz2NogV5HTE2kiUWjfBycSH2CTR/VB4rAXQNF9Eid1XLiiYI1nd2m8+yO9jDrvybxNh6xEz2Yie6YXV8AMMm7K/dRVUMzDcpOp9OHZVs9HNe7KXCggj3uFbVNVg/HE3YcqaZ9ZbWUkhhP04d0s3o4tsc69VmGvzBXAjtD0Gpsv+Xbbci0B+fLzxMiXdyRi+6YTxIvvPACj2Q55ZRTqFevXsGvDz74gJxOKLIgzsVZio7VUHmtNZOPqBUknLAFKWVVa7GrpIp3DunFXlebiyv49/1ltVRSFfk0op1HqngGXWV9E+0urSa70TsutiP448EKXnBSy0QPV2zWixVNtxysNPR0SPmI1ArE7HnbcaSqbQJb8frKOnWjec/Vut0K98VurjZWIzrRJc9V4GJ8oIpuaCe67Ocdh6tVM6j1Hqxobye68JzHCusa/373UVq2szTiNs6eK+G1x6itGp9YNFBE7yIU0ds5sajeOBd2ujB73Rp9MJY9Xuw92Azi12Okzn1kogMA09DcQq9+5++IvmH6AMkExWCOU4Z251EUNY0t9PZKe2VOu9X8LYf595MHdaMOyYlWD8cRLp2Qw/Pj2cGHr370P35WWlN0nHfGZ6Ul0YRAERLAicYHctHZNu0Gjimisw91Sl/XXnstOZ3wgRU1dOcoLq+jGU8sprEPzbfk/tWLcvbfiISx6+mS3VNaTTOfWkq3vbtO9/09/vU2Ov/Z5fSnzzbT2U8vpZ8+/33Yx+mH3cfojL8tpXOfWUY3v72GZj61hBff7WTaY4vo9CeX0NZDlZpu/4/Fu+m8vy/nE2ipZaJL41zaNz52GuS5f/c/frHuRP/thxvozL8tpY0HKkKKbPICuNrBgnDFdVmzryq1AxTS+5f+rPXl2xKhEz0hUEQ38uwm+WvmyldW0u8/3qTpMdLb4az39hc89x1/zr/f5Z94yWz/WLSbfv7ySrrqlVX04Oc/hr3t/f/ZzF97T87fzn9We+/hE4s2SYvokSbKjJSJrjeLvuhYLX/d/qvA2Pljnv12F/3yzQIyg/h9K+IBDWSiAwDP5j5IRyobqEdmCl04trfVw/Fc5jTLordT5rRbCTEgM9HBrBk72HD15Dx++cUleyz/XC0cCDltWDYy7cHR8gPzjvx4sFL35xs7wqvRBsRnC9kxRgFCbdhfbun9q20mDqihR9WJzg5aMNsP6+82ZTtBzDsr9/EOGLascB2Ln288yL8XHqvlnQhsmPuP26uIXlHn78gXTvGL5EBg/GxCD0knuujNR9KJ3s73obcDOaOLtpeSUbTmbLN1FAqC4SJrlJaplBUfaRxqwt1veycWlRzwkOS8+y8LaRVmTizKbD+s7SBOpJp4yIcUnePeVeI/K+OTdcUUC9uPtK33/rLwkXJvr9jHvz+/aHfYVWPbnLDddQx0jLGnVs9rMeRMC52d6IJXDM6s3XesJuzv23MWnp5OdGSiAwB7T31pqX+/8Lqp/SklMcHqIXnGT8b0pt5ZqXS0uoE+WRub/6+9ik3et+FABY/3O3044or0uGZKHqUmxdOm4greWGUVZNqDm/TplEa9slL5Pv/6fdbW0YyAIroNhOuUBHuy+nRwteKHEzYfpZiNiH8TuC07pc2IrgC2HDXip1YoSrGYAzvSOq62SS5bVSfaVI0IiQI77dBooXVW5TG2PWf+gppa573Sz8FlhNk2Nce5iNqxVYvoIT9rLdArj0e4JGQ+GxkRprQotddRu+NcKDrhDn4Y6Vh123oL25lmKivHtlvh+UpJio9qn0CeiR7pPVZt0fJivNnvU3qz38XET3mkIrrw+CYgEx3AsxZuK+EHXjNSEumKSf2sHo6nJCXE03UnBzKnl+1BjKmJFmz1F1/H5nSi7IxUq4fjKOxswMvyc/jlF5b4GyCswGI7WUNXcgLLtO9u2TgAjI50KXBBpAs+SdiAuCiIyUWdQXw6uBWneqndpxO2H2GnWc/Os7BejS2tVN3Q3O6C7rGwRfQ4ScQCv1/bFtG1FZ+EYhorDqt1SEuL6GS/Irp88klfhG0l8JypRZ/4b6u8jKYwzzdbXMSs6VafZNmqRfko41xUJxb1SQ/yGXlQVmmdj9c2KRZqQ84aiFAWDzmYEOW4Y1VEFx880PveoPZYsLELRXA2CZhAz/tkaCZ6hLGonYmhNbNIo0iPUXtO6xRva5HiAYKd6IhzAfCsFwNFsV+clEuZqcbvq0B4V0zsx/cR9x6tCUZVgPHQwdw+v5w2gDdVLdt5lM9rY4VvAs/hlEFdKT0FmfbgfPkoooORpLnElg4FouhED9e1ahaNNTnbYUWbYBFdR6FMXBsL10WutaBbVtOgevs4haKcXYvoWsfVrFJEN6sTvVOHJOMPMmlcjLBOQver+D01pIjeGl0RMdJLPiSbWuUPQju29UfFiP9GKNAKRUKz48HYOIRoofZMFCr/fbTDjtXrVPwepPcsFbXHgh2wEzrAk6Msosu3u8hxLrHpRGcHP8Opb4z+eRM/PpGK8UJ8ldVnkgGANQoKy/iHd9bZOWuqP/cYYqtjSiJddVIuv/yCDTKn3Yg1G32/yx9DciaK6FHJ6dKBzjvBP1+CEP8UazgQAm7NRV9XdNzxZyKhiG4Dkm5Q7Ew4ghCXYFWBVT3Oxd7bj/j9Mpo4l0hd5Eoy0xLDxjEoTX4kL7rYtYiutYAnPH7iyAj/z62K25SRcS6V9cZMHqK1W1nYrrR0oqu930YqIkb6j1/+e7UDbaHrFHaxbcuXrBOpd6IbuIOiNjal12OrbByRtqeQswyiHGOjwcVfte3reK2oE11n97tqhEor60QPxLmIMnr1HKSVb7d6H3ezOvojvU/VNkX/HiHexusiFOOF2yYhEx3Ak+YF5sj56Yl9qEcmIi6szJxmB4vZ/FIr95ZZPRzXWbqjlO+b9O/WkQZ2T7d6OI5143T/RLj/3XiI9pfFdm6skqp6Wh+Yf23mcBTRwR2G9cygjskJVNXQTDuO6J/nzk5QRLcB8edcJ8RxgLSTzV5FdHLlASPx+oYrgBsR5yKqoVOTUJCNUUyEXlq3vbYInVbJ4y7tRA+9vREHmfSeOaAmNCIkctd9pG2uNcoieqT36ZBsaoNfr2o578KlYCe6gW8IastSen6FAxwJgRdTpFGEdq5HGecSg/fi8romycFAra9B4X1FvXAtykQXdaLrmlhUZya62q+N/j8tcpxLiyHbZV2EYrzwnoBMdADv2VVSxXOi2XvxDTP8xTGwRveMFLpkfF9JvA6Y08EsbgwCfUb1yaJpg7vxfTOjJ1yPZOHWEr5vPKZvFg74gWskJsTTif3cEemCTxI2IC7smH36PRjPigKrWtqE3bceaQZ3dH8XLopFSUaKUpyL1kx0l3Wi8zgX5QkvJe9D7dyQ2vN8aY/8UB6k0gEA4X01NM5F+2tanKMcqTittRPd6DgX4Q0gIdBpa+Rbk2onenXo8yvcNFirjBTnEuFnO70Xy7dnre8NwvuKepxLWyc6m3wtmk50rZn/kQ5WGB1RFukxqm9HEV0a56JtYlFkogN4jxDJcMbwHujOtYHZ0wbwAxqLtpfStsOVVg/HNdi+xLfbSvhldDC3343TB/Lv76/eZ1hTkBaIcgG3Ty66ptDZZyGhiG4DapP7gX2JC1d26kS3+5kM4k5JPQeMJJ3oOndilB6TcN3s4vqK8Kd2LaI3apxYVCiQ++NclItl4uejvbFA4oL8UZ1nDqjRGn2i9B4qjCe0yKhWRFQooosiICK9TwsT0gbvx9Q4F3EnulAkjDd+YlGV0rZynIu0Ez3i+1JIKzrZdmJR+fastXAvvK8IT5e8OYxFKwnxSixuRGsUjmQZGrfviNEyMc5EN6wTPcJyhO0DmegA3nKksp7+va6YX75xhr8oBtbK69aRzhnVk19+KRCzA+23urCMz1XTpWNysFgF0Zs6qCuN7J1J9U2t9NYPRTG5Tza/y/JdR/nlM0b4XyMAbpGf539fWl2ITnRoJ3HBCjV0ZxAXrvROLGfqxKI2334kkzzqKQ6JijplOouySgXPcN3R4k50gV3jXKLpRBcXiMWZ6EYezJN2ohtURNcZ56I0npCJF1XWU6mImCSKgIj08GjtRJe/YLUWTFvVJhYVOtFNmFhUbWhKz69wv/GBcURaLXlhWa1gH0ksDnYJ65udkaLrPttOqfYpvs+w6Chx3IjwHLanEz3S61i1K97gGc4jPUZ1TcZ0okdaDjrRAbzp1eV7+cHtCXmdUVi0YZfvfzYcpOLyOquH4woLtvi70E8blo0DxgZg+243BQ68vfFDYcSD9UZYuuMo32/q16UDDemBs2bAXU7s15k3FrH3/MMV9eRUKKLbgLg+Z/dOYgj94G5Fl7Jap7Ddt55oO9HFBXe9RVmlIlTYZSjsc1pxoESLhqYoMtHFE4uqFGONjXOJbSe60ntoq85OdMU4F1EneqRtV97JrlbMjDbGRFzjD5eJHouJRRUz0WXjiDQKoWgeKfLEDp3oQud9r6xUnXEuJFk3+WdblucuLvIGu/h1PIfy9Y988EJluzT4P5KIRfR2xbloX47wfscyGQHAGyrrm+idlfv4ZaEYBvYwJqcTTR7Qlb83swMd0P7PhvO3HuaXEQNiHHbGRE6XNL6/++Ga/abfHzLtwc3SUxJpWM9MfrmgyLmRLvgkYQNqp+aDQ4roVmSiqxY/fM7Z1vVMLNoafZyL0msqXMSIYie6TYvoWrc98WSbah3nLUbGuYifL6PiXELGpNZF3hrmIIK8iE6aO9HFhbdI267WjmB5gVTrw646sagQoyIU0S2KcwnpiNcYKxKciNRn40z0wPbcKyst+JrSUugOHiAI/Cz/YOQ/S0Qo8sYFD0C0LxM9/N/G6qB9pOelPZ3o4nVAJjoAyL27ch9VNzTT4Ox0OnVottXDAZkbA5O8vrdqH1XUNlk9HEfbfqSK9pfV8cnJ2YSYYAy2/88y/JmXl+1R/JxhFLbsb7chDx3cbUIg0qXAwZEuKKLbLs7F3kVQoJDilDWZ6MrX233ziTYyRPx4H9M5UaVSvnX4iUXJ1kV08fuF1nGJJ9ZU60SP9gCHVROLqneiK1zXqq+4rbSDzAq8Qt0z0vu0vPCptA0qd9e3b2JRn6zgH5s4l9DnVxiTUCiOGIlOTopz8a9vz0AnOr9fDR+ogmEugQcjpBNdlInODj60TQ6r/bEIiSuKdPCCYiPS89KeTHQ9cS7IRAfwlobmlmCH8w3TBwQjxsA+ZgzpTsN6ZvD/B95aUWj1cBxt/o/+4isroHdITrR6OK5yyfgcnjPPDlJ8udnf7W+GNUXH6XhtE3XqkET5iJ4Clxqf1yW4vTsViug2ICmI2KdWB2GIi1OYWFQ7teKfnsdbbya6uKs4OVBcZMUWtVP/lTPRzc/A00pcJ9O67QnFNZYJKimii4p/kpztdm7Sze04c6C9RXSlgrXeiUVZPrUc++zdFrERfqzyTna120c7n6b07KXQ5SWa0omuTOlMA/k4Iq1ZW8SJ/k508YEH+YSusYhz0Rr3JO9El7/PsG0m2InOMtEDv9d1sDHkzIZIj3uMOtEjxrk0R71s8TYeKc4FnegA3vLpumIqqWqgnpmpdOHYPlYPByJkTr/+fSHVt+PMJK+bvxUdzGZJS06gaybn8csvLtlt2v6TEOXCMu0RPQdulR84QLTlUCXVNET/GcBKeHXagFEdoN/vOmrJER22w/PJ2gN0tNqYjtP22nqokhYE/hOKSSe6BQVW+WYS7OC0uIbOCrFsgqD9ZbXGdqLLirLltY308ZoDmt54xQXdPp3TgoV0tY52pfw5pSIQu282BjaWWBIXiVmXlRZtmeDqmehGzs0gOegRoYjOukP/ve4AHakMP7mIT+uBJIV6nXqci0/hPbSM51PLsQ42oYst0vu0vJCv1okuv/+vNx+mHUeqwi6b/53KGQQCtYlF2QQurKiglB3OHpvP1herTu6l9ngrHSQRbisUioVh7Cqppi83HQqTiS78HGrR9hLadKBC4b7aLis9b0YTtucemaJOdA33K3+PForkAvacCNsn70QX5dqz1zn7P7ZE5TWyYs8xKigsC3leI73F6nmZC9uH2nv7+v3ltGxnqeS673cf5ePSE+ei571dvo3XRijGIxMdwDvYe8OLS/fwy9ef3J+SE/G6t6vzTuhFfTql8ajFj9cesHo4jsT27zYeqOD7GqcNQxHdDFdPzqW0pAT68WAlfbfrmEmZ9oEDIcPxHIJ79e6URr2zUvlniw37y8mJsEdhA+IPstEWr9gHzmtfW03XvrbK0FP4tWBF0zn/2kB/X7iT7OCcZ5bRL98soM3FoQUXt0wsKi8GBrOEyVor9h6jO95bR/f/50eD41xI0vV55Ssr6TcfbqCH/7sl8t+K7od1I3XumMQvH6/Rnr2o9Bx/sHo/H4PwIS1WxPVYzZ3oLaJMdJU5GMTXt7eILi7OH49QRJ+3eDf9+oMN9JNnl4e9nbzrQ22Eip3oQhFdtgzx+lfVN/H30GteXa3YWcwKwkKRN9J7rN5sasE/l++lX72/PuLtJM9V4L7Ej49anvbZzyylX32wXnECr6U7SunO99fTn79Qfk2prQJ7fkOeG6FQLEwsGvh55lNL6JZ31vKCuPQP5J3o0uWxwu2s11bTT55bHvb5jkUmOjvNluncMTlYlNFyv8IBGHl0jfjsB+H5SkqQFtHZgQf2f+zjX29XnDTv8pdW0MXzfgiZaDjSe2y4X8sL8h+t2c+3j2mPL1K8/S/fYPsfq4MHFVlBm/3885dXUiQ1og7yX75RwN9X1f4PkRNv4/URJlpGJzqAdyzYeoT2lNZQRmoiXT4xx+rhQBhJCfH8QAfz8tI9mB8sCkLx9cScTtQ9I8Xq4bgS2++7bIL/veTFpbsNXz5rNCk6Vsv3LacP6W748gHsGOmy2qG56Cii2y7OJbodB/ZBmn2Qr6pvjvlEl0KRTCgu2MW2w5E7OqMlLoppOZXfzPsXF2isjnMRCtPHVbqzoy2iy18Xm4sr+ffPNxzUXGQZ168T3X3OMEpJTOA/q71OlF6DSrcVOlKPVsX2DIyWKLa9tk509Ux0SZxLOzcj8XaoFI0i9tWP/mxBdsp1+GVKf1ba1FnxVenuVONcRA/fkcoG/jyzCchKq+rDx7nozURXiRlRWkykzn2115F4WeICrFh54D16yQ5pxzAjnAmgNhGs+kELH1XWNSs+3myCTKXHa8VuaQePvLAsf1wOVdSrnn0R60mehftPTYynlEBHs6ZOdHkmuqyQy6KV2JkiIZ3oPh/tO+Y/O0CpC1x8kEqeCR5xQtcwh13ly/pe9pwpnZHAngthG6uoa+KPi5bnRLwOBYGz6djBeS3E71tqZ3y0/b6t0x8A3Iu9z85b4i9yXXlSLmWk+psnwL5YcTIrLYkKj9XS14H9QtBOOAP7jBE9rR6Kq7GDPWwfYtnOo4Y3630TeA6nDuxKHVOQaQ/eiHQpKCojJ0IR3QbEH3SjLV6JP8THuogufDAVCgB2YeZ4xA+xNUV06c/BaACLmzfUipXy3/sv61+uXHpq5J0MIff7t2cNpTE5ndryotUmlVQqois8x02B7SvWr7dozoIQ1okVcyUF2BbzO9EjHSzR/vqRd6KHLlftvsQTq0quF09YK4qjOlzZoBznojGnWl40V9t+ldYhUiFQPm7hsnhJwjau9jyyri+1yR1V1y3MNiGORmLFC3nHr/wvWYFVumhpYVl+e3HRU36QQZyDzhZjds638NyySJBgJ7qOTHS1n/0TiwqPW7zoQEhr8PFVjs5puywfR6SHItymJs8XV5orQsCeb+G+hPdDPZOFKq2XELsVifR9K/zzL/xfgE50AHdjB+PW7ivn7yOzpvpzjMHeWNHwmsm5pmdOuxFr/vghcKAbeejmyunSgc4/oRe/bPSZyEIeOg6EgBeMDxTR1+0rd+TZRyii24Ak3zbKjUhSRI9xUVetQGU1M2ubVk8sKt+5bMsStvY5iLQtiIuLes66UFteuoYj9W0FvXhJd6zWnGq1Qq+wLla93tTGFe5v2DqLC9zix0A6sagvZu9pSvncSkKeljAd5yHXq2yX4tuLi7NK2dM8ziVYnA4/Vvm2pVrcV7hay+SYyp3obdclBLZ1tYeWxYWodR436xir0mMnvp1QrJe/X7Ezp8JPLCq9fYOoK1reKS9/bM0+qClsr+wx1FNEF+ZaEFZN/gyIJxaVZqK3FZmVzlIQr3+4Ln0l4Q6W6Smii1/DwmMRaZJPMaX1Et6nIwl5TYdZ5+D/BchEB3A1VoRlfja+D2VntM1fAfZ29ZQ8SkmMpw0HKmjFHmd2J1phyfZSfgB7QLeONCg73erhuN4N0wfw719sVJ8DTC/2uYPNLcPMHJ5tyDIB7GxYzwxex2EHAbebmB5hFnySsAEjOkDFhYNYF/Wa7VpEN7GLQTKxqB3iXGQT+FlFrVipNO72xLkI0jWcots2mVycrMAYudAfrjAnFI5i/fxLJ7Vt1VTwFr9GpfEHys9He7cjcRE50vOs9fHTUEOPeAaE/PfiYq24G/awYhFdNGFnhPcWrYU9pcVoOaiglGWvpxNdOKAkJhQ9Vcca5gCd+LETP/dCsVI+DBY7Jl22rIguW764q1netSw/YKGnAzoawkEOdoBAKKJrmeC37WQhn+Jzw85saSvyxgXPLmLrVxY4cMBissJtW/JM8PacUSJ/HMN1b4u3WeG9Uh4Ho0RYpmIRXWEbVSJfR7WDQOLfIc4FwL3Y5NwLtpbw99zZ0/zFLnCGbukpdEl+X35ZiOOByOZv8cffoAs9Nkb2zuKZ5WyX4uVlxnSjs/csZmxOJ8oWTVwP4FaJCfF0Yr9O/PIaB0a6oIhuA+LPfNF+6BVHSsS8MzZChIdVWkxsRY91Dq+c/KEOxiBYXUSPsC1IirY6Bqt22wxdnehx0kkXVTp+lWKAFONchE70GD//8qJ5vYYCnvAYsMdfrXBuZJyL+CExrIguW4zSqb6R4lzkBTbxOMWFPCEfXG1i0YhxLlqL6EpxLjo70dsmFm37fULggJHa/SYFir96OtHDbRLi7nDxy6ctzkXWiR4S5xIYd7zyfYkLsmWi6BilddRSvG0PoWjPO9F1ZKIHzxYKDFf+MDc1s9dmW9yIONde2DbZ3woTdwrE910vW/eIcS7hOtFly5JnuKtts3o60bMDk58pHRxQOluivZP4YmJRAPd7KRCxcNaInjSgO7pynYYd+GBv0Wzulq2H/PMfAYU9iP3tNn8BFkX02Lkp0I3+r4L9kjjIaOFACHg50qUgMB+Sk6CI7sY4F4sy0cN1gFlBT+a2Xq2260RXvt5ucS7RRoao3bZDsn+S0HCELkmhKCV8V9telQr2Ss+xkK8b60x8+fi0FKuCRfQWNvGmL2K8TnvjXMQHIowqosu3baXFRupEly9DfHtpnEuDShFd48SiLe3oRG9tjZgFKl68sB2LC9VCF7NqEV2hiCh0HgvbtZaxKhW2JZ3oKgf3KkM60X1hO9HF27g8zkX+WNc1SpdttKbA9so6pYOd6KqPWdvY2qJq1Dqo1TLRfZLue3nXdmNL22Mjfy+K9NoL95zK31fCJaBI4lx0ZKJ3CxTR2Tjkk1FrjXORH/MMtx8i/78AANzlUEUdfba+mF++cQa60J0ot2tHOmd0L8kBEVC3em8Z36fq2jGZTuznL0iB+SYP7Eqj+2TxMwDf/KGoXcuqaWim75BpDx6Un9uFfy8oRBEdoiCNUTCgiG5RRrPVBVx50cLciUWtLaLLH2qhKGD1MxDsRPfFphNdS603JBNdNGFfuNuLKR2YsizORTY+LcWqtgNdbYU64efgcg2Y4LhtWeLL4Rem9SCEfClKS1UtogcPIrR1EfNliMZ2VNRJUtUQWohlm08wziXCkOXblnoRPfR6dlXELOsInehKcS7i+1IqUArFZy1RTHLiIq941YVMdPki1TrR1TLRa0WFcXkRWV40NT3OJXB/rJs/Uia6eGxtBwgC18k70WWZ6MJzyK4XF5iPyg4iiF8/8liZSP8nC79XqimLH3Px+MM9JpJO9KbIBzNY9m2nDkmKz6vS5LdK5O8v4Q4AiuNyAMB9XvuukL9nTuzfBQVFB7sx0OX7nw0H6cBxYzKn3eqbwGSUpw3LxgHiGGLz3AgH6t78oTBkn0mPZTtL+b5TbtcONBiZ9uAhY/t14p9Bisvr+EFwJ0ER3XZxLtEtQ/whPtadscECnZmt3xpJJ9wj18a5yAtdwqR1Vue5tEbYFqLtdhYe4oxUaXyLlsdenoneNrFo+IJrxDiXwO1if9BK+rM8wkHxb0QxO5JOdJXXS/vjXKSd6OE6q7W+fuTL0BfnEvjukxbo1CYWVZKgpxNdHueicnu1xUQ6q0cthic4VlEXs9L/C0oTK0aKc1EivB7Fj534wEzw4J5PmsUvz0QXqNVp60RZ3/LnSX7AQs+EltEIHoiJjxznovQ+KDxd8ueNLVdc5BXiU47XSKNOQjrRJXEu8kz08Osi/Frpg3dInEuYIrr47IW2OJfIr2t2v6x7TukMgySNmejy17yWTHSteesA4BwVdU307sp9/PJN6EJ3tBP6dqIpA7vy9/dXlu+1eji2xfatFmz1F9HRwRx754zqRf26dKDjtU30r9X7230g5IzhPdo+zwN4QHpKIg3vlenIbnR8krCBaCdbtEsmeouNOtFbYtSJbrc4FyG+wepEnUjbQrSd6MLyugdO/xc06sgDb8tEjw9b6FcqwoSLc4n1QRT546apEz0wxnCZ6JIDHO0uosu6Q03YLhU70VXGLVzflmcdOrlspCI627EVam8tBk0sqva4RJpcVPp/BoV2oguZ6KIrxdtJuDgXPdEzwutR/NgJ9ymeiNUXiKkRsNeM+CCIcFkeeaIU0RI6sajs9WBiJrr/IFTbgYiUpISw/weI3xuEbUcYbcjEoqwTPXB79l4lvF+VyrI25Znw4TLRI72O5Y97+DiXONUDoNI4F//faenKYq/Drh1DtyH+u0SNcS7RdKKjWw/Add5ZWUTVDc00tEcGnTo02+rhQDvdNGMg//7+qv38YDKE2na4ig4cr6PUpHiaNri71cPxHLZfNDtw1sTLy/aqxiGGw/4GmfbgZfmBXPQ1DstFRxHdBtQKWU7JRBdPWuidTnSyrPM/bJyLxQcyhLq0li5vPc+P8Hfd0+VF9FbDM9FbNce5WNOJHs1EisKfsAMH4r8XH0gwNM4lpDu0/Y9RyKatMEb1yWIDB3cCwxCK6OJlyouzcrwoLBysajUoE10lgEnYtvREgEky0YOxMz7F7UTpIIBQgFUr4CuNVXg9iruIhbGxMQilSva+JF+nyrq2IqtPPvmm7L7EY5dP4CR/rOtN7EQXPzbsQEWwE13lMRN/oAoWqtUmFmVRS6JOaeH2JbJJbuXbqfi+5f8XRY5z0d6JLr6NfH3Fz63wfqjlDBm2zC6BTnR2cEC8vSaa0ImOTHQAd2LvNyzKhblh+gB0c7rAtMHdeIci+7/o7RXty5x2q/mBDuaTB3WnNA1zRIHxLhnfl59Rx+Iovth0SPffswkVy2ubqHOHpOAkiwBekp8XyEUvKiMnQRHdBsQfdI2Ic4l5UU+YtM92RXTvdKLL6jOWCebjayii64tzUelE11CJ15uJrrUT3apMdPlzryW+Qihis3WTFNFFj4GpnegGPETyMSkVddXGLVwvrG+y0Kkt2l4jdTqxwltbnEv4scoPGqgV9lTjXCJs19IzbnyhneiBbV28GHE3t9LBhkid6EpXC6/HY6LuaEkRXZQyJV8n8d/IM9Hl24u4i97KTHTxfbECOsv01pqJHnyeAtttaDxR23ISEuKCZxOUVMk70dXjXEIz0cOvjzAE4eBQuMdRfBP5+654exLGo+V5YO/FXdKTg1nv9aLxC/MWRKL1rA/x75CJDuAun64rptKqBuqVlUo/GdPb6uGAAdiBECGW5/XvCzUdmPVqEf1MdDBbJjUpga6dkscvz1uyR3czm/Acnjash2LUIoDb5ef5Dx5tPVTFJ9l1CrxabUByan6UxasGK+NcWmzaiW5iV7bVmeghcS7BiQTJUm2xGebEuWRnpEquj7Sts50ZvZnoSoVY5TgXn6Vnfgi0FKuEoiQ7cCBeb7XnI9pYqVh2oittPuHOgOC53IFfs0kh+fWBhVTWN0V8//LHuYRmjSuRL0vtgJFPw0SNSloVi7NK7wc+xe1EqdNdOBijXvAPvV54PbLCrvD7YBE9jhXRRXEusvsUF4OFwnLbwUD1A0XHImWim/hBu0mcK88y0SMU0cXXyyeAVdqG2jrR2w7YyIvo8uzwcPOhRDpQGZxYVKkTXfa+Io58ka+vUje8lvclcSY62x7Ef6O1W1z+fh1uEl9kogO4D3vNv7R0D798/cn9g+/L4Hznje5FfTql8f/3P1xzwOrh2AqbhG9TcQXfbzptOOKLrHTV5FxKS0qgrYcqadnOo5r/ju2XCEV0RLmAV/XKSuPv8+z/8vX7y8kpsKfhyjiX2B6tFwpR7S28GTIWlagKM+9HSy630eQPdVuWsLXPgbizN+JZF1F0omemJQYjFLQU0cV3oTkTXeF6eYYzv12geOeEOBdxJ7pSAVZ+ub2bkfwAiRHvDfIlKI1RdbuTdeAL25DwnAqFWbYTrCnORWcmup7CtN5O9GCci+i6trMtfIpFUaWDGsJ2pB49E6pbhr8AygrkVYHuAaU4FzZG+X2Ki+HyTvSQTHTRNs4mJRW/5uSvVzMnFhXnurP1ixjnonDASrgm3EsiQZyJHiiidwicqi3u4Jffd+jEoj5tnega4lzEry35e55kYtHAZS1dg6zrqi3OpVHy3Gl9zwjpRFc9G0V0v4hzAXANVoTac7SGMlMT6fKJ/aweDhiI/R8xe1p/fvnlpXts8TnTLhYEiq/j+nWmbrKoS4itTh2S6fKJOfzyi0t3a/67HUeqaV9ZLT/wx+KLALxqfCDKaHWhcyJdUES3AfE+gdqH3u2Hq2jul1upvFY5ckB8Gjc7HYLdVp4daxZhp0a+c8PG9PhX22hNDDOOxGOIlFX++nd76bP1xbTjiPpjy4oFf/16O63aW6YrzuX73UfpqW+2a97h219WS/d8sonm/Gs9rd13POJzLi++BbOELd6/FAotZnWisyKmUHTRUsAWF+40Z6KrjEteKGs0IRN92+FKuuvDDfS7jzbw7VLL+ISYjv9uPEj/XObvxhK8u3IfnzFeWFW2PUoKe6ICpDRWSnofrLuCbYsVdU2S6w8cr6VHv9zKswCjyQTXQ77NKz1Pqp3ooi5U6cSi0q7o7MwUykpLUlyGOJ4kXHHy6x8P03Pf7oo4Vv86KS9DKZd8yY5SenrBDv4aE9ejlR5bYRuXTCwqKmoqLV/oAlY9a0BhrB2TE4PF3bJAh7RanEtTc7hOdFkRXWVsguOi98RYxLmwIvGT32yn5YEOI1Y8Z132Qsej2v814uKy0sEONUnx8cHnsKTKn4k+ODs9cpxLyMSi6vdRdKyGHvlii+rEoq8s38u3ueC6KBTR2f9N7H3hx4OVkv/L2HuC2vuXGCtmdxVy9WsaJIV7+ZkLR6sb+H3tLq0Ou45t8UY+embBTloUmLBL8n8B4lwAXIG9zuct2R3sBk1PSbR6SGCwSyfkUKcOSbzY+L/N+jOn3eobdDDbCjsLhu23fbfrGG06UKHpbxZsFTLtu1FHvHeBh+XnOW9yUbxibUCtM1TsxSW76ZN1xZTbtSP9fFJop4X4g7RwWmPhsRp68ap8ilkRXVYcYB/C/7F4N/8q/Mt5po9DPoZwMRusgPDA5/4CAisCscJL0bFamnfVeMnt3lpRRM8t2sW/xOsQKc7lL//bRhsPVNCUQd3opAFdI46bTZrz3qp9wc7Dt66fRC8s3kWfrj9I/bp2oF9MypXcXr6ZKBXNrBA8K0GtG1DDtq643Na22AH2eBwOTLYX6UCJuJjbnkx04TWWkpgQUiATutSNmMjqxSV76N/rivllNoy/XjIm5Dbyx03oPv3DJ5uosr6Zzj+hN/XMSuW5Yvd+ukmyrbDHQ1zQFReW1LrSmRcW76b/bDhIA7un8w80glveWcu384Vbj9DC35yi+vdqz7X4+kgZyCFxLhGWJ79evN7yOBc2qQ/TKS2JF9HZOsmxQmPwdRZm273xrTUh16md9aBnYtGH/7uFdpVU08zhPVQmFm0jbOPi11t9pDiXQAFTbaxKBwLY67Fzh2Sqbayj8sABFuExTRBNjumTdXGLH3NJJ3rbzKKKYxP/bY/MVMXXqxlxLv8qOEDPig6MCJFQEeNcRP83yDvRxdhqi1eDFXmFbU14fffv1pE2HKiQPG7y90B593e4s32ufW017T1a478/lXYKts3NmDPDP36FyJaHPt/C90vE3lu1n7TiE4t28B8UZesl7kSXH+i5++ONtGBrCb35QxFtffjsiO817DT3vy3YQX07p9HyYafJ/i9AER3ADViDCzv9m70XXzvF37EM7tIhOZGunpxHf1+4k+8js4gXr08cW1XfRCv2HOOXUUS3h76dO9AFY3rzz3Dzlu6m538+LuLf4EAIgLQTfd2+cr4frzXS0UroRLcBpVPz5aoDp8rXiiaHE1P6EL+5uK07zIpO9J1HpB1jsaA0wZkScTef0Ln43a7QHLPCQJEhbLFe4X6E50veuatGuL3S3yotQ/5Ys4lN5Jm9VhCKNmpFRnHBS1+ci/87e1N98pIxdPc5wzR2oosKJxoz0dXGHhphoO2AjR7i17fa5Bry9whhPWoC23F1Q1Nwu5avCiuai8ctLZy33U7+NsR22P3Llo5JKDbvLq0JH+ei8r4mLniKY3q0FJyVFqk+Kaa0E12YWFToChYKduwgyTOXn0j3nT+Cnrj4BH56uFIRXe/Eq+oTnirfXqmQLX4OIk0sygrY4t/JO7TlcTHsdsL2zR4npW5ppaGyM0OEgx/CMoWxs6ezrRPdF7JO0kkwAwfJNGSiywus8oNhZsQrsYOuYkIRNlIRXem1prQpyDN82fLlO5BCl5L8fUt83/XyTPQw26lQQJdPLDqsZwbvqJL/36PUib6xWFu3lRq2nmmBMxnY9indRqVjF3IS5QdJ1IroRyr9Z+KVVDZI8tD994tdXwA3eDHQNHTx+L4hE8+De1wzOZdSk+L5wdEfdvuLx17GzhJjzRADunfkzS1gDzdM90+E+79Nh0L2G+WOVNbThv3lfD/5dGTag8cN65nJzyRjn3HZWflOgE8StotzUb6N8AEwXJesXKwm1wnmLcs+9OotNBmfVa5eTFEqtgmZvmJqR8LC5cOKHwuts8krFf+FgoJSxq/8sU0RijkWTHKqlo+vVIhrNSDOJadLBzr/hF4hE+oqjkd0f0KhSCgwqnXcqhbRZfclLuQZVbgTj6lJdXzyv/F3wgvjFrpElbYFdhNx97nkoEaYCY6FZcmjPjoGCmChY5QV+lXWRXzQINKs9KGbS+gy1Q+MSLe9tjgXaRGdHWBhHb+siHhJfk6wwMewtwKh+0nvPKnqmejKt1d67oJFbnY2gdLBD9GyhANF4ucxXFRGSP61T9tY2cMoj0cSHlNWqBRS0XmcizwOSfSaiZSJLj94LF6WfNsyY04Q+cSbwv+tbZnoyvepdKaH0lMuP4DEHlPhfUp+oFR+AES8rcj/r9D6HiteP3Zm1lUn+c98UssoF9ZXXHyPBnvNC3FA7P+7uqa251l+5oJS5Ey4iUXLAtnx7PHhB54kRXT7d7gAQHgs8vDbbSW8CDV7mr94Be7EYr8uzfefBTkvcODEyzAZpT0N75VJM4Z05/vQ/1y2V1OUy9icTpSd4T+zEsCrEuLj6MR+nRwV6YIiug1oibgQigZaC3xaOjuNIty1/MOsFfO/ROoQD95O4+DUiujih1spUkQodGjN5xUXDIRxCwV4pSK6vDYixIzEepLLcI+L0kMsyUTXMVRxnIu8AzRcxrBQxGJ/JvytUEBpbye60nPWXtKJCFs1T1opLooKY1GNmBBd36LSlS5/LQt/Iy++ssl0tIxR7YBafaMoMzrCa1LTxKIq9yPPgheK6MJVwnrJC/niIiHvRA/8qDc2SX2yTu0Tiwafg9ZW5YlFRcsKdsyrTCwqL2jLi9RK255inEscmwBTekBCGFu8rBNdWxE98LPsfuQTZoq3Q/lja8Z7oPy/AWGdI3WiK45T4XFMFsVE+Zfftq0JhElvw61vvWySa63/B4uLymzdhMI2O7givL+KXz/C/3ntPaOed6IH1ov9f1cnej+Qby9qhW+1SXzFE9eyM8+EbZqNWX5QBACcR4iuPHtkT37wG9ztlycP4P8XL91RSj8ebN9ZUE7G/m8U5vo4E0V027lpxkD+/V8F+/lcLmpwIARAKj+3C/9eUIgiOmgUbkI/+QdKtY5OKzvRhdPp5UVJyzvRW8wrokeaWFSYdFJzEV0hGkT4W/GEgEr3L+5Ej5QRbja1vG090UVKgjnLgacjJSEhYsc2H4NQHBV1dbblWmsrUscyzkV830qTP6p1Xip1xasV9sTbiFonOrsoPjjRVkSXLjNTZRJOtcKWXK2o8zRSYVpLJnq4PG+hoOzv8pUWmYWitRDzIhDnbrLCW1untMr96Dwwo1JDV3y8hG2MRTYp5deLhxTM/RddJ4nKkOeIy96nlB5H5U70uJB4JEknutC5z8+AUD67gS878EDEqTy+QpFfeDrEBxmaYlBEl3dcC+ucErGIrq0TXVhO24SsoZ3owlkR4eJcQl4jUXSis/tPDdwXj/kJ7nuEvse0N7OQ/X1bJ3qz5GCOfBtUK3yHHrz3SSa6FQrqbf8XoIAO4HQHy+vos/X++RhuDBStwN3YfEjnju4lOYDi1XkA2PxH3dKTaWyOP0cY7OOkAV1oTN8s/lnrze8LFW/Dzo77fpc/lggHQgCcObkoiug2EK4DVCB8AFQr/FlaRPepFJCs6ETXGufia28nemhXnphQQNYe5xJaoBAiFsQTAqoW0ZNsEuciyTxX+L1CUUkLcQFUvL5aD5YIRS8mmOGsVvBU2Tbkz7MpcS6iB009ziW0QK1U0FcvoouLqerPh/hHYd3lhS02EadSwS5kWSqPtbh4q/Z8tI1H+nvFuCANneisICq8rIXnWijEyrOSxT+Kz2ZQ2+TkERTi+9eyTsHlyO6APX7C9sDWQykWSbwkxU500XuRvNNdHucS6bkQ3498ot7gWSMs/iZwO3ZNuE701gid6ML4MlOTQgrnIZnoJrwHygu4wpkMwU70Fg2Z6MLzpPDQiv+vFp47+YlkQqFdT+d9uPdYoQNcfpCAvVeKfyecLaKUid7eInqiqGDPFi/OYJe//2nuRG/5//bOBMyOolz/NUtmSzKTfd8XSCCQkISEhEBYQgBRFhEBkX2/4B9F8YpXQa/ei1cRRUUCyCoqCAoqm+xhC0kIBAKEkJCV7PueSTIz/+er01/319VVffrMnDNzZub9Pc8ks5zTXd1d3af7rbfeL+pE37hjr/+65lCsCAAQz31vLNHXJBKsKA4BtC6X71MfrFYrNu1SrRF2MB83rBs+z/IQMkHwwN6DM5ZZ61vRbAq6bxzQuQKZ9gB40Gc5XdNWbtmtB8rzHYjoeUAoi9gpzoTFHpPqJo1zyVMneoy4INvKTjgbrszXUGyMZd/zg7yrEKyJLY6DBcZdzSrOJZ0TXdWzsKgR5yL6dpLjLG80/aKLGWaiR0X0ZH0tE6ToZov00O0zC4vW1FqjZVw5zbKt4Xgd9/nru6CNY1olRHTZT5M60aWInmmcS7q4oPBrg8z4IuEo523kfS0HW8wc5lScSzRrPLT+DPuU6xJpCojyGkNidGhGh+9ED34XCNtCRBfXIp4pw5jXGFt7bYMWstgqt1k60QtDcS519cpEp+3jOJfKcq+4ZlwmeiM40Xkgjq9D1UbcDCMHDmibaFtsET7yesbHzpmJbtSbiBs0iDul5OeePNfpGNAgAW8jzxaxzfJy5ZQnhbaxQgj2suC3+fnhcqJzu3gf8raE41yq/WtDGxQVBaBZs3XXPvWXWcv193Chty5G9K5Sk4Z00df9e9+Iz5xuidBnfxAD0qOpmwMcnHhwDy2QkzGAYl1MXhRRLnLGKwCtmbalxWp4z/b6+3eagRsdTxN5gHzQdToTPWEgadRE48a51FlFsKYW0eOKTkoBlaoB++8xMmXrW1iUxROZ8RqHFAzMwqKZxLk0tYgeiiayOdGl87mehUVZUGGxKd6JWWvJ/I13oieNTJJCXnVOMtEdgnA6J7rXFleb5O9Z2IuLRZDL3LffPgPCFMDMY+u6bsVFjEQwnegZxqlIEd10avP5yg5jq4hO4nthfEyGK4LHWVjU+tv44pEkRstzyxYT4jvmHYVFzeWbs13smeguJ7qRiS4GvIJ4lug6Q/3Qa70tLkfmfLcv9ZzoMTNachFpZQq4kUx0x3E3Bw5SAngyJ7rpvGYRPToTqsa5vLg4FxkhQ1PDg21LrZfd6DzQZXOiN9QER++nOgQsgJNj3LznMdtlws0yZxhxYVG93J3kRPfc82bYPACgWfHwzGVq594aNaxHe3XMAV2bujmgkblycqqI7COzl4fuO1sD81dv1y7NsjaFejAB5Cd0H3f50al+SgVG5T0r3Qu/vCCVaY+BEADsuehzlm5S+Q5E9DwgHIHhEPZq8zkT3XNzxsRBNBa2B30b8gNNihPmDZkU0W05xGlFdJH5HIdsD4n/JH7Ex7mEf+ZtyHsnukX8y2S5UsxKV9RPiljS1cnH1FW40zX4YwplclZItoS7JDMpzP0WyURPF+diuGbNLGtG7h5elrnP5Huk89N0+buOtRkjEudGN/9iEwjjisX6ufrCic7t4n7CQhwjDSL0HvN9Jq4IHlefcg6axkR20A24tbCoeAsPNsn9GTdgkciJrhyFRZ2Z6AUiziXqRA+dM96f/EKkjra1K0sNeMplNUYmeqHLiZ6mFoV5vtCxSiei80COOYArI1bSfc65ol8ke8T7yNnJ8Ho5g533v+3alI1MdIIEAfMaYh5Xl+vdd6L721wbyUSn7/3iwZj+DkCzhSIS739ziS+mwsXZ+iDx+OBelXqG2h9nLFOtCXahHzW0q/8ZDfKTM0f30bn1NOjx9Aer/d/PXrpZbdm1T3VqW6LG9EemPQASPifgRAeZx7k0x0x0Fk8imcWq0Qm7Z9155FIQlQ5J6YQzRQK5j+PiXEi44uf/ehUW3V/rxxfoZViEeKcTvYkz0dP1Zdl/MyssGo1VCFyg7n0sBT1TAHMJTC4hdm+jZKIncKKbcS6GiM6CXpJM9NT7vVkuxuqscS4x4vhGUYU+4kR3HOtIQcs4ET1Bd6lJGufCTnTv5X7RwTgneoEsShs/2Bn5fU2GcS7GsZPHksRFa2FRvzinw4ku9rXZN8zZLpkUFjUL9bqc6JFM9FBh0WB55rq43SQi83UulOXvLSeX10AzGc3PRC9KV1jU4kS3vE7GuQSZ6IaIXlKYuCYHx3vFjVOG+oPYZzwoUlFSHBrosg3UNTTOhd/P65LucXPmghm1xHAf52NCb6MBtnCcCzLRAWgJ/P3dlWrDjr2qV1WZ+uKhvZq6OaDJM6eXRu4jWzIvzF/jx4CA/IbMbRdNHKC/nzb9M9/4g0x7ANIXF52/epsuwJvPQETPA0IRGC5RxZE7ztiEg9JGy0S3O1njppLnCluBxXRuXPm6OCd6qBCeIWLJbZe50Ulv7kzBYNuefbHLMB27+RLn4nLrJ8ngzqSwaCiPOEEmuhRg2JXuEjZdbujQIIoRy5At4S6c9exyokffY3Omutpk7q/9CeKYfCd6TTIn+v6IOzSZEz2uT0QLi0Zf43o/NTsU5+J1Bz8T3Ttn2xg3tPLHVEHSqMgrMfsUa4yZRluZYrzse+Y57q+S3dxisCmUiS7jXGrTxbnYnOhR6BTkASpZ+NR3ovvbb9ummshnhb9/VbTd5Lry1yVihXh9nPHdGE50vp6UppkBZA4cpK4bdbED3kEmuhHn4gnjhC2+yfZ54JwBURvMdDLh6yPPbtrdCE50dtTJz19anVynqz5JrcWJToPX8jpH16agX+K2F4DmCF0P7nl9sf7+0qMGReLXQOvhCyN6qD4dy/VnxmNzopnTLREqtPfhym36vvT4Yd2aujkgAecfMUDfm36yZrua/un6VKY9BkIAcNKzqlz17lCunwHmLt+i8hncgeQB8jnbJeCxaJBJnIvLuZVt2AlmCgRNkYluE/5syLx0+bBtiuhSI6gWjmfzMIScouKPLqEinWORpnr5y0gQ58Jiji0ftzFJF9ci+zd9m3Sgpb5xLvXKRHcOVAX7NuKqzUGciysaxJY3bhNZXW2KiLBGQUhGap58jthEQSYkgHm/54G8JJnotm2TmH+yeXpd76ff+yK6JZaFBxzinOgF8n0JI3/4ZS6HujtbPfx7eY0yz3G/sKhop5/5XueIc4kUFg2P9ttmPHFbpXCaKiwaPsayfkFcnEuosKjfdl6XbFvgRGfRRA5U8nrZzZwLEd28JkSc6K4s/JjzJV0muilQ8zU+1R77IHBERHesL27gka+PPCjB+1/ug+osiej8do6qkQNx5vXGWVjU6yx8LOgt5oyyjTurg88CZKJHuOOOO9SAAQNUWVmZGj9+vJo1a1bs6x977DE1bNgw/fpDDjlEPfPMM6G///3vf1dTp05VnTt31tejuXPn5ngLQGvg+Y/WqCUbduqC5ucc3repmwOaELpXu/yoVOY0Day4TCctiRfnr/XjDjq3K23q5oAEVFW0UeeO66e/v2v6YrVg7Xa1YtNufY921FBk2gMQ50Z/Z1l+56JDRM8DTFdzbCZ6wqgJvdxG0rClICPXmc+Z6C5np/kQL+/LXE5082/yZi6pE90UJ7fsCtrRnAqLhgqHpnGiZ9JH/DzrgvpmoksneryInqR4b65EdNkmV5FKa2FR2e/TZaK7nOiOwqJypoWZU7zfIaIndqKb4q1j4CCd0Oq/35VzL/ZRXJxLm7RxLmmu066BD0f3cM48iulfZqa9H+cinOh+nItYAWXJ+sszlr/bkZMv4eWH3PmiwC+/J7SfLXEutmKcwbJj4lxKAhFd7mdeH7uZcxHnUuMS0dNcg2zxR4kz0Q3nNV3jed+nq53Ay3P1L3PQRFJkiOjcb2zrbGgeMfdTPnbbRYFTsx/assxpYIf3J28z3SuRaC6hTHTuM5g+HebRRx9V119/vbr55pvVu+++q0aOHKlOPPFEtW5dqvCZyVtvvaXOPfdcdemll6r33ntPnX766frrww8/9F+zc+dONWnSJPV///d/jbgloCVD5zpFIhAXTOiv2pamBk1B6+WrY/uqjhVttCj57Icpd29LhmNApgyHg7k5cemkgfr+Zcbijeq25z/VvyMBnY0fAIAwYzkXfWl+56JDRM+7OJd4Z6IzE90iHGQSl5G1HOzaJnai10NED037FrnO5v424zwk0qUuhZOkmeimaLVld4ZO9DQF7hoLqRnZ+p/NRZ1ZnEvwu3QuULl8OYWfnYiucymJiG6KpXG57PUvzJpM5Kef5cBN+jgXRya6I87FNUAkX0Ow+1OegxnHucQ60b3ZCDGRKq6uIAcCUnEuYac2b5dZWFQmP4RFYdd12tWnHE50a0hKfP/as9++z2QmelBYVCVyopuDGdZMdO9/KZzSevzzydt2Gb0UDHhQH039vp0nftic6KxvyrVzcWYSdXldcj/zctvmMM7F3B8s6KYbvLQV4rUdcxm95nKi07bzTImkhUVdn8Fxn0vcdzjOxXeiWzLRG2rqDjLR7QXS5Dpt+evyusKDD7TNPKDXoaKNJc4FIrrktttuU5dffrm6+OKL1UEHHaSmTZumKioq1H333Wd9/e23365OOukkdcMNN6jhw4ern/zkJ2r06NHqd7/7nf+a888/X910001qypQpjbgloCUzc8km9f7nW/U9xYVezjBo3dDg64WWzOmWCEV8vr14o/4eMSDNi14dytWpo1L1G57HQAgAaRnTv5P+/73lm/N6lhFE9DygJpGIHu9Er7a4leMEyh//6yP106c+dv598fod6oL7ZqnZSzepnz37iTrp16+pi+6fZQ35d+Vcy03549vL1H/8aY5+4KcT4to/v6vufWOJSsqdr36m23DeH95W67bv8X//tzmfq8sefMd31tmmnNtwiR788P3svNXqkgdmh5zpUpQ0xb6PV21T5987U81ZtjkknEj3ZxzmRWKrENFpO9LlzXMhOW7j715eqL7z2PsZ31RSe6/84zvqkVnLna+hXDfqG8s27tSvpePyX0/M0+uyzaqgyuQX3jdLvb5wfcRpnHSgxXeiC1UzifvelonOgjoJY7Tfr/nTu3ob/vPxD/Q2mMfWlr0u4yTStcHGk++tVJc9OFufT7TO7/3tA3X7iwtD4iB9f9vzC9SNf5+nPly5VfeveZ9vjbSP+ptZmDauTaaT2S9a7CgG6ooqku8l/vbu57q9+2NEdNpe2u4n3vvcKua5Yk8krIFR33llwTrdF1dv3R3vRBdxLiSicTfi/rq3xp6XHIlzsTi86ZynNixatyNGRFeZFRY1tiMU52Icv9qIE50iVlS0sKi4FtH3VzwUnOfmYIbdic6DGHYn+rJNu/R5TtcH/pucNcD7xpZdHh0gqYuPcxH9jo85u5lpX9H5ROc0fZ191wy1YtMu60PppQ/MVv+YuzL0ezq21z3ynvqDl70r1+F0oosDzNfQv8xaHnWiC+d0ppno1Df5b09/sFpdfP8s/Xllj3NJ7Yvfv7pIXf/oXLVw7XZ11rS31Mm3v64enb089nOpyC8smloGvZ7202YRMZatTHTeHo5zMbEVPHUVM/ed6DVBUdEDurX3+8Q27zMVmegBe/fuVXPmzAmJ3YWFhfrnGTNmWN9DvzfFcXKuu17f3Hjrsw36fg7kF+xCP2tMH9UFURbA44IJA1RZm0L10apt6s1FKZG5JTJ9wXp9PzG4a1s1qGu7pm4OyJArjk5FDxF0m3s8RHQAnBzYo71qX1qsdu6t0fUE8hU8TeQBYeHR/hoWq5yZ6Bk40enB+/43l6o/vLEkVMBSQlPjXvt0vfrT28v0zSt14lcXrFdvLtoQ337xUCsdd/e8tlg9M2+N+mjVVvX0vNXqqQ9Wq5/EiPgmd766SLeBbpJe/DiYZkxCPOXEzfamfJhOXmeRSIdzmLPIqeL7y5+s0/sgSZzLRffPVq8v3KCFCln0LqkT3RRbtgrBgjBFj0icS5uwoHzHK5+px+d8rj7fnBIXk/Le8i3q3x+t1X3DBQlltF+O/+V0/Vo6Ln+auVyt3065s9G+8PL8tVpYI1Epq070LGSiz1+9XfdH2oZH31mhp4WabaooDcQ5Ji7fOQnffHSuenH+OjXt1c/Uqq171COzV6g7XllkZKLXqt+8vEjvty/+9g3dv2ggKxLnUkN509HMbNcgkqwHEMqyjgzU8OvdWfDm8fydsQ08AMGiLF0HaLu/9ej7+mdzUC5OQ+c+z05o+unBt5bqvvhvbypvUie6mW3uO9GLw6JggRnn4jvYg9fQeUZteGbe6oj4zFPS3OK+SuZEd8yckdvgv6MgEKNdcS7siGFhIpJNb2kvL0rGjGhXvydKPv9R6jx/4r2VorBocKx437S1ZJfXxZzT4TgX79yVTnQjE50+3+h8onOavsjB+OyHqyPbc/8bS9VLn6xT1z0SzmteuG67+sfcVWra9EBEN2OMWNBlMV22l6+h1Ncj50tN8Kn4xUN76v9PObRnokx0Opf4d/e/uUS9smC9Hpi0OtG9zwO6Tv39vZXqO49/oD8jqdo9bZd5vCcf0NUpbJP7k/bTcjEQkTTOZWTfDqpnVZn+/ppjB+v/Jw0JckC5n/IASNx5IAe0eP2ym3LfoOsEC+Y9O5T5g63rtqdmmSETPWDDhg2qpqZGde8efqCnn9essccj0O8zeX0Sqqur1bZt20JfTSWg070cmwRAfkDXLXr+oEsT52ADQHRqW6LOOdzLnH4tdT/TkqNcTjioR1M3BdSDYT0q1bEHpu6zDuvbQXVtj4FAAFzQs86ofh18o1q+AhE9DwjniNsdgOxMdDrRLQ/SLoFSRpaYBbjM5W0zMkptrw850WU+umgSiwn0UL9qS+AkT4orcoWjDfih2txmV6SFS/RkRyaLpHuE61O2wRU7QauXLtK47FnJvhgnemo5poiu7E70/bW6v/B+SeqEd+3POMy+SCOGcr+wAML7jfZlJIokQye6FFJYeKpuQCa6GW2yQRegC7epsqxNJFbHnDlQ3xidtdv2+MeI+qrsB7LvMeSwjDrRKe87GufiapN5bPk4msu1x7nYB0EumzTQe0/4nDOd6Ga/Ngv5xjnRI5ncdcH1iJ2nzoieOruIzgMHvA/aRJzowfep90Wv0zwLiPYTH7+BXdqqF6+frAXS1PqdW1WPTHRHYVEeZBB9XLbT5pLn/WdGRlnjXCznIDnzWXTdaVzr6G/8SmrHPm8b2nqDUqFrs7e6zu1KUu0S/YKvyTrOxTs+UtQ2M9EZcjF84ZAezs+tXV5MjAk7/feKa4MrE52FW7lvd3oDQ7Q/9lud6Knfff2I/rqP3H72KF/ojXWiF8l97Q2U7au1Z6Ib2f4kQjEbdlT7+5RcbS99e7K654Kx/t95vS5hW6/X2zeuy3e39qXqle8cox694gi9/NduOFbdcOIwvb1yXbyJ7jiXYAVyINT/vA850Yv8/sCflzSw0rltqk/xDDZkoucft9xyi6qqqvK/+vZtmqKRB/eqUoO7ttPnyNfvnak/n0HTQwOSxMkjeqoBXdo2dXNAHmZO03WdjCY0a7OlQfcXNOuSQJRL8+X7Xxiuxg3spL455YCmbgoAec/hAzqpvp3KQ8/h+QZE9DwglCNuy5EWxcicmeiWB2mX4C4Fik1GAS7/vZ4osMMQ0W2vdznRwwIOi1W1arvD/R6H3JZQxIq33dxeUwhMKiQyLCbx+uT74zLRXQ/+NiE0WSZ6WPQxRS6nE72mVi/LdxFnKO6a+zMTqI2yL3Ab+djTsiO52wmd6NwcKYD4meixTvT4THTTUU4F6Mw2VpV7IroQLyNO9HpmdtHNcZzL2IREO3OfUXtDcS5pCouasHBtXlp4P8QVVOXXHNKnKtgGsZ9MEd3MNTbFzTgnOm8hO6HJ08sifCCiOwa3yInuRwKRezrsKOftMl2q4cKi9jgXdvbT4BkfB3LxDunWzl+PMxPd0f3j+pfTie69hZpsa6dNGN9evV8LooniXLz/5SGUmejmgF3KiR5sJwvfXBBObgf7szu3LfUHW/iY8LWPMrrjMtErjEiQ9mXFWhSzFYyWg2Op9klRPjpgbe47Fs/9Qqfitbwvqd3R86U22I9K6T5COeehOBdvmWZ2N207u/55X1Pfi3OiM/I1VLyTndokMpNoaIuTcUWsyOW5+jUJ8DSQRMeM1tGvc4X+PW2vrDvA5wfnr5vIAWnpeufZMeFZL8HAWCCiF6lO3sDM2m2eEz2f78gbmS5duqiioiK1dm3K5cjQzz162B2P9PtMXp+EG2+8UW3dutX/WrFihWoK6LP+wUsOV/07V+hZaRfcOytU5B00PhQH+M/3V0UiEQBg+naqUKcckjIs3OUNuLQkZi7epD+3KcaIXMygeTK0e3v11ysnqKPFzD8AgJ1rjh2iXv/ucer8CflbAwUieh4QKsxpUVVCD/OOrFqbiOfKm5buT5cTnddDIovEJkaE2ydzbqPONRIjXBEyLrQAJtYh288P8yzQmA/1LiHRJXqyAMIisnQqh+JcYhzUUjjRonYCgZVdmiwqcKyM2S5//UY/KBNOdNnOTMVdc39mAhUADDnR2eUrRF1bUcwk8HEtsjnRaxqQiW70F+pbZptIjIsUZmxgJrr/vgxF9PZlbSLtS2WiR5eRWET3ixaHl8uHUvYhs1/we3gmhDlwxAMdgYCtGu5E984R+nmjN6hHgx+p99v7E22C34cscS6BiO52otN7bHEuwcBTUOCVhcJARHfNXLH/3rxmhPuIGb0Sfq/ORDfiXHRhT0cbNu/cZ8mmt7zW2P9mJro5YEiv8zPOxTbZM9FT/3esaOML75s98UoKon48kKxP4R1XFuelkEtTvW39jKj0BsfMWCF/wNeSu25eQ3jbaT/zNZlFf7pmRzLRaTH+YIccEAzOH+4z5oATzZLgfiXPcdv1T56PLmHKJZSzUO9yh+v1pqnRYjrhnRFJ3rbKddGfqR8Q8romz6EgzkU60YMBDR5koO3r5A3MsKsYTvSAkpISNWbMGPXSSy/5v6utrdU/T5gwwfoe+r18PfHCCy84X5+E0tJSVVlZGfpqKrq1L1MPXzpeda8sVQvWbte1cZLOKATZ597Xl+hzesKgzjoeCgAbPMDy9AerrDVQmjMvfJyKypoyvFvo/gsAAFoqRc3gWgcRPQ+QQortmdTmupNI57H5+/ROdLuIzg+pO6rj4xeIGldhURFVwA/99PdtuzN7IDGL7IVEdHaBCiErtB0OgdUlVvLDEm9HqKCfxYle6QmsofYa6zQF8LhtZDEhGudiZEcbh1ZmoodE9Ho60V0FEuMgscs2q4KXRWJPveNc2Mksnehi4MD9vvDghPyezg9zO3VciiPORTptZe59ujbEsXe/fQDMRbvSYj8aJBAUSbyNCkyu3H8TW5E+d5yL3Ykuna8cCRR2otdGhEESdlkEN9dpg68nvAzqbyzc8jXB9f5UnIsllsUf6KkLuVldmeh+DIxYjzxnWDRlMd4Us5M70eNE9DSFRQuicS6mmCuhY2Beo+yZ6N5AiOHOl8V+I050GUnmbVNbzkSvSUVPybZTuztWhIXv3UIQDZzo0cE6M36EfuYoD9vgr3Qky88Ubqds335XnItwcPM1nK/V1Maow1840UVXsznBzVkRtC7zptK83icRsQmulWGLbOG3utzhvF69PY5+FXfzG4pI4kx0sS46/jwIIJdvO+fkNYsHNuhc42Mg+wDV7JDHDqS4/vrr1T333KMefPBBNX/+fHX11VernTt3qosvvlj//YILLtBOcea6665Tzz33nPrlL3+pPvnkE/WjH/1IvfPOO+raa6/1X7Np0yY1d+5c9fHHqbo3CxYs0D83JDe9sZ2tD10yXjvT312+RV318Lv1/owH9YdmATwyO1X8+qpjUjUVALAxoneVOmpoF/1sJIuCN3foHoTz0KegGCUAAOQNze5p4o477lADBgxQZWVlavz48WrWrFmquSP1Elu8RdgRF/276+beNdWaXZsucUGvs9YV52IR0aWTPhTnEW0jiREyzkVOo3dhPqhTXmV0uZ4zzVie04nu+D2LciyauFzdvGvN4iCUbWsKLmYUS9w2tvUEJlNEjzjRzTgX6cJzuOeT4DsMY0S32DgXixOd3cv2OJdky/aLGmYY58Lb4SosGolzoUx0Y99WlrMTXbhVs+REN+NckojofI2Qxzw0+yFTJ7qjsKgtzsWViU7HgncxZ0rTfg4KXKrIIAjNcuH9T9sl25IkE11eB1iMd70/NZslmM0QEZktsT/82pCz2uIsD0T0YGaDmWvtFNEd22o6/uW1x4xNCQqLRjPReb1xDn+6pifKRLcMLGgnuqNQI+07v7AoxbnwNc471vQ7Pl7+gGtBQSB8G3nt5SXFQSZ6gjiXijbFfsa6LYZMDghtEJ+Jts9bZ5yL6C/8mt3CkW9Gl9FhkNn1jK2wqOlEpz5lRpG4HLJyeRJe5Oebdznd5oETPTpAbBsUz1REDw9Mcf56sC6aPRAX2yPPB75m0erkrAA+BiTOB5no1c3G3dKYnH322erWW29VN910kxo1apQWu0kk5+Khy5cvV6tXB4V5J06cqP785z+ru+++W40cOVI9/vjj6sknn1QjRozwX/PPf/5THXbYYeqUU07RP59zzjn652nTpqnmwoE92qv7Ljpc9yEqHH39X+cmnjkHssPDby/Tg+XDerRXRw8NChIDYOOqyamBlkffWRGqndWc+WjVNrVq6x59HZqEcwAAAPKGZiWiP/roo9o1c/PNN6t3331X38CfeOKJat26VMGN5ooUkm1OytCDpEUMcYvo9ht+KSi4nOj8wEo5bBJb/IssJhoW0aPrJyFLCsRxDkmzLbY2SwFLv7a2YSK66UR3vYeFK5r6KyFRwnSRmlEJJjJqocIruhcR0Y1lmLtWTt+XAx+N6UQnod/mRA/iXMKFR+vlRLfEucSK6H4xSSFSiUx0s29R/3YWFhXiWNIZD+lwOUnjnehh9ze1V/b7TDPR3U70oI1MJONZ5Iyz+5oHcWTRSVscDw/m0TnDxSbjRAqzsKUU0X0nem1CJ7rfLhXqo5FMdPEJqTPRLYVFg4GnIFaH+6ac9WDfJlWPOJd0TnRb5nuwIlNEpD5virG24xAp7Oq5ll0Z00UyE10FAwx8jZPb5bfdE1F1u3Za4lx44MjiRCentmxLKs6lNDJwzMh9YnOiy2Wbx4/7iewvvogu9qVZmDuJE52d0uZ+pd+bx878fGZkoVLJ0G7t0sa58Hpj41yMwWvXMtLB56FsBx1/3gfyGNXEONFlnQP6HR8DmYnOxxiZ6FHIRb5s2TJVXV2tZs6cqQ0qzKuvvqoeeOCB0OvPOuss7S6n13/44YfqC1/4QujvF110kb5em1/kWm9OjOnfUU07f4weNHvqg9Xq5n9+mMj4ARoODRbf/+ZSXxyVg28A2Jg4uLMa0btSm6EemrFMtQRenJ9yoZPLPm52GAAAgMalWYnot912m7r88sv1NNODDjpIu1oqKirUfffdp5ozISe3TUR3xKWkE/BcgtSGUCa6fbTeJUqb8QtJnehyuVJYSCLWmq5fysqlBxkpHrLoZIpo9c1Et7XLVli0W2XYiU4P/+bAQLo4F/l6duSameimEO9yops59pkWFvWz62PEzLaGuFLmibmpwqIq6kT3to/asr/ehUUDscTc5rjYEl9gE2JXm5hM9PWW84FyyFPb5+63DXGiZ3KM6DlSur9jnegJhX2/KG8kE907bqFM9FrnceH2sFOaxKrAER11orNISqJZutiTVHt4H0Rzybfs3qe3I86Jzsc6FOdiZKKbMRjhwqIiJkUWFhXnjB/nYjjRXTEzLkHGvIaEYqWM7PHAiZ6C1hjMAAhfH23CKR0HnoHD57atJoIZp8Pfx4ront+aFscRSG2F69gX0bntBSpwj3vnosy35nXJfsgDNPQ3KUan8rBTy9qpo3+i0Sq2gWXbgJQ5q8smdHOb5PWeC3gy1A+CQy6uZUUWJ3phtO+ZUSROEd0oLMpQEdH0cS7xxT7D+8Xef5PmtvLmSMG+SzsS0b3BpzSZ6HJw1S8YLWJ0ZJyLuX0AJGHyAV3VbV8dpa9ND7+9XP3qhU+bukmtgsfnfK4/m3p3KFenHJoqGglAHHRvyG70h2YsbRG1DDjK5YSDEOUCAAD5RLMR0ffu3avmzJmjpkyZ4v+usLBQ/zxjxgzre8gls23bttBXPmJz70rkg6TNuc0PlKZRw+lETxDnYoqELK6Qm8sUfqTokG5b6O9yinuS2BCzLSzEhx2yDie6Q2CNi3MxC5kG7wmWxX/v2i4sopNQsz9DJ7oUc1yZ6EnjXCJO9IS52DZxwiVwm8JLn44VQSa6ZUDFzxjen9q3kjixPl0esy+ix2Wi18RnopvvXbctKqIHcS41WRfRdWHRDFzs9Freh4ErN8jizmqcizUTvc4porOIxYKsjE0JMtGD967zCv2RyBXMDogR0b3/bZHG1NTNu/Y5+yxto9+HSNw3ss3NLHNX9IRZkFTun1QR4fBy/L7muM65tjauf8m4JrN4aKrR0TgXKe7LASUWkPlhkweM7JnoynouuTLRQ050EtG9ZdJ5y8vgvh80vSBSDFTmW/N+tTnRTRGdrqVUs4K31/ysk+eM/JstQsSViU79g5fP75PXCbOINi3Pj91Jl4kuI6iM/sSYNUvM9kmoWCfHj/Egrb2waHInumsmWWInuh/nEnai+7E9jnsLU0Q3iwXzMZCFRf22IRMdZMiXRvZSPzktFVfzm5cXqfveWNLUTWrR0Hl9j5drfdlRA1HHACTmpIN7qH6dKvT94GPvfK6aMzRjjOJc6OP0eOShAwBAXtFs7kw2bNigampq/JxGhn52FSu65ZZbVFVVlf/Vt29flY9IPTRdYVGbyMQuxXZGhqk7ziV9YVHTodu9qsx/aJZOZ91m+aArNsbm5iYxIhTnkiAUm4UMcjyzmE8O+pCI7i3H3GaXyzdOYCTB2ibuSrHTF9GNTHR6ryksmA5IE/n6to4cWjPOJdK8gkCI2VHd8DiXuGNjbl+fjuXWOBczT1iLjI7c7eSFRVW94lzCglQgMO43jqPNiR7EuQTHwBRFpVs7G3EurjgGciH7cS5ehI/eDulE50KuDY1zqU0Q58IilnYkh53oJIybYq4cBFm9dU+9nOhmVrS8lrkGZVL7SAhujszwSJyL+FFnoltc8EGRRRHnYjiVM3Wix8UFmdcTP87F+1lnokcGCYLtM0VEnYnuLbO9VyjZKvr7MwGCX0kHsIl0/Os4FzHAwPsncNUHwjKLnmacCwmiXPjV9plYJJZLlJUUaZHbF+WNSBe5DPm3UNFSR42IcI2FsLAvr9VmEW1qq4yuictEl4J5G4uwbl7r/dfSeWc5R2g/8L5gbEI5r8PmUneJ2CZFmYrooTiX0rROdL7ehq8/IhPdjwAqjmwz4lxAffj6Ef3Vd6YeoL//76c+Vn+b07wFunzm3x+tUcs27lIdKtqosw/Pz+c2kJ/Q/cXlRw3U39NAjGlqak686LnQx/bvFPkcAwAA0LQ0GxG9Ptx4441q69at/teKFStUPmITHiWhh/qYTPRSw1XmypvemEBEN4VSEhL5gdsUI6RwZXMISsiFzk5V8/UuWOygGI7OnvOb2l0tXNa8HHP/uQTWOIHRFINty2JxyhTRab+ZIlc6J7oUcyq8OBdbm+KEN3JwciSAdPpnKqJLMdh1bMxl9upQnqawqNuJ7hIXTaSLOFJYtCbDTHTfiU7O4dR7u3uxPLbzobKc41xqchTnEu0fLgHL6kSvZ2FRX6jynej2fW6b8cFIJygvzxfRhROd1yFjHtZ4TnQSzdIV4JTtcYnoFDXluubRe/n9suCpLzJ7USOyUKS5rlSkhrc8iyuWzhcpVsv3O2NmHJtrXufjMtH9OBdf5KZBAu9vRqY3bR8Lssz67UGcC4vo1kx0T+g2nejxmegFooiodx0vChzjPFNGCsscv8HnIvcn+vzhAQDZD6XLPuRE9z4PA1E+PEAmr2/yvA/N/HJmogvnuCHsy2u1WViUjpUZS0RI8Z9dl0VJnOiWOBcS9W1xKp3blkaiTWRBT4bXYXOpR+oAOAZak4roNtc7tTE4zvFxLv7nQlF4YCyIcylEnAvIGtccO0RdOikl0H33bx/4IhfIHnR/O236Z/r7C47oH1vgGAAbXxnTV4vOFFv29LygKHJzA1EuAACQvzQbEb1Lly6qqKhIrV0bvmmln3v06GF9T2lpqaqsrAx95SNS+LGJivJhPy4T3XSv2kRQEn8oU1wK6jZR1hy9J3GCs2qlCB8nitocAOu2h4WMJJnosnCcLDpnc8iaIlqmhUVZLN2fMBO9ixHnYhNO0mWiS4eseQyrPAFXCvE24Y30GBaQZE5uppnoca5j/zXi9yS6sVNbx7mEMvHZBRuIsQ11okuHJW9v3Dby+6TQx0IpZefu9drWozJcIFZCkRDmcTQzoxsU52K8l5rqmr5Mr+U+zttP22iNc0lzbrGT3c9EFyJzSEQPDazUOgYpgrzmPd76ZbE/23VtlVfckDKQk4jo/BdHeogWQmWRY4mcdUDCdpBtrkIDPW3inOhanI620y/kKmZasDuZBVZXzIxra7lf+j/HZaL7PwZubnO/+wORxYX6S8JFJol23rlszUS3zASQx9iEzlX+C33G7OWBCnKMG+eu76LXTnTvGr/DcKKTiC4GwILtr7VeP3kgyhTlbdc3WSdEbvs+33FtfB4WRQVwPgfltdq8NsnrX1onutjPQQa7kYlucaJTnyt0OtHDn1flluz07DjRk91acjvLIoVFeWDCfu8TrF9ZnejB7IViv7CouX0AZAoNfP3XF4arM0f30f3smj+/q2Yu3tjUzWpRzFi8UX3w+VZ9Lb9w4oCmbg5ohtBn10Ve37lr+uJmWQyYZmy/7V1bpkBEBwCAvKPZiOglJSVqzJgx6qWXXvJ/V1tbq3+eMGGCas7ID3ib2CRjNeIy0eWDuGtZlNFqPoxS0bXIOo310A0tP4CHXHsxGde2tq713KfBa9KLj7x99PArBRGbQ9YU0VxCou33/ODuinORLu0gUqPQd28ysnCqXl6a4ja+e9VwUhK8vXIZNuGCWm6Nc8lwKmOc65jXLddP7WMXoengN4u+mo5p17bEx7kUZBbn4kdI2DPRuW3kNndFqLATXYpjppiciYguz3dyQJvvJaHMLHAp18OrDsQ7Em+jTuV0beLt5ePkDziw8Os1szpm8EC6u/l9/HqZPR4UmQ3atEbGufDARtzDThonuhbR45zoYvvMbHMzy5yRbmGZuyx3Q7V0onvft0noRHfHuYSPnZytYGai8zGQbm4zHkdeY0wR8fPNu/zv23szYbiWgG095sCC04leZHei6+sczyJhEd1bNsnufM1j57jvKm5T5IvJodxyHmTVDvdAjGUR2MxYt13fZGFRPoapZQfXrvo40U2oD/rbmiYTPRTn4q3DjM6xOdFp39ouHyQmR+NcbE70wgZnojsSfhI70fk4hwZLxLnC55z8XJADXHvEwAv1aTk4hkx00BCon/3fmYeoKcO763542YPvqA9Xbm3qZrUYSPQkvjq2rz/zFIBMOf+I/vqe4ePV29TrCzeo5sarC9bp+44h3dqpgV3aNnVzAAAAGDSrp4nrr79e3XPPPerBBx9U8+fPV1dffbXauXOnuvjii1VzJhznEv27fKiPixmJONEtr2UXOT1YUsa4LZ5Fr9NoCC07ELCrnUK9dFzaBPL1hhM9SWHJQCQJnOhaRLc4ZBviRG/nCUgklu5PF+ciHLimG32bURQ0fWFRz1lsZPoS7P6XwoxtcITEKl9El4VFG+BEj4sOCtpX6k/7J6Ffto33kRRa0hVIdeEXNbQ40WMLiwrhjmEhSovoIubCnPZviugpATssutZnsEJ2LTpHzPbLIp3WOBcewPHOX5n3LduSVEQ3i8iygMXbKrfNPKf5vCNhgR3+LHDJ7eDly+tXKBO9MP31gP9i5j138yKVyLnsGpQxnejcHXhf8naYTnS5Lu3wNmJg9P5hEb221h9kMJ3Drna5tjbSv8SxNE8Zv7Co305L5ntN0C5zlgPPXKHPAzPiJ11b9UCJQ5TUTnR/P4fbwH3XF9H5TQWpa4oUvWW+dSCiRx3KJP7a41yiM6hS2xjsU/kZKH/vD87WJshE915j1q8Ir5NDcVIDBkkz0fk8ihYWTe5E79K2RM/6kFBufOT9SeJcsuZEVxHXOx1/bgPHLKWNcxGDObSPd4kIIDofKMrG3D4A6gsNxPzua4ep8QM76dkgF90/Sy3ZsLOpm9Xsmb96m5r+6Xp9Xbj8qEFN3RzQjOnYtsTP07/rtVQ8UHPixfnr9P+IcgEAgPykWYnoZ599trr11lvVTTfdpEaNGqXmzp2rnnvuuUix0Xxl8fodasItL6n73lji/45cafI51DbtP5Q5bi0sWmN3onuvve6R99QXf/u6FsB4ijy50vjBcoMQxW947H110q9fiwi/tGwWIzZ4y/ivJ+ap4259NdLWO15ZpI782cuR6BabEz2JyCsFLp6avcEsLGoUGgv2jX35tt+38xzlu/buT5uJzmI9iVWmu4/c/qGfd+9Xp/zmdXX9o3PVn2cuV0f870tq4drtkbaT+GEOhPCy5fGw6c700MECfJLCoovW7dDtePCtpfrnP769TPfN+Wu2Be3aX6ee/2iNGvc/L6o3F22wLo/aV57OiS5EKVNgyjjOJSYT/S+zlqvx//ui+kRuQ1wmuhCw2xQHfctEzjTgQQAzQmnOss3q/Htnquc+XK2G//A5NfS/nlH3v7lEfffx1PlEuc40PfOYX7yifvr0x+HCooYwrYs/OoQeKeTz9tN+lstIHOfiiWT0fjn4xEIlO2ZNAddWw4HaS/tQZljL7PGgL9RFMtFpoIiPjyv2hNdNmPrgAd3b6/9vf2mhemjGMut7//rO5+rH//rYb1cQ58IDBWHxm5FaoBnn8vU/zNTHPIhzCWY2+JnoxuAAZejS+UQuo9PueFM9/YE9r3PW0k36GjpnWer/J+eucu4Xastbizaoqb96zVJYlNcftMsVFUQiNR+Hnz49X0391XR9LOl6Rv2W9788QrQeM2Odof3sx7mooI/qOBfj3JUuer7mbd61T1+TWPwmUdcfALPUbqD1cV0I/XrvusTCMQnlVz88R51+x5teBFKwjFVb96jJv3hFn6PhvPVgloFEftYG0SO1/ueHiyv/OMcfPAo50YvSOdHDhWrjBmhJ1JczKGILi1qEcj8TPcaJTsIhffabn3XmNqSDz6cyMYOgsjwYLKHc6QHfe1qd+KvX1M7Q51qN+u1LC9UXf/uG32bu89Rn+bpkzkaQ2wdAQ6AIonsuHKsO7lWp74np82D11iAaC2TOXV4W+hcO6an6da5o6uaAZs5lRw3U1/s3F21U8z5vPrNF6J771U8gogMAQD7TrER04tprr1XLli1T1dXVaubMmWr8+PGquTB76Sb9AP3sh6udgqg1ziVUXCsqjLFoSq6rL4/u7f+ehBsSif4xd5X6cOU2NXfFFrWjOvXQSznWLA7ywymJZv98f5X6ZM129akQefkhn7OveX1/mrlciw+h9tfWqV/8e0EoZ1dCIkWmTnQWWsj9wxnh5J4MiegWp6trurtepqWYY7vSoIBk2sKiIot10pAuvqufRXPJS5+sVR+t2qb+/t5K9dL8tVo8nLlkU9B2sX3mQEjPqvLIMq1OdBU40bcnENHf+myDbgf3RRLLqW9SP/HbVVurXpy/Vg+GvOLd0MlirrS+Iwd39qfik6BjGxCS/be+TnQ5aCHXL7eR9u3abdXqDTF104wo0d8LITSImAj6ll52UaEa2q2dOqxfBz1rgzUpFshYxDu0T5UvpNOU0X99sFpvIwlxz85b459PC9ZsVx+v2qaWbtwVEk5tmehakI6Nc/FE9GKHEz3DOBc6PlKg4uPJx9JcTuh6JCJW2JHLIjodKz9f3XJ+8ve03/nw7K9HYdGpB2f2kKGjH/w4F16v3YkeinOh2R7e32kQ741FG/Qx5y5MfULOmpFxGbu8/XvZQ+/o8+mi+2er91dsiW0nXUN/89Ii57VUHv+v/WGmaHMgFPqzCUQeuWuWgxapxfn16dod6t8frVEfrNiq+y0xuGvb0HlCh9wlStJ+ZjfzruqgzoQcLOS+xYNrJHrSjJCDeqbql7DgzH+zOeX52FE75PWTi2ZyDNlqfb1boz8HF67bHokiWbZxl/rg8y2h/s2vMWflyGxyM2JGFs52QbOX+guRSA6e2oqI8iyPJA5v2kfmIabPp7EDOqmOFSVa9CPounaQ9z1B8RR0bE/wzie6Bo7u1yGy/L6dUp9JizfsjIj4xw3rprfl21MPiG3jxMGd9eDGEQM7659pvXTMh/esVN3bl0WufwvWbg8NytN185cvfGr0w+jnH/e/ow7oknpdgVKj+3WMbRsASaF74gcvGafjFug6fcG9s9RmS3FykB6KFaP7J+LKowc3dXNAC6BPxwr1pUN7Njs3+swlG/XnWNf2pWpUn+hnMAAAgKan2YnozRl+4JTTys34EVumr3zYt0a0eM5wmgb9y7NGqr9dPdEXrrYI0ZoEEpmf7ueOioJo7NA2ndr0eilaugS6dKK46US2FfCMLFM4Ddk5R8sJRY84nOjmFH7G5tLlPGDbFHnzPdIZ/a0TDlAf3HyiOtBzxJruPFnI1Ra1wdtni3MZ2r1d2ggdjSgsGopzcexf7jNmZIKE2mW+TkYHffijE9VFRw4UcS52J3ooziXiRFeJ8ONzhKhpCnHcZ+Uxl33HFKlSmegsLpLgFzjOaV8+e91R6m9XTdRCKm/jnr3hjOTeHcrV3Jum+u+TYjQ9FLKgRvvPlplMx8c810gMkiLSqSN7qRk3Hue/3hTRSeCTIl/iOBd2otMMlVDMU+r3vB5ZCyA6qBcMUrDAydujnegiYsF8L0P7vTiJE93fP2GF8Pjh3f1rXhJSDnkzzoX7ieFEN+JceN/Yriu0DH9mg7cvgnxvewHndMgZKyZ8rYh+ZgjHPG+fiDViQdaERGrKMQ8tqaDAzyanQaV/f/PoSGFRlyhP6+LZHbT94ezy8LnLs6HIMUxt/9c3JqmRfaoi7ePzwlbkWS5Xv96Ic1kk9iXtO/7MuPHkYeoA7zpL1zs5IOX6XAkNykU+R6OfH2bk11vfO0619walk2Si8/rMQR4btI/kYCMJ2/T5NKJ3lf79P6+dpGb/1xQ1+wdTVK8OKUGcuOeCMeqdH0zxB8vp2D9+1UT123MPCy3/5W8fozpUBG2X0L6c96MT1VDvs9DFny4br2bceLzvFOdj/tQ3JqUG39JsZyQCSxcLVqHPP9pX3F9uPHm4eveHJ6i5N09VXxrZK3bZAGQCndt/vHScLk6+cN0OdfEDs0P3ASAZ976xRF9njxzSWR1iXPsBqC9XeAMyz8xbrZZtbB6RSy98vFb/P2V4t9BnOQAAgPwBInojwuIZC5O2h3NrnItl6rqEBU4SbOjBl13RJFps3BGIr/QzC1wkIpgF0WS7TEwR3SzS5toekz0RV2t6YYkFIFo/OztpX1Zb9ou5fik+xz2Eky5UUVpkLQxqe4904HLbWBAw3y9d5NxOW840HQ8pptC90+CuLKIH+9u2iwsyjHNhYYyPua0Yno7/8da7wRDRZX9wxbkERRuzEOfiO9GD3/n90RCNZb6xNRNdCLvc/0hskfEF9BISx/gG1nfb70vtWxlNQe/jZcoBDDlLg5zL3I+rhVOVNksWjeT2SRFJ9nv9fu/1pV4EQkq8DTu86SudiF7mO9Hr/P5FoicPVNjiXHh9cl0s+LFg5TvRRU4xv852vGn/mbEn8XEu4YcKGljrmkEBMhqkiMa5hGNYGPn8Qu/h42C7/tHMDTmzQQq4dN2Nq43gqJUamekjYUHV9pnhx7nYMtG92B2irejz1MfNGA5aDl8jDujRXp8TchCPjrHLHU3njqyjIc8189wNPsNK/X3NMT1hp3w4f1x+rzPRxeATn7NcV0LuS2oLz16igRFeF13vbIW8zX4pxezAHR8dJDNz+4l+nSoiM46smeiiU9jc6ZKw4B6Oc9GDs8byyeHGA0IMvScaZxQMIPJ76TW9vBlSJvLYxmFbl45k8bbDNROHMa9J1E7uh/z5Z24fnYs8QABAth2vJKTT4BLNdLnq4TmRz3Xghtz7j8xaob+HCx1kE5ptdfQBXfVz0x9eD6JU8xW676bYPwJRLgAAkL9ARG9EWEBM5a6Gs2AZm4bED/suEYqFThZsfIGori7kmCQRJ+RENwQJFlZtlBQVhZy/rtdu2R0/lTUuGsIFCxkk8HAhNHL7yWWxGMPbEog3NscoFWcM/65YiAXbHTmvrsKijP9+I7JGOtP5wUoKqXL75LR+mnrPDkZ5HG2OVmpFJoVFeb+QS562xeZEp2PDr+PBCDMLXG43LUMKbDXeaxtaWJS2t85WWLSoKLQvbU70uEx0mYtMwpPMB2bRimFBhveT71z2Xufve4cDLeVEjw6g2CKOtKtbtJeWLff3bm97+XepAqnhZdJxNx3k7kx0UStBD8Sp+DgXb12ynoMu7OeL6IEgHSlwabl+pcTb+AKcen2eF93UEUmELytJ/lFGzWSRMSi8GQwuSqTrmr4v99YjBycZ6ktyZgNvGx8n18AjUR+vkV8A1jiHqMncffhvcqBObhOJP7KPm058WoUcpCXkIdJO9JhMdI5SkTMxaB28n+mcpX2/Zde+SHa1rFFA+zAl4MZnoksBl89ZMwec+zQX7KZ9IsV+OUjEfd0cvJYiL28/DWTRtdQW59JFiOi2gp08IEbw8QkNpHnfu/a1rNuQinOxFy2tDzaB37XMdA7ypKRz3JvXNpsTnQdRAGgMaPbFAxeP0/2OYr6uf/T9xCaB1g7V5KF7Q4p0OmpoKnoJgGxx1eRUkdq/vrPCeu+WT1D0Jw34033CxME4FwAAIF+BiN6ISKGSIz4SxbnI6A9LJjoLnCwESKetFG50BAqLRcVRJ3qcyKOdx6IYnOu16y3FROOwbY+JTeiMxrmEna7ktHPFLtgiTlICWVF8jrolC1pqbvzQzqI57y95SNmNuldkiwd5zOTiCx78SfzhY0oZ8CzA253ogQAvhVyXkMqiKS2LIn9s7knZf9jd7Q/ChByfxQ4nenSgxBRRkzxkyteECou6nOhigKfGF7ujTnTpmqbiiGEnuuF2LjFF9HBsh59H7+g7tB9ts0gIFhBl+6Rb2Iz54TZIIUsOyvC+qI8TnfpbkBdud6LzYIA8LiSMcoFJ3qdaWDfiXPh4RJ3oYVHbCgv24vhRU0sNp346qK3BQGNqQIxXaw6eyG5Ab+HIHxmTxegZAWKGQur9gUBLZ4GhLAAAbV5JREFU1yKbgCo2LSOCArDh38vCovQ3GuyQLnB5PnK+tT+YYY1zCQ/SykE8eYxNqB/xe3Scizhn5KwmKiCaWhcNHAZO4S6eAE/wuRnkj6fPROdzVi6HoWupHy9TWGgV+/WyM8hEp9fYrqPkTpXnr61gp2w3DyzKgT9en8v1HxbRC0MDTdkU0fkcdy0znYM8KeZgTto4F+FE50Fw17kGQK4Y1beDuvv8sfp8f3reavWDJz+sV4xXa4LuFx7wCtxfOXmQtSgyAA1hwqDOun4RDdo/6PW1fOV5z4V+9AFUawufYQAAkK9ARG9EdokHbBatEsW5iAd4Fn0kfhSDJwT4IhjFuUgRfd9+ayY6CxKu/PBM4lzWbctMRE8U5yJzq0V0SEhE9/YRC3++iG6JqLGJi2Enul0IldnVfNyk2MoueY5vqSyPCnssstgGAMyp8CRA6aKLnnCxeec+p9BYINyM0kmfzome+r7aGjVBYjwL8pzpLPsPUx4qLCpnTYRnB9iwDRrFvSausKgZDSHXbctEl/FC9DspbpnCoO+2944fO9xZ7GGRzMzDZ3RMhGNAwxTRU+7eoI0kEssinSxSS2FujzF1fKcll9mEb9B1bI/nzqE4DTmTxTboxGKoPK7UXBZgeZ9qYYtjRdgRbRk0kwUt40R0XoZ8yKb3ysz6JOgIEtEu2aZonItwous4l9R6bN2WrmXmDAXpqKbzzOWOrY/O4hIyZWFRs4AuXUPlYA4XLiZoH5pxIanZKF7f8GbFhOJc0mSiy0FAvsakCigXRT5LOpS3Ce834SDnwVNz4Je3j9dnE9HpOmyez9qJLtz5HPlCnxf7EmSih+Ncgkx0m4hO2yG1ZVtfleeyP0AbinNJ40T3imLzawpz7ESXM2NyIqJnmImeOqdVqLAoF5YFoDGZNLSLuv2cUXog6y+zlqtf/HtBUzcpr3lszuf6M6BPx3J1yiGpIpAAZBO6R+SYoAdnLMvrmgVBlEuPpm4KAACAGCCiNyJ7hFDJzl7TpWKLtzCFZlOUlFEMhIxGkPnQu/cG7tRSysY1psbHOdHpoZkfpklMduWnr89wqlyyOJdw/rQfTSPeu5fdsTVhEd22TTZhWQpk2+oZ58JCD7fLlr/KLmJbFI2ZiU7CDrWLYl0IjtCxOZtIRLBFiiQR0elY2uJc1m0LMoQ50zlORDcLi/LhiSseG1dIMnhN8H04ziXojwS3LVS4V7hUGSlE8XbTuSDjXEwxUfY7OTuEHeO8P1w356bDNTbORRcWjYpg/D8LdfIYmMfPFSsj8WsnUAFZkYnOm+7KROfrkbxWpdoczkSX7lDfiW4RI1PO2bD73Qb/SR4aPmdNF3IcdJ5xN0pF+gTrNItuynXJ2So2dJyLEKsZzvmm8yybziJX5EWBKCzK+zSIjAo70aVQLbP9GSly+3EuRjd2uaPpmMhBwHXeLCXtRBezmvi6ZsauyDgXHqAMXN/RTHQtzkvHt7ev6QG6o7FsmqEjP1fkbAF5vTJjwqxxLt5xoNfarqO0bDkoZhtIkcfS9tnC2+USl9uZTnTLe+uLfL8fX1WU2ziXdG22OtGLwtdgxLmApuLkQ3qq/znjEP3971/9TN3z2uKmblJeQtda3jeXHzUoMhMMgGxx0ogeqn/nCn2/TbEu+cjnm3epj1dv0/edVBAcAABA/oI7lkZEun1ZtDJFJZvOZoqQ5nt4WV080cHPw9VxHIGoLXPEdZyL98KgsGhcJnqyOJdMneiuiAuJFID4wZiEurCbO+xE715Z5ouJZoEn6SgPOdE959qOehQWtT20ty+PEdEtkQEk4EnxgEUlM989XWFR+XebiK77hRcnxOKWLeJmrXEsaf0cDxNyfIrBAylIsoAdN9sgUZyLjI+wOtHDAxMy+sbmRC+yxbkYTnRTRPcjazjORURByLa4NkeLc44/miK6LNKpl23krnMbpBuUt4NxzaaQ8MwFcmKbxYkJ7hKRwqKWGQa0G7jNfH6lRHQVLnBp7AMWlc3YFxv8F3nOyWOWVDRLFcMMnOjy+moK07IfpOJc3Oug5XCBVymaSoE2m7hcv9qJLvYRHS4pGMvzkR3YZjY9k6p/ER6kNQd6Xe5oEtflIKBst21WEw82+G2TTnTv2PK6QhFnIhNdIvuGXBavV85w4m1zxrkY17DiDJ3oUtTmAQGJnF3Bqw8XC413olcamejyZS7XeFJKM8hENwehcuZENz6v5EwdvoQgzgU0JeeO66f+86Rh+vv/eWZ+3gp3TclzH61Ryzft0jFeZ43t09TNAS0Y+uyigRqCCowmMXA1lQt97IBO1louAAAA8geI6E0U58KCtakZ1SVyosuilLW+CGdzom+MyURvIzKRM4tzqXEWFl23PXAvJyHJjYx0d/KDMQ1ISHHczESnm3J+qDYFf5tgXJQgzkW+r9YidJjiiBQ2zD4ghXx/+4rDhUVZVJICj163w61rEzbMAQRiyy6KZgl+Xrllt3V5a4QTnfsHZ2+7Mn6lA5p3l+0YB4J/ZpnoUkAtNTPRxXo4+ob7BbsUXZnoJNrEieiROBcxeyDVlvhjT4NZrr5uusapn0tHlu9EN5ze8nibxQxdxXFD2+Rt7779QSZ6KnoiPs6FXq//bmSi836tjnOiG9cy6SQ3l2liKy4rhbJ0MRlBW8Miury+msddiptpnehGbAojz18ayMy5iG5sBw1CyTxy+fkRcqJTrI4hXmqnuDfriIVo85R1i+h2AVsWUJYiesSJbrRNbrOM4OG+RdssrxWyP5jL1nEuIpIpiHOpDhXytg0YyXakvucBoNRsHROKwZH7SM54sRFkokcjqNyZ6CLORczsaOxM9Gw50eVgjq177awO72darbwuEHHnKgCNVdDwiqNTwt33/vaB+vdHa5q6SXkDPevcNT3lQr9gwoCM6poAUB++MqaPvh+hZ56nP1it8o0X5qdE9KkHdW/qpgAAAEgDRPSminNxCKLWwqLG/HkpFHCBUnp+7FBhONHr6kKxKzJHnMQlfiBmoSBtYVEhfLjiXHjKfjYz0WVRPJmJLospstAX5OMW+lP4zbba3NlFGca5BIVFpTgSfgiotDjRuX1yWdJpb8a5yFiDoBhond2JbhE2bAMG5nGmKYQ21m41RPQdgWNdrosEMVstqLhMdH5/EjOIFFbl/pZCnPxft9Ub5Akc47IYZSCisiiu+1YmcS5GAUlz3/fqEGRN27KW49BO9ML0cS6p7GN7JnoyJ3pQEFG6jc04F3Pmxj6bE72ABoHMOJdAWA+c6OFl8T4vSuRE92Z/yHxp8eBtE81skSe0KhbHqTlS+DaLmplxLhXp4lzEtYqR56/NqZztyAvaBimiysgaElilq1q6v2lfmv2e+rs5SBtxojuEUxZ8TQE75ESvqVUbOI5MuOLNtnG3kK7vYPu8Aa1CGiAQAzuOfHVfRPcjmYLCotv27A99TvsxYUa/DcW5+DO66qyDJLJYb5IZEzYRna8Hrn0dLixakN04F+lE50LKrjgXx4BKQ9bZw5tVJtlRHZ294xr4BKCpoGvxjScPU18d20dfw77xl/fUW59taOpm5QVvfbZRzVu5VcfKXThxQFM3B7QCaObjRV5fmzb9s7wq+kv3WTMXb9LfnwARHQAA8h6I6I3Irn37E8S5RD/UzankUoxjQZSmzPNDJD/U0/2BdIyn3NsizsUv0laXXkQ3hA/Xa5OId6FtsxQajLxGuH75wZi2jQuIyeXw/qN9YcagxIroBQmc6GkKi5aXFKZ1otuWFQiy4VxnFn66tDUz0e05yFYR3bKt5oyDlZvtTvS1xqwCel8QB1QUelC0uSt5oEFGL0RE9EwLiwqdREaopKI0ai2Fe6OZ6PLnIM4lLJBGXI2GE11GQXCNAUnPqrDwQ+eeKybIRLu6E2SipyIMwhEvcZnosn9o0VsUFpaFRdPGuXAmujjX6D0s9LErnjaBxTwWN02RnEXwTJzooXPOy3VPfV/k3GfhfVPjH1+dF+45623O7nBh0ehAmdk+nvkhjx9fhzbsqI7MGGgInMcfbUddqL/TPvUHCgoLQoOyMs5FFnhl1nqzUeQgrXmEXO5oXpYpjreR0WDaiV4dus757RHnY1CUNOhP/AAsM9Fd/aeLVxSVoc8wuU+oqClvurzu2Yroym2TbaLrOF9P5G6k63hxmjgXiSyUynDfdBYWFZ81dE2wXSfrixTM+XywLdM2CFVf5GK6G9dS2/VNRjQxyEQH+QCdE/97xiHqxIO76+vdFQ/NUfM+36paOyRiEmeP7YvoCtBonD+hv/5s+GTNdvXawvwZ0Hp1wTp9nzG0WzvVv3Pbpm4OAACANEBEb0R2J3Ci2zRFMwZCCu1cOFTehEoBUDrDdY64tyyKnwhENM5Ej3eis1Aop+A3lGROdBY7KBM9EAu27trnjHOhB2ozBiUuE50cdizauIoy8r5zOaOlK9ZVWNRcVqrtgavZlonOLsm4OBeZiR5az/4kTnSHiG7JRJczGSQ2FzALT+ZMCvn+ZIVFecAiHK8hhRw6pnKf8jYGAltYYGExikVNEp7k8XMJMrs9p6mMgjDbQvSoCjvRbYMSLpyZ6N7/fB0psjjqGZtgL4V+ep8U/3hGC4mqfP2odRYWDQuL/Hp2/rKQLJ3oPBBiDhKacS6xTnRrHYJiq2jG22oT+7bs3hvKauf+aRMoQyJ6QYEqMwbKTOTMBobP31WO2KT6YuaXM3v214ZEVFlYVGeie4MGqbaFc8fNfr/Gm40iB2mTZqLzAEokzkUMFlJfccW5SPi8k/uVt0lmorv6j82J7r+vKJzdLq975ucKYzs/6TrOYr/MgTcz0eMGYuT+le/hc8u1r9uVBp81slBvtuNceD/Ylunqj/VBDmSbAyC265vNiZ7NIr4ANAQ6f28/5zA1cXBnfX954f2z1KJ1O1Rr5aNVW9XrCzfoz6nLvJxqABoDMgOcc3g//f20V1MDOfnA814eOlzoAADQPICI3kQiOruBTX3R5kSPy0Q3i77JKdfEFiE00wO+LCxqTo3PKM4lSyK6WTTVRhBFkHpQ5naQGOYU9oSITg7QJE50FuFcedKc9RwqdOnIZ3bFudjaIKMWSmyZ6JE4l+jyqBWZOtG56S4Rfb03AMOvS4no0aKWLhGd869txWPZRZtJYVFTJJFC/k4jRoEjIvxMdEPgsTnR5fEzRfcyMxOdoyA43qDY7UTn/bfOyJh3QesOiXTesnmf8yCQdqJ765fRRoScpcGUCte2Po+8dWzWxRTrhOCn4jPRjegkfwZMkeFELwyEQFdf4H0eFAWMi3OJulRlv5ODILytNnc5Db75cS46L9ztRJfrImGS9pnZDyUsotoy0V3nWX2hdtiaQp8zqUgXMVAgZvPIQVkSe3kbaV/KCBRitSeiSyE8konuiBjxnehmnIuIraK+zNe1ThaxNG6/2mYfmbEr8Zno4boG7Mrn655+HX+uxBQWlTO6+DNero+u41L8NmcsJXOiF6TJRDcLi+ZGROdj73KiZ4ttotiyrTDq9gQiOpzoIJ+ge4i7LxirDu1Tpe+lLrh3ZtYHVpsLd7+WykI/5dBeqm+niqZuDmhlXHrUQP35OmPxRvX+ii1N3Rx9PzJ9wXr9PUR0AABoHkBEb0SkW9SPmzAUCRIGqPAjQ64VM2dVCo8cw9BFTJk3oyjk+qWIzg/pJCbQOuLyeqWILnNyG0pmhUULQ8KbbAMJGCQGyvgOdrDRviaxdKcnLO6tqYktLOrSdXfurfHWIeJFCt0P7RnHueh4jqj4xgLWqq271YI120Mij9+OgnBRUn893rKpT3G7uc/06ZhyS6fLaebXkdhly0R35c9S3yb3sDUT3TuW63dU621iMVsO5NA+or+xG1YKQ0EBPbszkSIiaJkfr96mf5YZ4/pndnUL57A8fua6+G8s5pl90nTm9xAiOu8/09nvotjoB3xczX1O5zm/zhS6P98UzbmXxU/le9kh37akSD/oFwqBmQaUTMccCYq0b7l2AItXfuFTjjRJ4ERnEdyPfalJ9ZnP1u9Qyzbu9F9HQvDCtTsscS6ysKjM6S9yin103QjiXKJFYuOc6CROx2Uts4gqXbl8bc40D52FUSqSbMMWYSH3P/8tVVhUONFFXynyokxccS587klROLETvcDuRKcBNO4rdE3hyBjzdZKgDoDFiS5mErgmNpnLpvOFHfncFpsTnvfb/kSZ6LV+O+WyOlS0iZ2xZMKHR/Y9XkeSTHR6TSjOpaGZ6OL9fP6ahZTjCt3WB8qmj1uuOUiIOBfQHGhXWqzuv+hwNahrW7Vq6x51/r0zszars7mwYtMu9ZRX1PFKr+gqAI1J7w7l6tSRvUIDOk3J24s36mf9bu1L1cg+HZq6OQAAABIAEb0RYQFOCpmmIDF76WY15qcvauGKBJnRP3lBPTRjWdpM9JAT3SFq0PJCIjrHuewPFyC1QUIeC1KZFg+1wQ+4mRUWLQi9V7rsl2/apcb89AX1ijeaTyKZjHP54m/fUMf98lUdH+AqLGpzU5uMv+UlXdldvo8x39+urNhacDMS5yIiR6TgzOIZC0AfrtymTvz1a+qrd82wLtMmGJLTc+Ha7WrUf7+grn54TqjPDO3WPu32yteRMM37LupEjwpDsqChCQsjP3v2E71NJ9/+uvrdywt1f//H3JX6b+fcPUP/7Yzfv+Xs17zNZgQP9edTfvO6P9CSLhOdzgU5/b/YGedSE5k9INthOtGpzw7w8g3XJHSik9uUi3TGCcIp96V9MOPv76X2oRR85TFLxbmkfl6ztTo044HFOxqYmPyLVyPLJrFwwi0vqVN+84a/LLMWg14Otc/PV7dH+5hOdBJ8/+fp+er4X07X6773jSX699f/da52Dcn1mUKZjHbxBx4sAhzPaDFd2vZM9OB7/nPcdcIXey1O9EwZ0q2d/n9w19T/BBVhk+2xnRNmdnzqPAxmTlQZonxnb7DRGufCArcYpDU/s9JlovPyg98X+jMFpn+6Xi3duCvtfuJoLOl2pm2i48eXTGo7DQTZMNtA18X9phNdFDJl6DVyHYxsB5+XdO3mz3i5v0jgDn1OpIkZ4T4tr0Hc91yf7TI6jPpxqABzA2NNZIQWD4bZBmxdAn99kPvXNkhjfobra6HxYYs4F5CP0LXo4UvHq15VZeqz9TvVRffPckYItkToM50+k44a2kWN6F3V1M0BrZQrJqcGcJ79cLVauiEwbDQFL3hRLscP7x6KcQMAAJC/QERvJOimUWZxb9m9T//OlglNv/9w5VYtpNsE35AT3RfRAwHA9aBNbnM/E13nb3MOcfqMcy2iZ9FpxkJCksKigVM07ESXU74JuSvpgZ5FmWUbd+l9SU5gclZu2x19YCEhyOauY6jYC0HH46NVKXez6RY0M9BJzHAJJvbCooXqwO7t1fHDuqkLJvT3t3dk3w7q8AEdtaNVigskrp88ooc6d1xffeMl3YhyPfe9uTSUucd9hrcpHSwI7zQGYSQ2UYX6qev4VhlRN0s27FS3Pv+p/v6Gxz7Q58X7RvEt2wwL7pOmE52OOT2gEgd0b6fGDugU+nsQH6J8p3rIiW6cQxzNwwM37MImZ5luh7H9B/Ws1A+JF0wYoNp64q7M8I+D2iad836RTOP8SxUWDbfz7MP7qh6VZbqvdG1fqs4dl8p+JKg9w3q013+j3/Py+DzidvIil2zY5V8Xxg/spA7uVZnaB7v3qc1iW8w4F7kdvhu6Nj4TPRB8a9V7YnrtXO97ec4dP7yb/708v6Ro9oVDeupjcOLBPUL9mLbhp6eP8Ae3dJyL1yariC72L4uJcSIoi6jyWFEfkT/TPjkkRjz42vh+ekrv904apob3rFTfOfFAXZSOznO5nLalxfo40vGk42oi970c9LnzvDF63zxw8eH6d7QMusaM7d/JXbhSZG6bp7TrPbz+CYM6qxG9K3U7vzq2j+7PRw3pqq919Dv6or5pux49dMk4vQ9+f95o/xjw+sglLmM9aNDy+hMO0HEJt3z5kNBy6HfjxDVAx7n4WeqpfWq9ftbUhmaLHXtgV/Xlw3qHBmz8GV01NIssdV50a1+mzhzdR51ySE/Vr1OFc+BHQsUHR/apUtdNGRrpe3x+ODPRQ3EuRiZ6Fj+3+X5FLrN9abG+PnDObDb49tQD9Tly61kjQwOKLrQT3bj+yGMEQD7Rq0O5eujS8foe9YPPt6orHnrHH9BvydD9xCOzl+vvrzx6cFM3B7RihvWoVMcc2FU/A9zzetO50Wnm5YvzU89mUxHlAgAAzQY8ZTQS5g0yPZdTMT8zzoUhofPAHvYHZilMssglp6u7BrJ376tVFTYnek1dWhG9pKiowdmqEu3m3JnMiW5mFrMTlMS8uIdq3icLRRwF7dcNO6NOelp03PZNO3+M+u9/faydkzJORYojkQJ6VKyyTVFoBoJNRJfbR8LJvRelxC0pDj521UT9/QX3zVKvfZpy29Nr7/z6GP91ciDFX09NbSTjnYvRstM1HSx4U5urOc6lKJmIbju+tM9k4T1bm8lBbgquNodGiR742B+Z3s/HnATM57812doGCQk1ceKoWaSWZ25wVIfZd0jA+eOl4/X3/+8v7/nblQQSo4utmejh9ulIFkM4OmdcX/WjUw/2f6ZBo/veTLm5+3Vuq3582gj/b39/9/NQu/gYsgDHtQRoEOLRKyfoqecEx2/47TDiXOTvTRHdzJYuM53oteFIH5r9INv4+FUTQmK5dIVLcZIKuJH4/MbCDf7vzjist/ruScNCWd/SpZ2ksKi5Htd5LY8fCb/Uf9jVPaBzhfrXNyapa/70rnp6XmpauymmMs9ed5T+/4hBnUOOJYLiqr7/heHq5i+ljveA7z0dWo6cBeDHDxUWaPffM95yiUsnDdRfZrslcj9zgdd0DmQ+9h3blqinvhGsj+jXuUL9+1tHq3QcfUBX/WWub7933DjqjM5zOj+6VRapf147KbIc6jN/vWqC+r/nPlF3vvqZJ6KHr2XW4sg1QRQO8buvjdaDF+H2BLVFdlZX+58F8jxM4kSnwRP68pcr+6P3rUtElwO49Bo53mi7NtcXnoUgr3e03+j6kO3p9nSOEPM+T59Zq2dlGIOs6bLnAWhK6P6LBjLPvftt9dZnG9V1j7yn7vjaaOc1uCXw0IylumYKDWYfOST1mQZAU0EDOa8uWK8em/O5+uaUA7TxpLGhGcZ0P0r3lRMG45wAAIDmQsu9W8szpJDKoiSJRS4jNolHrgxduxO9JCTa2Nzou/fu13EmgYgeOOjSFQql18c5tesf55JBJrq3TWY+tY1iR2FREpBZRI460d2nAz2gs0i+zsuQ5t8zHIfB6GKVDsFNzkqIE/FMpFBpvtyWKUyah5lfzyIl5Xbb3JcmlOlLkPDkcqLb3I5SoJTQcTFdgya2/mjr03zMTCc6H3NXRITpOqZ9L4+VOQOEl8PtMmOUzO2X+yfTwSediS7jIhyRMfRrs8+Y2yVnLpi73HxY5+XzYAUPFpnbGBHR2SVrrIB+n9SJHryuNnS+8mCFq9+F41yiMwlcNQu4zSQKBnFRDY9zYczjIvshO2TrMygpM8HTxcTwPpDbmE6gcV2D5Dabk6dcM5/iCrA2BCpMSpCQzuejjE+Jg/sw1cVgcZz7rU3cpsLXctDatk38uUTXOv+6YLQnVIA6YVa3XBcP4BQ5jl84Ez0c55LNwW8+f+Uyk3xuNYQkoiI1y2xHeRt4REB+c2ifDuqeC8fq69K/P1qrvv/EvMggZUuBovAefCs1K/KqyYNDMVEANAVHDOqkZ+HR/SUN8DQFL3y8Rv9/9NCuiCADAIBmBET0RnaiU6YtP/CTQGTmyzL0N85fNpG52TYnOmEV0WVhUR3nwg46eviPzzmXhUXTkaSglx/nksCJvtcrAMcP00luNEhAsgkrG3dW+/tMug5IR4nbPtqfLFpJJ7p0R9O0dilaxsa5CHHZF/ES7F8p9JvFL11C0gZj0EAOvMQV82M6lJf4bXaK6K44F8vxpXW6it/6bRRCqmt75XpNt306oTHiRC8KD6KYIjrnJdPsETqXOcOUf2/mjTdExKIBHSnK+3EuxnJsxfRYYLQJUOaRMIut+iK692sWs3kbWWzkYpNBe1lEN0R+kT2eLhM9yKinmRP7I31V9jvZDVxxLiyoyX4m/84P8NQsuv7p/ZGmsGiSOBfGPFby3GQRtT4xG3FZ6+YlP9j34cioOFzCd4XY5mhh0cLGFdG9fasHf71rW9LceT4u2oluZKLbPrf21daFBn5sgnHQHiHqG7OCksS5xIvo7vWbcS4U0xaKc8mqE53XIa53WcxCt5Eka52OpzlTCYVFQXNg4uAu6rdfO0yf439953NdJ6Yl8ticFToGrm+nch1DCEBTQ/d0V3nFban22M4mqE3AMZsU4QcAAKD5ABG9kWDXNLkQWbgkMdd0ZjL0MO4U0S2FRaPF2woizndqAzugtROdHXTk6PPECBKC3U70ZN3FnO5ugwWtjJzoMWKHCW2brVAc7VcWOqgSevD6+Mx3nbHeLiyimyIR3ZDJddJ7XG2tFrMMTKd9HFIQMUVll5C0Wbi6KdOWhGCOg0giPnEeeKwT3Sai18U40dNsqy1eyHZ4+Jix8Gr2X9cggc3BLZ1RZvQK7yc6Xym/nZdRWR51FUdc6Y5+Fdc22T6XiK6Lg0ZEc3O7gp+jxRHt7eR+td5w87NITrUFbOvkGgt++4TIz33cvN6xoMyvky507rvkzAsK2hapAs62MAra2pzoYfEyeG24sKjbpS37BAvySa8/rmPNInx9xE3Zl8z+Yw4uysKicQMFce3ORye6zCB3DSK74M8wijbjsYAgziX6ubVPFyCti90mP6Nd1BYxBzQzKSzqv8cSJeQU0WVGu76WqZxkotuc6ObAXbaR7XeNvdIMu4gTHSI6aCZQ7Y6fnXmo/v6u1xaradM/Uy0J+vzh3OnLjxrUoiNrQPNi6sE91MAubfWM3Udmr2jUda/YtEt9sma7vj84blhQ6wcAAED+gzuZRoKjWegBmoVWckW7nOj0ML7LEeciBSkWRE0xVD6AcxwHOWhZHJSZ6HSDu1FEfNiQzvV0JBGZgjiXemSiJ3Si0+CBKXroOBeLiE6vK0kY5+KL6JYnenkctBO9JIkTPZqjXB9BgQRGLnTpEqRl1jjlktty1GPjXByZ6La+QeKTFKDkPrK5ytPGucQ40dkZTrML5CFP6kQ3xWfTiU7r4cgEzlunrGcWWW3OccY1+NStsixZJnpRTGFRs5hnpLhnYeIsazPOhYsk8j7kQR5nnIshpmlHPgu53qrNmQksbPPxWOedW7yvqf9QIWA/iz/GiS6/Z0FNulNlRjL/Wg702DPR5fcFiWfCmAMU8jzja1+94lxinOjmdZGboONcvPMwXfSGS/iOy0R3CfM5c6KLDHKeQZWpE32XcJyZBasl1P/4epnKGrc40f3aIrV+VFjk8zjUD5OJu6Gitn5bC5yvlW71opw50aMieq6OMyOvK3KwIJ0TPelgBQD5wFfH9lXf/0KqZge50R+ZlSrA2RJ45sM1asWm3fq6eNaYvk3dHABCn180sEPc+/riRMaubMEFRcf276ifJwAAADQfIKI3ElwAjR6gOyWIcyHhc4/Dic4P9SSg89s7ekKnbYo1O9FJsN5VHWSil1gKizpF9OJU0csk+adJHl5ZPJN5sy4CkdmLU3A8SEuondRec7/QdgYiellyEV3HuZSG3LI2A550IMbGuYQy0d2ZzCalbdxOdJeYJAV7FqdJpKTtTeLg9AuLijgXUxi27buUy7fWHueSZlNNodZdWNRzonuiWGmbolDRUjOb2OlENw6mKaJzu4lFa7eHfpbtML+3/cy4ihhR26Rgzvva3Oe6sKgZyRKTiW5eayJOdK/mgdmvuHgqv94c4AjiXAwnOol5RUHWud2Jnlomi35cb6BnVZk/IESDjTKGSrZPDthJcdLPkJZZ1CIjWeaF8zXIdpzChUWj63Rh7ttQnEsDnOhSUKSZJBJT3C+yOdHTrNN1DZLbbPYjpxM9R5m3bSy1PJIMBsrzY6f3eUzwOWSNc6kJCpC6tpP3Gc304uuQeV11DfwkhcV7inpywYMB/FndYkR0GZHmmBFHM+zgRAfNnSuOHqyuPmaw/p7y0Z+1FJ5ubtCg612es/7CCQNwXoK848uje+v73FVb96inPljVaOvlQvGIcgEAgOYHRPRGzkSnB/VwnIs7E5qFdxN297IYTE7hSB6xeGpnEZTgIpMkJtgKi5J4ZYMfXOXDMzuUTZLcJJdlkInu5/l6AkISEYK33xSVN+zc64vgoUx0b4DApfvQ3/0se29fpXOi0/JkhIREZjEnjVpIV1jUXL8NdtFzH3SJzHJ9vL8zjXOhfmqPcykNCS+2Ni9cuyMiRtnEGt4fXFiU2iGX54xMMQuLmk50RwwN8Sm3Tey7+sS5yJxpCQllocKiMXEuUUd9+DXSOVuXOM4l/DoWKF0zJbgNtmKtgZCrrINmLGyz2L7Oi4qh2Tq8v2V8jOlEl8KxPNd4/7myqP3CojovvC6ZE90XWxMM4hn9SfbJhmSiy/PJPG+o3oaE25ty29clit5wOtFDmeiqSTPRiy2Dv0njXPgc2ukNJst+a5thQPtbOtHt7eEZGkHMV2VZ+LNxn1fXI2n/MUkX5yL/RsejMMdxLqVimUkyyxtCKH9df6YW2Z3oxucxMtFBc+S7Jx6ozh3XV19nr3tkrnpj4QbVnHlz0Ub10apt+jPkggn9m7o5AESgz/6Ljxyov79r+uJGKe67ddc+NXPJJv391INQIwAAAJobENEbOROdbiRZ/CABwOVE37Znv/6ywcJzXFE1KWCQ65h/5liZ0lCcSzAtvkdVuXWdfqSEFNGFOF/fOBebWOkaNGhTnDyTmLfX3Defb97l58J3qwyL6CQ4uqI3tIjuLYsPmc0Zbca5xEU/8LYnjVqIZKJbXi8HNmyi/Jptu0PtTCc+keAni/HJOCAzSsbmRLcNkpjCfZ+O0T736bqU27u3+FuSOBcSd+QxcDlUbYVF0znReVncNrlsuT+SuPR1GxziUyTOpdgR56Kd6FHh2kVE/HTEuZj72Y9zSRPbYe5DOXOFnej7XZno3jr53KQ+wuvlPsv7VrYi5EQX5xovTwprNqe6dqLHZKLLcyyjOBfjuIRE9AY40WXRVfM6aA5ehnPfw7N5Ms9ED4Rf8zPL1eVynYkel0GeVkT3BqhpUdxO2+cK9Q3us65BJD4vePYMzYQxr817awLRPmltEUm6wqLmjBA5eFaf9aUtLCqW6RpEyRayz9J5bRtE1050o28jzgU0R+jc/enph6gvHNJD329d8cd31NwVW1Rz5a7XUi70sw/vi8gKkLd8fXx/1bakSGeUv/rp+pyv75UF6/Sg9IHd26t+nStyvj4AAADZBSJ6Y4voFOfi3UjqTHRHYVFi5eZAPJKwIBXnwpMCBolvpuuVHoI541hmufayONE5GoWXZXO4Zx7nwk70DOJc2ImepLCf90BtFhddvH5nJONa7i+Xay8V5+LOuWXksSBxJU7wZ6GWitclzkSPKSxKyEx0Wz76qi17QoVo04lPFVJEr6n1Z1SUFEX7U1InOu0jyrlmbLMf+DhJgT0uzkU60WXMhWv7ooVFCxLHuXDbQnEuMZnoLrHUjG0J/z58/iZ1osdFAkXiXAzxi8U2M/eZ96Fr2a44F+1E90X01LprIpno4cKi/jrblvgxMtxneV/I5rniXHh5roKOvOk1oo/ajkV941zMfSH7Cr+/PuLmtj2pmUS241RWHBfnEi8EZ+JEV8ZHFrXDJu4mGRSsDzKDfEPMQLINPsYcayb3hzXOxchEt8GfS/x5zP3WdT2xXcfSwe+JGwTh9tE2SiddNuNcbMvM1XH2l2840W2f/ygsCloS1M9/dfYoNWlIF/3scNH9s9Qib/C+OfHhyq3q9YUb9PZcOinl9AUgH6mqaKPOHddPf8/xQ40R5TLlIBQUBQCA5ghE9CaJcykVTnT3e1Zu2Z0mzsVdVC0kohcXqrISi4jOURjV+9VOT+S3ZaK78p6rRPa0JElmuR/nErcDIpnhBckLizriXJguOpdbPJxzgUiLo1r/vbBAi9KhqeUWEZvF6XSFRaWwwvugJGMRPfp3OTDQ3ogUINZs3ROOc0mTJUz7Wq6TYxCSFM/UBQ0tTnRa95bdQa52W4vYz/TpWBG7v3m9nEWcNM4lXQyKbYaEKcjL9VAWu9mmtE506lPiePlt0Q7uIFpFZh2H3x8W1aSrNgnOwqKROJeSWAHPd6Ibojydg6aIHnGie/vNbDet03eie302GMwLXitd4SEnui+iq1iRPdVH3S5tW5wLryduV0cz0YPzrKwBIjoPxtowrzXhOBceKChocCY6Lc/Euu9yJqLz4G8wg8ocLE0f55K6XvBAsjPOZX/yTPTYuhSWQbn6kCQTnY6FnAGUaxE915no8hi5RHQzzkXXOMlijA0AjQ3N7rvr/DFqZN8Ousj31/8wS8+kbE7c9dpi/f8XD+2p+naC2xbkN5dMGqjvM99evCmnsz9o0PfVBev09ycgygUAAJoleMpo9DiX4sCJvmOvVZBgXDfMLEhxNrcUaFwiuumyoxt0Fj7WeTnZJE7YxAiniO50ohcmj3NJIC4EmeGFyZ2gntjgciJTXIR0rnG0hjPOpSA1RV4KJOniXGj/xgn+HF2RNGohmokefb0Uzm37abUnSGYS5yL3CcemRNzWFsEiFYVgF6PpoTCunUxiJ3p1kPUfjnMpSSR8JcmjN5cVykSPcaLbom70OgvDsyFsmehxBUtTcS5Bu9O5jM1ZL+Y+4OMsrx3UxbhQqytPmwc32sQ50b3rXCQT3Tv2pouU+iUP8HCfDbZf5kvLTPSoSO4qQhrEuQTCvi2WIuxE90R0bzlx2dbmvpB9h2cFZVvcNPtZKPc9ZhsltmuKKTDbIshsy82VQzkcQ+Y50esZ5yILrVrjXGrTZ6LHHWsmSWxZNjPR5WBVLsTkkkbMRJfXKV1nRBQIDhcWDV5Hn7vmTA0AmhtkMHjgosPVkG7t1Jpte9QF987ya/rkOys27VJPe0Uarzh6UFM3B4C09OpQrk4d1SvnbnQS6cm41q19qTq0d1XO1gMAACB3QERvJHb7cS4UN5F6yN68a68vENvcXDLGQL5mn5GJnj7OpSgi5konui9EtC2xCjshgbAoSSZ6cfI4lwyc6CyeJJmmzc/Tct9IAYIEupBzzXeix0dWSIHE6kQPrS86eGHNRPdF9PSnoxS0bSKBjHCxbYuZiZ4uBkE70UW7tntxEpHimZZ1kXBqzURvW2qI6MWJRHSbgFRqiXOR4rbLoRqJQUmQ62sOyMhjLY9L0jgXGrixRe6QKMXnpuvc422QzlTp2LRhnmqm+MfLl/2KBHRXXItsR+rv0Ux0X0T3+oF5vvP5YQ6QUB/h/ct9lvfjnn2BICmvBTanuVxbKM4lFHXiLuxbEBPn4roOcX0FSWVZsb987u/ZFtHjnOi8jekET9ugFyGvY7ZLtu3zyyXINxTej5t27fU/G5IWFuXzlLchJLza4lxEJrq7hoEx68DSFh4wrS+8K+Nc30FtgoJQjFaSz5WGOdEbLxO9MM6J7ph1AkBzhnLE/3jpONW7Q7lavGGnjnbh+7B85p7XF+vr7FFDu6iDe0EoBM2DK48erP9/7qM1asmGVHRjtnnh4zX6/ykHdc/ZjD0AAAC5BSJ6I8EFPUlA4eI6dIPJArZNIDTda+yIm7Nss/rH3JXq49Xb3HEuQsCgB17zoZIEs+g09FK7iO4omiiLWEqSPMD6cS41qenyMz7bqCNvFq3boW9c6Pt/f7RGPTNvtdqya29IJEwS58LiCLtZ6T006i+FjpCLNyYTnf7EopgUUm2ChnTn07Li9sXsJZvUuu17fKE5XdRCkjiXkIhu2RY/zqVdQhG9JOXo42U5neg2Eb22zurApMEXPqbpCjWSMyTWiW5pF28THXPX/pfHnr5NciNrRt+4CotGBhgcIha1wSaiU7/yRXThLrZlosvtkK5aG6aD2BTX/MKihe5CuenEu9DyhYhOgufMxRv9orwMn8sRJ7osLMpOdG/9NBXWlgMujzVfK+VMF2uci+6jHBdlP/eD78PXH9d1yCXGs6Of41zMugKZYOtT5gwg3qd0bd3sfc7EZebHzQySIrrM2zbXFfpdjhzKvA3rvEKe1LYkxV5t+1weK5vDWTrRXQNt5uCVLSKroSI6ryJuxgwfA9o/3OZc0ZiZ6KYT3Xbe0UCH6UQHoKXQs6pcC+l03/rhym3qsgff8SMi85GNO6rVX99Zob+/enJKlASgOXBgj/bquGHd9L0qDQRlG7p/evFjjnLpnvXlAwAAaBwgojcSu7zp4/SwTw+F5EwkuDBaOnFDCid/mbVcXffIXC2mE7KQYtI4F3oYtxW/kw/H3Eb53mRxLkWqe2WarG2Oc6mpU3+euVyde8/b6vevfqbOuONN9eXfv6l+/eJCdeUf56j/+NO7apUnorFIaOZIt7cKkan/u3rCeZf2Jf73+ud2gcOW8AunWoRI+XAuXYZFCeJcbCIp872/z1PX/OndSOHUhhQWlbmTNgE5KMRX6vdHjhSxHU8+9rxedn5Gcr8t/VcWNJTQvh7YtW2qjW2KnG596n+yTTb9yGwX/dy1XXDMXUgBWZ577HyXfYXh5TKygGBc7IozIqiwQA3vWRltW2GBKvMEUblvInEdJKKLnZKu/5jbFHGie+2UQqPcRpdQGYjoNqd8ge8eP/vutyPv5WWafVnHuXjr5j7L7ZP7QQ5+yOLJfqFgx+AGv602jUvbFufC1x/Xue0SW3n/8/WqIbnSo/p1iPyuf+fUOeW311vmtOmfBdfQNJ8zrkGncJxL9O+2fWebqZMNuJ+v9UT0pEVFbeem3B9WJ/r+uvSZ6MYybdEytoLdmcB9x+b65n7Ix4j+j/vcqQ98j8HXx9Ki+EGVbCKPEZ2Dts+LQV3bhpzoSSLfAGhODOraTj14yTj9+TFzySZ17Z/f8z+78o2HZizTn/mH9K5SEwZ3burmAJARV3rxQ4/P+VwbnbLJvJVbdTRT25IiNRHnBgAANFuy+6QFnGz24is6eu5tyjHftme/Wi/yyF1MGd5d9epQpl/77IepaWD0kDyyb5Xq1r5MHTssWt1bPvCTiNehPCz4kTPSFHtomVLwGzews+pWWaqOHNwl9N50Ijo9wP758iPUHS8v0lEC/5i7yvoagh4CKDuR+GjlVr9A5Kdrt0few463sf07qbPH9lWfb9mlJgzqrEV4fl+w/al2ju7XQZ03vp8aP6izaldapO5/c6kWGc4Z10+t3Lw76kS3CJ5yN0mXoU1UoeN6w4kH+nmWxw/rrr4ypo921/Ogh+Sz9TsDEdvh7JdIgdOm6Rw/rJu6aOIAdXCvSu3iJtGB+taL81POB0aKLP/1heFq4bod6uIjB6jbnv9U9elUoX7z0sKQo0/vFxHFaQqqLic6x0PQzeIB3dvrhyrid+eOVre/tFBdfcxg7ZSVYtERgzrrgoFfOrRXyB1qE+9sgvWY/h3V18b308txwQNEpkjzx0vHq9967TIZ3rO93rcL123X05MHdmnryERPv294vd84boh20R/Yvb36n2fm+32Rln/+Ef3V2AEdnecbiZTSBVpVbr+c33neaPXawg3q7MP7htdvnP/cTnrd8k279CyCK44KskxPOaSnenfZZrV19z49C4Zn0bic6JXlbZwu1asmD1ad2rbx+5EpwpIwSuuxtY/6Nj3k9OtcERkY+cEpw/X+JOceMbhrO3XNsYP1dTIczRJEnfAsIdsgQbiwaOr/cQM7qXMO76uvuyQgTv90vRb6X/h4rb/dNr415QD9GhYVZL/4xVcOVW8s2qAumDBAxfGPa45UD761VH33pGGRv106aaC+lpKLirB9pKRzhx/Us1Ifm8ryYvXz5xb4v5efC0kz0XNVcJIHmDjOLBPB2DwX5f6wfQbvE0501/aYfZyKVpt84/ihOsKK81aTcvs5o9Q7SzerU0f2jqzrskkD9Tl4pef0vO74ofo8P6xfB/06+vvQ7u1UNnjkiiPU719ZpK45bkhkP1rGSbNKaKCwqCBUJP3M0X30OUj7V/bBpDMTAGhOjOhdpe65cKy68L5Z6sX5a9V//m2e/uzIp0gIMgw9NGOp/v7KyYNQmwA0O+geb1TfDrq4KN1v3XBi9H6rvvB94uQDuzrrJQEAAMh/IKI3Ept8B3AQo0HC6nqvSFBcbimJwCTY/L+/vOf/jj7gH75svPM98mHbLLZY6q2rTXFBRNiWD8ckVvzvGYeEXiPFQpeITg+wJF7ddvYodccri6yvoQKrPA2bRawNnigni6ZKgoiLQvV/XznU//0f317mdEHSfv0fsQ3HDQumz3FMRMiJXpTGiS5chq7nlmuOTQkNLIzfetZIdfuLC60iOuXiV3vbn8RRKY+P7eGEtuNHpx7s/3zkkNQAyIm/ek0tEAMT0qlHAwoMHbOX5qdu8ohyzm829ovp9LMJxXRsOR6C/i7bNaBLW/Wrs0fp7+lGlSHh/7fnHub/LKM7bFETZjwDrYeOudlvY7PrhUhDwjjtAxu0v+U2mOsN2pQwE72wQBeCpf6xaN12X0QvKirUf/vJ6SPCbTYcrqnMcTlLwj774+RDeuqvdIIqt5ums/7hwrGR1/eoKlN3nDdaf/+/z8xXd7+2OFLQMNTetiXOXOxvnTA07CgXr6NvO1SUqPKSPc7M9hu/MNy63MuE6M/YHoCCOBdyyXtRWxbhTZ5jfE2hdv/szOD6c9KInuqbjwTXZlcxY8q/pC9ze4julWXqtq/a+51kZN8Ozv5J113ZLpvomy77n7b3eycP0/tEiuhyP9iMx7Z15UpE52sPf15k4jqOONEL46+nqeLIXJPD4USPxKJFj39lWRv1i7NGqkw5bVRv/WXbp1RsUF67zfP8B188SGULWpfsd3I/5tyJXmg40cV5SgNql0waqL/fmrBYNQDNGTIH/O5ro9VVD89Rf3v3cx2rSIPH+SJW/3X2Cm0a6tepQp08InrfAUC+Q+cSmQnoHPvjjGXq6mOGZG12F4voZI4DAADQfEGcSyOxcWd1SOjiB+313lQxmatqxi74bs1QYcx4wVU6U2RONP+cWl748JPDK66QoXxvOid6OiGF3YQ0VZ6LrpL7mJHfMy4RwxYZ4ioCF3qNLRPd5kQXiwoVFs1AJHK1nfQHqtKetDhefSMgzO2Ky4wNRRxIJ3qGIjrlTfsCVIx4J9ti5jrLPigFddd6eYAoHaHYnSwUxouLc4nLRHfl/towz3nTiZ5JrIW5Tlu74whHo/CAlZlrXurct6aYK1/HxUzNPuqKxakP3GZyVe/yiz5Hzwl5jsWJFHIQNOlxCA+IqaxjG8AwB06THN8k15niRhXRi0OfEZkUkTTPxXTOfPp84qK4zr5sFhZ1DKJkA+mWz0XB0KTIY5vr/PVwZFU4ziX0eSjz7SGigxYMZSn/3BswvfeNJToKMR+gmaX3vL5Ef3/50YNy9hkAQGOcY4O6tNUzxh+ZtTwry6SZgp+s2a7PC54xCAAAoHkCEb2R4OgDFlhYMPXjXMTDIOeOmg+E8oY0nVATcqIXF4Ye7PnB05y+Tg4vKTLYBAYZVUFxJTak+GXLxaX1svCgRXTPCcpuffP74H327morXpkkjzeUiV4Qk4nuEMhcLlsbcXE9eh2FBdqtmA5brnMS0ongobZYxAjz/eZ0eZt4TVEunNkZt/2yLSyQ2YRL23FOUuDURieRb56koGsmxyWSFx/jRLf1MZeITuKy7HJmJnqm4p15PmUiUocKC3ptMAVK7US3LJK2wZx+bitmavaFTET+dHC7dJxLjIgeLizqXp7s30lFdLm/C1T2xQabgJF0wEgen0Qiui0TPWdxLkWhzwie1dTQTHQbVGshGAh0xLlEooji64E0BDnzJN1nSmORaxE9lIlO9SJcIrq4OCLOBbR0zhzTR/3Qm23yi38vUH+aGZ2R2dg8PW+1Wrllt/7sP2tMn6ZuDgD1hu5faCCIB6pcRdfr40I/fEBHPdsSAABA8wUieiNAjlzORGehi/9nEV0+oPfuYBfRpdAmC/7ZKIqJc/Gd6IaAQCISPaTyw7nN6SaFMpcDUP7eJeTwgzG5yNkJyo5s8/t0UQRWJ3ph9pzo8nXpCou6SCdeddSCY0GD41yc7zOOpRQiTGzF9kzxPolQTNoKF/yME6tkf4lzlVbvy56ILnOLs+HolPsjaZtCTvSQoG4/rtTfSEhnqL/IZSSZyWAuT3ahjJzooRkR9usJXXNs/d7uWo4OVJlO9GyK6Cy40UwQvv7YBpZCcS4x56fs37ZCz03hRLfGudRDeE02IBl/3cwmfJz4MyITJ7p53Uq3P/RAYG2awqKhuBGlOjhmaGUD1+yVpsSWkZ8z9z050cV1QR5PeXzgRAetAaqDca0XH/iDJz9UT30QrT/UWFCs07TpqYi3CycOwEAWaPaccVhvfT+3euse9a/3V2VNRD/hoB5ZaB0AAICmJD+ewlo4VCCP3VosgrFbjaaKmQ/EfTpWJIhzKU0uopMTXbyeBVFTQDAFUynsyWX5r3fcJEsHqVVELwoctDLOJR3OOBdP5MhYRLcIZDZHtXwdRVRksg5GzjSwkVQAlaJBQ5zocXEusp/Z4lzod6aAb89Er9XHVy8zRqwKx7m422VzopvHyxWdYtJJDEKli3RIQmwmuivOJTTrIypK2wjFCRWEM9EzjXMxBUAzXz5x3EdBdD9S9yAhy7Yp9vxsFRkgNMXRpMc2CXIWCRUi1euzFhaNzlaxIQcLEse5WCJxsoltmfUZMKp3nEuOMnrN42TLsk8c52J0ULPJ+/YHhUVd1wn5e/p8z2WRP9vAb1PDTv1cIY+RjnmSTnRH7FDc5wgALYlvTz1A102isaxvPTpXF7puCl5fuEHNX71Nn3sXTOjfJG0AIJvQs/clk1LF3u967bMG1f/YsmuvmrV0k/5+qqiNAwAAoHkCEb0R4CKZlWXFvthmiqZSRO/VoSz0MF+fOBcprjnjXAwBwRRMbU43+SuX2ysU52J1Qxb66yanMse5pMPlvGO3c0Oc6EUJnej1jnNJ05765Chnsn4pvss4HRvyb7Y4Fy426moXQ2MbLLDEFTSUgy4VDXaiJxNPTDE6l5norpiUsKs0mTgW6n+FYQFPRtQkRb4/E6d3qciu52uNFLQomogGWmxOdFtfsA0G0D6R554sRNpQpNC5k0V0S78OxbnEOtEzj3NpNk70DK+lmbyvPpiDK5k40c3ZG+bgptk391FdB+/zxTW4Ja+XucxDz18nem6XL/tsSkQvdnweBu+xncsAtEToc/a/TxuhvnhoT30vfNUf56h3l0eL2OcaEhmJc8b1RVQFaDGcN76/altSpD5du0O9smBdvZdD76UB+WE92qu+ncJGOQAAAM2P/HgKayV56NLFbAotUsxqW1Icim1gkSAU3ZAuzqUgLOKFCylyXEtY5DAFU5trUZqBXdM108W5aBHXK3BHbuVde1Milg0ZW5OJAJQrEZ0GQrgdmRUWTeNETyiAhp3oGcS5JJhBEBfnItdbXhIf88O7RTrR4woaJnWiJyksmlQIlucXx3k0hFBB3npkoicpLEp0Eu02C4vKiJqkyPXWt7AofyvbUlle7BygsBX9tc2yIXFAuoyzmokumsAium0AJ+xEdy8vJKTWQ0TPBXzuSeIGs1wkuc7Zrs2ZxE1lQkUDRHRzv5uDm+Z2UE0HdqK7BkLrM4BSX+TnSN6I6I2YiU7XE/kZYcabcV9FnAtoTVC/v+2ro9TRB3TVppSL75+tFqzZ3mjrn/f5VvXmoo26HRQxA0BLoaq8jfra+H76e44raliUC1zoAADQEsiPp7AWzsYd1ZEHbPNhWz4okjgt/17mOTBdBS6TONGlaMhZsuZDOLu3XIVHiRoRneJy2CbJRC+WTvQYEbN7ZVnwvgxEgyRT3YttIrplHfJ19KDO+zITB3O6AYD6CG+ZaFTyfWbBRhM5uOLPTpDudEshv5Aw5b2WNDw/zqWw4ZnoNq0mEp2SUJiUfZ/ilhoK9U3uJknbJPtV6PuYvtKxbZtwYVEpPtfDBSv7ZSZxKbZMdHmu04NHEsHcJlbLcyEU3ZDNTPTCZHEu8hyLjXNpoBPdJng3lG2Wfl3ciE70XNGQOBdXUVyXM52uOdXesXFto/xckrFpuSBcjLh1FBaV20nbLwVy85rF+wdxLqC1Qde1aV8frQ7r10Hf05x/70y1YtOuRln3NM+FfurIXpE4SgCaO5dMGqjvlWct2VSvWR5kAJq+IBWzNGU4RHQAAGgJQERvxDgXKa6YTvKQmCWc4/QwyDECsoBXOtFVPluS2B0SjSw57LyucGa6Lee6Lq3TUIoaNqE5FScS/H67J2KlFdEzEGqSiDoynoHbaRPqzBgHPjaZmDrTuQbrk6OcidMz7CSPFxhCgrkxsOJ6vy0TnAZcOAohbhBBiiKZOggjru96uDNZRG0o3JakbQrnoAdFPuMy0eU0ad0vCxrmgpWDGxnFuYRE9Gh/bF/axu1Ed9RJsG1HrkR0KYjHFahMmokedqInLCwq3mOLpGooXMxaUh/3cpLBQu5HuXbXNzTOxdzv5sCsbbBvj9c/XKJ1ozrRHRFQLbuwaPg6GXdN4P2TaZ8AoCVA92v3X3S4OrB7e7Vue7UW0tdvT5l4csWyjTvVs/NW6++vOHpQTtcFQFPQs6pcnTaqt/7+rumpAaNMeOuzjfo+s3tlqTqkd1UOWggAAKCxgYjemHEuMU50+fBOAhW/Vj4MbhWiCGUOJxbHjIKBLBpK4S4c58LO94J6Td2WbbYtQ2eiiwfj7Z6ob4NuOuT7siv8CBHda6dNBDLFex4AySjOJQeZ6HJWQNr3yYiWNC69kBPdi25JFwdTKvoY73pyKLI4GHfsZCxQpg7CpPnjjQHv44iwI1zqEtl/SIDmqI24vtLBc3jr9xcU+FEkhJxtkhQZs5PJvgu5eS3Cox/n4piJktiJLqMbclRYlJ20tr4n2x93Cu/dX5vxjAC5PRQbkm2okFVWRPQMnOi2wszZxjxOmQqmMs/f7FM2YXqPV7PDmYnewOK+meCKgGotIjqdt/L4m3US+HMfTnTQWqGB9ocuHaf6dCxXSzfuUhfcNysrs+1c/OH1JXrGzuQDuqrhPStzth4AmhIeIHr+47Xqs/U7Mnrvi16UC7nQc1l4HAAAQOORH09hrURElw/Y9PDXvrTY+qAoM8zlw+C2PcGNcLoPYvl3U9STzlszRka+3pafm8QwmS63m0TFJFPRaRO6iKzwTETrJDcqsm2xTnRjGzizOaPComkEyvrEuWTiXk3nJHeJnH6fsBQbdS2/ToiTlIuulxkj+NBx5T6TaUE4U/htDCessy3evrKJ0UkGZ/iciBXRK8JxLvLhuD6imjzHM8tED/qA7TzgQT7bttjOfVcsjeyr2RwgsV1L7Jno8nv3cZEDgVSEKtNrVE7iXCyDk/WJXckkE70xzj8zjirjgbeY+gO2vrnHq8XgykSn48h/ynVh0XDthMJWF+dSp+rCcS5Gf+PBcGSig9YMzeB8+NLx+v55/upt6rIHZ8fGJtaXDTuq1V/fWaG/v3IyXOig5XJA9/bq+GHdFI0Z/+H15NnoZDx7cT7y0AEAoKWRH09hrSTOxSweKcUi6YAjMY5fG3KiZ+AmkeJAnLAhhQF+8GSxqr5OdBnrYBPRdJxLAgGAxJJ0jvtsZq06M9GN/cCCdyaCVLrtTVpYtL7u1XAmelHGOdny/WVpRHSmpq4uKCyaZl9xP29MJ3q2c5x5X1lFdEu/MtfvKvgrqSoXcS4FYRG9PhRnIRPd1t5KzzFvG8wqSvM7GYcSJ5g1BNuhtxVKlteyuIE5OcBZn4Kae3MQ55ItksRo8fFrDHe0Wdg48wgoOVOqMO11evfe+Ex0uZxcZ6LLJuRPnEtuly+PCY3Jhp3ohojunXu2zygAWhMDurRVD10yTrUvK1azl25W1/z53awP1j701lJVvb9WjexTpSYM6pzVZQOQb1x1zGD9/9/mrFTrtu9J9J55K7eqtduqVbvSYjVhMM4RAABoKUBEbwQ27ay2uo2lM10+zMs4FykQZCKYSddknPgk18sPp/xgas9Ez+wm3CY8kSgj3XtxwirHQuQCGfnixxEkcKL7InoGYlk6533SGAAp0Ml8+kycwzax0NUnuA+ERPg0sRcy4uK95VtSy0kjgPIyMxXEGuJEryzLbt/ittjaIIU7l5OU3xeXid4xxoleH+qbiS5fG+dEt68zXkSX25irOBc6j8JFQ9Of+3HXK1sRz0zIRZxLtkgy2MT9SEal5Apztkq661l8/YbwtsnPPO5vM5dsTHsN59fmOs6F+i2fP/kS59KYTnSKjombScV9NdNiswC0RA7qVanuu+hw/dn28ifr1Hcf/yCRESYJFCX34Ixl+vsrJw+u1+AxAM2Jsf07qtH9Oqi9NbXq/jeXJnrPC16UC8UdmfFjAAAAmi/58RTWwtm4IxrnQvSqKrdmHdMUzF4dyiM5x4cP6KT/lzEwLuTzNT/gH3NgV/0/uUZsbjYWMKu8trCbVDKqb8fQz2WeaDKkWztrO+xO9GRF6EhAO7BH+ozFg7wcRsqArK84xO1MErvBx6ZdBiKszTVIx5nWR+3oJrLfk1LfOJd0QrUUKzk+JJP30wMb7TJ6VvtkzXb9u3QzCnhWRkeLCMXV7G19zFwu990knHhwj0jufkOo8vaVrQ02gdYU5XhbyDnmol/nCv972seH9evQIFeqHNzILM7FHYlBHCquMSa2QQJy6fCxCA3sCcE021Eh0uFKs15sIkDSOJe47U1Cb++akk2G9Wiv/+8hijNnAsfSHDmkS+j33OcOHxB8FnCfHdU39bdcYgqkZrxLOuRnrfkZx9tKn2s8gPvRqm36//Yx1zAekOvVoX77OhO4zZl8/uQCvs5NzLG7Tl5f6DNFDqyZn0XcD3MdqwNAc4GeG+78+mh9Hj3x3kr13099rOqyUMeAYlxoEH9A5wr/XgqAlgzdI9KAEfHw28vUdjEDMZ2IjigXAABoWTTtU1gr4Stj+qhlG3epAZ3bhn7/nRMPVH06lWtH83lH9Nci9559tapr+1L9/Q9OGa6OGto19Hp6SD95RM+065RmExaffvXVUerRd1aoMw7rbX0dO7yuP+EANbJPBzXV8qF/yaQBWrCjUXXi+W9OVv/+aI362vh++gbdLCxUGCOi0wDB6q3uKXH0gEyizM+/cmisQH7/xYerJ99bqb46tq96ZcE61a19MiEjVDQwRkQ3t+GUQ3uqjTur1QkHJX9wkK7Ba48doh/2vziyl5q/apvO3K1PbE2u4lzotXefP0Y73alIlVkwMN1UeRK1bvrSwWqu50InIf5LI+P77E9PP0S9v2JLaICH+eVZI9Ujs5erU0f1ivytW2WZ/jsJXUO7t1P9jXMsjh9+8SA1sEvbROdTEn586sHq3WWb1WHGQFPSwZn/+8qhatG6HWpwV/uAFNGzqlz99tzD9DGkG/rrjh+qZ0ZMzaAvSjhmh/ThJLEdVie6eN/frp6g5q/e7g/YEQ9eMk4tXLtd/fTp+fpn23r6dqpQPz/zUP2/SzDNtohOgx7rt1fHuplDdRNi9s9lRw3SyzjmwG4ZteGxqyboYz4+B1PhyYH4r/dXqXMO76ee/3hNxkL9M9cdpa/tXz+if+j3d58/Vv393c/VmWP6+L+75tghalDXtupr4/urIwZ1dg6qZgPTiZzp7JXvf2G4OrBHez2wdcGEAaG/fefEA1TPqjL9wPv55t3avZlaZ/S1kl9+dZRasXlXRtef+nL7OaN0FrGsF9IUPPWNSerZD1frY55LwoNbdXqQ7d4Lx6rd+2oiMWg/O/NQtXDtDjWkW2oACQCg1HHDuqtbzxqpvvnoXPXAW0v1vfd1U4bWe3kUC0MFRYnLjx6U9Wg8APKVE4Z31/c6i9fvVI/MWqH7v4vlG3epBWu36/ND3hMDAABo/kBEbwRIYLFBAt6NJw/3f5YiB4mu5vvIrXnF0alR8EymWLMLlly+V3mj6IzMSGSH16Cu7fSXDZqOJttFzli+iTDFlnSFBcmZHyeis7BF4ni6IkrsDvjy6EDYqZcTXcSeuLaB2pX0OATLCARAOg6XThrYYAdqJvmWoUzzBFPdpxrOonCcS3HavnfqyF76Kyk0WOJysZLYycfXBol5Z45RGdO2tDh2uZlyaJ8O+stGkkx0cozxbJM4viT2Kw1YZNoXbecitS+T6djSWS/PjzH9O+kvCQ24jenf0RfRXTFEXz28b6xgmm0RnQYfWER3CbFyl8TtHjqnXNf5OJIe8/pAM2a4f5+V5hpqgwRhW9+iQV7zvKHBD37tueP6qVxCfY+OBZspM41zIQGdhHQbdD7x5xllCk8aGnbhu6Cs0wmqcfJO5cB6UyKPeWPBl47jvdlJjXk+AdCcOf2w3mrLrr3qR//6WP3qxU9Vx7ZtYgcG43j6g9Vq5Zbdqku7EnVmBvfcADR3yDRy5dGD1H/+bZ66940l6sKJA5z3pmReIMYN6OQbkgAAALQMEOfSQpEielyW8H4RCWIWWcsGNocKC8rp8mMzdRhmihS2OWLCdjOUDZdNuFhndlw7mcS5SCd5ffar3C9mYb+G5ua3BuxO9Ka//CaNVjKRr09yfsgIhr37axKvJySiZ/n6JK8/roK24Ux0uO3yARrsiYv0AC2XbMRQANBauejIgXr2GnHzPz9S/5i7sl7n4LTpn6WWN3FAxoOYALSEASkyE6zZtif2HHpxPqJcAACgpdL0Kg7IuYhui1Spj5u5Psjim/xtSXGBtdCqiUvYyhZSw2R9ToqD3N7siOjCuZslMTCTgm4hEbwe+1UKmGZhv4a0q1WL6FkaTMlGv7RltseRqaAtz6FMBn9ChUWLcyiilySIc4GInjdI4TzXnxMgf8BHCwAN45tThqoLJ/TXM3m+/df3dQRiJkz/dL2udUPXYNvsUwBaOjQj+5IjU7OJ735tsbVYL836mL10s/4eIjoAALQ8moWIvnTpUnXppZeqgQMHqvLycjV48GB18803q717UwU7Qf2FTFe0QraQQmGZV5k8cKLHZ7q6hK1cOtGlmMjtzYZ4JvdDJtnT2XJ8h53kmac4lUrnZxrRKtd9qjliLSyaBzmi3AZ6KMgE2Z8yHTTJZOBOiqWZCv3pkJnSLjezHGiDhp4/yM+GXH9OgPyhFk50ABo8k+fmLx2sThvVS9+rXf3wHPXO0k2J33/X9MV+bBciKkBr5bwj+umI1YXrdlgHoqieCt0bU4F3s9YPAACA5k+zENE/+eQTVVtbq+666y710UcfqV/96ldq2rRp6vvf/35TNy1vyRchUzo5S9sUhgTlzu2a2IkuRDEWyqU4yO3NthM9W47aTBy9ISd5g53o8e+vyaBdrYVcxQTlQ5xLpteavfuTi+hljeVETxPnQv9lkhkPcgsfLzok2R5cAfkLNHQAGg7NTqVCo1TscM++WnXJA7PV/NXb0r6Pir/PWLxRD75f4tX1AaA1UlnWRp03PlX/heONJC98nIpymQoXOgAAtEiaxdPnSSedpO6//341depUNWjQIHXqqaeq73znO+rvf/97Uzctb8kXx5Z0e7PYwYJsujiXXGfdkijGQib/L8Vibm82YjdCcS5ZysLeX8/Cog3PRIcTPVO4X0mxNj8y0aP9PgnSRW+byhrH3no60W1FfxsrzgVRLvkFz6ahWTEY3Gg95Mt9DQDNHbonvfO8MWps/45q25796oL7ZqllG3fGvoeiKwgqGt+7Q3kjtRSA/OTiIwfqe2iKbZmzLJjNsWdfjY49Ik44qEcTthAAAECuaHoVp55s3bpVderUKfY11dXVatu2baGv1kK+5FJLnZBdpSxKpyssWp/YkUxhcYxF9FCci9febBQUlEK8LDLaEPZlcIxt25UJmWSq50vfyyd4/0lROB+c6JzPn6nLWwqXNXW5i3ORfY1nhmSLzomc6Px/0x8rEFDu9QVEubQuoKEDkD3o+nnvRYfryIn126vV+ffOUuu27bG+dumGnerZD1fr76+YPKiRWwpA/tGjqkydcVjvUMwRMeOzjWrX3hrVo7JMjehd2YQtBAAAkCuapYi+aNEi9dvf/lZdeeWVsa+75ZZbVFVVlf/Vt29f1VrIFyFTum3NTPSmjnORQiY7a6WYGLQ3C050sR+kK705OtHTvT+TrPbWAu8/OYCRrcGUrDjRGxCJkXkmegaFRUNO9NzFubj6NA8W5MGkASCo8AZYIaK3LuBEByC7VJW3UQ9dMk7161Shlm/apR3pW3fti7zuntcX68K+xx7YVQ3rAWEQAOKKo1MDSi/MX6sWrduhv3/ei3KZclA3zJQDAIAWSpNKA9/73vf0B0zcF+WhS1auXKnjXc466yx1+eWXxy7/xhtv1I51/lqxYoVqLeSLiC51L3aSsnCXrrBoruNcpIhOGZGuTHT+W9YKi2ZJPM3kEDdURC/NIFM9T7peXsEzAcrzzYnuqcMNEagzvdZk8noWS3ORid5ZFBZ1zXqBEz0/4fOook3uZyuB/AEaOgDZp1tlmXr40vGqW/tS9cma7eqSB2erXXv3+38nl/pjcz7X3185eXATthSA/GJIt/ZqyvDu+rPpntcW63jDl+anRHREuQAAQMulSUX0b3/722r+/PmxX5SBzqxatUode+yxauLEieruu+9Ou/zS0lJVWVkZ+mot5I+IHnV2sxNbOkFZrCoTkQ1lJU3gRJcFQL3vs+FEl8vIlhM9E7Ia5wL3Z8ZwX5IDGPmRiV6/OJfGutbIAZusi+ji+uOaFcDiOUT0/IL7RWN8RoD8AU703HDHHXeoAQMGqLKyMjV+/Hg1a9as2Nc/9thjatiwYfr1hxxyiHrmmWdCf6+rq1M33XST6tmzpyovL1dTpkxRCxcuzPFWgIbQr3OFeujScaqyrFjNWbZZXf3wu34R8IdmLNXfj+zbQY0fGB+jCUBr4yov3uiJ91aqF+evVeu2V6t2pcXqiEE4VwAAoKXSpCpO165d9Y143FdJSYnvQD/mmGPUmDFjdJHRwjwQoPKZTHOKc4UsyMfObs5hppt1k7Ylxb5AQkXjGs2J7rVTCnXsQM+GY5hmVbBQ1xQxHrIoY32c6HzMUu+H+zNTuF9JUbiolca5ZEIu41xoGjuze29NGhE9q6sGDYSvYY3xGQHyh/y4q2lZPProo+r6669XN998s3r33XfVyJEj1YknnqjWrVtnff1bb72lzj33XHXppZeq9957T51++un668MPP/Rf8/Of/1z95je/UdOmTVMzZ85Ubdu21cvcs8eetw3yA4ppuf/iw7WZhQojfuex99X2PfvUQzOW6b9fPXkQ4ikAMBg7oJMu0Lu3plbd8PgH+neTD+yqSj3jGAAAgJZHs1CiWUDv16+fuvXWW9X69evVmjVr9Bewsz9fnOhCKOQbijaeImW7GSeXNAsk5Y3pRLeIiSycZSt2g53HTeFAbqiTXAqljZFV32JFdLHv+TxoSmz9Pp+uNXJ/ydkU2UDGNO3e5xDRvVVmI9IJZA++BmFWTOsCTvTsc9ttt+loxIsvvlgddNBBWviuqKhQ9913n/X1t99+u45UvOGGG9Tw4cPVT37yEzV69Gj1u9/9zneh//rXv1Y/+MEP1GmnnaYOPfRQ9dBDD+mZpE8++WQjbx3IlDH9O6lpXx+jZ0/+8/1V6ozfv6W27t6nBnZpi3gKABxwzBGdK8TUg7o3cYsAAACo1i6iv/DCC7qY6EsvvaT69Omjp4jyF7BDuWyZkCuNyOZEbxMjhpGAXt6YIroR1yDdrgXKc6JnyXkTONEb/7STx5djdeorosvIHZDZTICKPMtE574oM+9zfa3JBHk+5nJ/pXeiN/2xAgGN+RkB8oc88Qa0GPbu3avmzJmj41YYmuVJP8+YMcP6Hvq9fD1BLnN+/ZIlS7TBRb6mqqpKx8S4llldXa22bdsW+gJNxzEHdlO3nT1K0cceF0u8/KhBeXHPAkA+cvywbmpIt3b6exqAOuaAbk3dJAAAADmkWahhF110kXa32L6AndNG9dL/D+vRPvZ1VBCFuPjIgTlpR2V5sRZdu7QrVT0ry/TvulcGBf36dCwPrb9Xh3L9RfT2/s8l3BYqqGS64w/r1yH1N6/dDV9XmRazu7QLspjrw1fG9NH/n3FY78TvaV8WRFdUlGYuPPXvXOF/75rOy+05c3SqfSCgZ1WqD/XtWKE6VrTRYnrb0qaPxaE+qf/32pcJ7b04pmOHdU30+nPH9dX/nzqyV8brIHKxv3p423+8dx205abTOcvXB5AfNOZnBGh6DujeLuNrB0jPhg0bVE1NjerePXz9o59dMz3p93Gv5/8zWeYtt9yihXb+6ts39VkBmg461/77tBH+ffKXRye/3wSgtUGzFf/jmJQb/aihXVRVRfDMBQAAoOXR9CoOyAkkSh/Qvb0uBBTHb84dpWYt2aQmDu6Sk3ZQfvbjV03UMS09qsrUUQd0VRMHd/b//s9rJ6mPVm1VRw7ukhrJ795O1dYqtXTjTt3+XHPn18eoVVt2q76dApH45W9PVjura9TQ7u3UuIGd1BGDgvY2hPsuOlyt31HdYFH+p6ePUF88tGdG7SLH5rPXHaWdRPXJ6SOx9Z/XHhkS401u+fIhevAmW/urJXH6Yb1Vt8pSdfiATuqssX3U3v119Srwmm1owIMEfmpXprzynWPUp2u2qwnifI7j5i8drE48uIcaPzB5/6B99O9vHq1jHHKxv57+f5PU/NXb1ZFD7G2ic/Xxqyeqru0goucTNGBHAxuURQpaPo9dNVG9v2KLOnJIbu5TQNNy44036lx2hpzoENKbnvOP6K+NON3bl+XF/QoA+cyXR/fRz7lUWwAAAEDLBiJ6C4XE0qMP6JpI5Kapm7lkRO8q//vJRps6tS1RRw1N/W6ieECmG5HGQDrfmUFdU643Ipv7hoR6KdbXF3qYqU+7hvds2I3doX065KRdrQHKHOd9M6Rb7geH6tOuTKHZJV2GJBeX69s/Dkwzm6YhdG5XqiYNjd+G0f065mz9oP4xRLjWtB6oCHCS+xmQGV26dFFFRUVq7dq1od/Tzz162POv6fdxr+f/6XcycpF+HjVqlHWZpaWl+gvkH/UZYAegtZIrQxoAAID8olnEuQAAAAAAAACyQ0lJiRozZoyuN8TU1tbqnydMmGB9D/1evp7rFvHrBw4cqIV0+Rpyls+cOdO5TAAAAAAAAJoLcKIDAAAAAADQyqAYlQsvvFCNHTtWjRs3Tv36179WO3fuVBdffLH++wUXXKB69+6tc8uJ6667Tk2ePFn98pe/VKeccop65JFH1DvvvKPuvvtuv2bKN7/5TfXTn/5UDR06VIvqP/zhD1WvXr3U6aef3qTbCgAAAAAAQEOBiA4AAAAAAEAr4+yzz1br169XN910ky78SZErzz33nF8YdPny5aqwMJi0OnHiRPXnP/9Z/eAHP1Df//73tVD+5JNPqhEjUkUoie9+97taiL/iiivUli1b1KRJk/Qyy8oaJ6YPAAAAAACAXFFQV1dXp1oJNKW0qqpKbd26VVVWovAHAAAAAADILbj/TA72FQAAAAAAyNd7UGSiAwAAAAAAAAAAAAAAAAAOIKIDAAAAAAAAAAAAAAAAAA4gogMAAAAAAAAAAAAAAAAADiCiAwAAAAAAAAAAAAAAAAAOIKIDAAAAAAAAAAAAAAAAAA4gogMAAAAAAAAAAAAAAAAADiCiAwAAAAAAAAAAAAAAAAAOIKIDAAAAAAAAAAAAAAAAAA4gogMAAAAAAAAAAAAAAAAADiCiAwAAAAAAAAAAAAAAAAAOIKIDAAAAAAAAAAAAAAAAAA6KVSuirq5O/79t27ambgoAAAAAAGgF8H0n34cCN7hXBwAAAAAA+Xq/3qpE9O3bt+v/+/bt29RNAQAAAAAArew+tKqqqqmbkdfgXh0AAAAAAOTr/XpBXSuyxdTW1qpVq1ap9u3bq4KCgkYd0aCHgRUrVqjKyspGWy9ofHCsWwc4zq0HHOvWAY5z66EpjjXdatMNea9evVRhIZIU8/FencB1AMSB/gHiQP8AcaB/ABfoG/lD0vv1VuVEpx3Rp0+fJls/nRQ4MVoHONatAxzn1gOOdesAx7n10NjHGg705nGvTuA6AOJA/wBxoH+AONA/gAv0jfwgyf067DAAAAAAAAAAAAAAAAAAgAOI6AAAAAAAAAAAAAAAAACAA4jojUBpaam6+eab9f+gZYNj3TrAcW494Fi3DnCcWw841sAF+gaIA/0DxIH+AeJA/wAu0DeaH62qsCgAAAAAAAAAAAAAAAAAkAlwogMAAAAAAAAAAAAAAAAADiCiAwAAAAAAAAAAAAAAAAAOIKIDAAAAAAAAAAAAAAAAAA4gojcCd9xxhxowYIAqKytT48ePV7NmzWrqJoEMeO2119SXvvQl1atXL1VQUKCefPLJ0N+prMBNN92kevbsqcrLy9WUKVPUwoULQ6/ZtGmTOu+881RlZaXq0KGDuvTSS9WOHTsaeUtAHLfccos6/PDDVfv27VW3bt3U6aefrhYsWBB6zZ49e9Q111yjOnfurNq1a6fOPPNMtXbt2tBrli9frk455RRVUVGhl3PDDTeo/fv3N/LWgDjuvPNOdeihh+rzkb4mTJignn32Wf/vOM4tk5/97Gf6Gv7Nb37T/x2OdcvgRz/6kT628mvYsGH+33GcQTpwr946wT0+iAPPBiAOPE+ApOAZpGUBET3HPProo+r666/XFXffffddNXLkSHXiiSeqdevWNXXTQEJ27typjxs9YNn4+c9/rn7zm9+oadOmqZkzZ6q2bdvqY0wXRoZurj/66CP1wgsvqKeeekrftF9xxRWNuBUgHdOnT9cfZG+//bY+Tvv27VNTp07Vx5/51re+pf71r3+pxx57TL9+1apV6stf/rL/95qaGv1Bt3fvXvXWW2+pBx98UD3wwAP6AQzkD3369NE3M3PmzFHvvPOOOu6449Rpp52mz1ECx7nlMXv2bHXXXXfphx0JjnXL4eCDD1arV6/2v9544w3/bzjOIA7cq7decI8P4sCzAYgDzxMgCXgGaYHUgZwybty4umuuucb/uaampq5Xr151t9xyS5O2C9QPOmWeeOIJ/+fa2tq6Hj161P3iF7/wf7dly5a60tLSur/85S/6548//li/b/bs2f5rnn322bqCgoK6lStXNvIWgKSsW7dOH7fp06f7x7VNmzZ1jz32mP+a+fPn69fMmDFD//zMM8/UFRYW1q1Zs8Z/zZ133llXWVlZV11d3QRbAZLSsWPHuj/84Q84zi2Q7du31w0dOrTuhRdeqJs8eXLdddddp3+PY91yuPnmm+tGjhxp/RuOM0gH7tUBgXt8kA48G4B04HkCSPAM0jKBEz2H0KgRjUzS1D+msLBQ/zxjxowmbRvIDkuWLFFr1qwJHeOqqio9FZiPMf1P0zvHjh3rv4ZeT32BXC0gP9m6dav+v1OnTvp/OpfJgSKPNcUF9OvXL3SsDznkENW9e3f/NeRY2rZtm+9KAPkFjfI/8sgj2lVE0zBxnFse5CIjJ4c8pgSOdcuCIhYokmHQoEHaGUpTYAkcZxAH7tWBC9zjAxM8GwAXeJ4ANvAM0jIpbuoGtGQ2bNigL6iy4xP08yeffNJk7QLZg26uCdsx5r/R/5RhJSkuLtY3YPwakF/U1tbqzLIjjzxSjRgxQv+OjlVJSYl+WIo71ra+wH8D+cO8efP0TS5NyaYcuieeeEIddNBBau7cuTjOLQh6oKF4BppKaYJzuuVAohZNcT3wwAN1lMuPf/xjddRRR6kPP/wQxxnEgnt14AL3+ECCZwNgA88TwAWeQVouENEBAMAyakzii8zUBS0LEtvoBpdcRY8//ri68MILdR4daDmsWLFCXXfddTrHlIoFgpbLySef7H9PmZMkqvfv31/99a9/1cUAAQAAgIaAZwNgA88TwAaeQVo2iHPJIV26dFFFRUWRKrv0c48ePZqsXSB78HGMO8b0v1mciqoqb9q0Cf0gD7n22mt1YahXXnlFF4xh6FjRtO8tW7bEHmtbX+C/gfyBRv+HDBmixowZo2655RZdWOz222/HcW5B0FRJuvaOHj1aOwPpix5sqEgcfU9uDhzrlgk5ew444AC1aNEinNMgFtyrAxe4xwcMng2ACzxPABt4BmnZQETP8UWVLqgvvfRSaCoY/UzTfkDzZ+DAgfoiJo8x5VRRDiIfY/qfLpB0MWVefvll3RfILQfyA6opRTfJNA2Pjg8dWwmdy23atAkd6wULFujcXXmsaVqffKCiEejKyko9tQ/kL3Q+VldX4zi3II4//nh9nMghxF+UW0t52fw9jnXLZMeOHeqzzz5TPXv2xDkNYsG9OnCBe3yAZwOQKXieAASeQVo4TV3ZtKXzyCOP6CruDzzwgK7gfsUVV9R16NAhVGUX5H9V5ffee09/0Slz22236e+XLVum//6zn/1MH9N//OMfdR988EHdaaedVjdw4MC63bt3+8s46aST6g477LC6mTNn1r3xxhu6SvO5557bhFsFTK6++uq6qqqquldffbVu9erV/teuXbv811x11VV1/fr1q3v55Zfr3nnnnboJEyboL2b//v11I0aMqJs6dWrd3Llz65577rm6rl271t14441NtFXAxve+97266dOn1y1ZskSfs/RzQUFB3fPPP6//juPccpk8eXLddddd5/+MY90y+Pa3v62v3XROv/nmm3VTpkyp69KlS926dev033GcQRy4V2+94B4fxIFnAxAHnidAJuAZpOUAEb0R+O1vf6tPkJKSkrpx48bVvf32203dJJABr7zyir6xNr8uvPBC/ffa2tq6H/7wh3Xdu3fXD2HHH3983YIFC0LL2Lhxo76hbteuXV1lZWXdxRdfrG/cQf5gO8b0df/99/uvoYem//iP/6jr2LFjXUVFRd0ZZ5yhb6YlS5curTv55JPrysvLtYhD4s6+ffuaYIuAi0suuaSuf//++ppMNyN0zvINL4Hj3HpuYHGsWwZnn312Xc+ePfU53bt3b/3zokWL/L/jOIN04F69dYJ7fBAHng1AHHieAJmAZ5CWQwH909RueAAAAAAAAAAAAAAAAAAgH0EmOgAAAAAAAAAAAAAAAADgACI6AAAAAAAAAAAAAAAAAOAAIjoAAAAAAAAAAAAAAAAA4AAiOgAAAAAAAAAAAAAAAADgACI6AAAAAAAAAAAAAAAAAOAAIjoAAAAAAAAAAAAAAAAA4AAiOgAAAAAAAAAAAAAAAADgACI6AAAAAAAAAAAAAAAAAOAAIjoAALRyli5dqgoKCtTcuXNzto6LLrpInX766TlbPgAAAAAAAC0V3K8DAEDTAxEdAACaOXTDSzfV5tdJJ52U6P19+/ZVq1evViNGjMh5WwEAAAAAAGht4H4dAACaP8VN3QAAAAANh27A77///tDvSktLE723qKhI9ejRI0ctAwAAAAAAAOB+HQAAmjdwogMAQAuAbsDpxlp+dezYUf+NXC533nmnOvnkk1V5ebkaNGiQevzxx53TQzdv3qzOO+881bVrV/36oUOHhm74582bp4477jj9t86dO6srrrhC7dixw/97TU2Nuv7661WHDh3037/73e+qurq6UHtra2vVLbfcogYOHKiXM3LkyFCbAAAAAAAAaEngfh0AAJo3ENEBAKAV8MMf/lCdeeaZ6v3339c33Oecc46aP3++87Uff/yxevbZZ/Vr6Ia+S5cu+m87d+5UJ554or7hnz17tnrsscfUiy++qK699lr//b/85S/VAw88oO677z71xhtvqE2bNqknnngitA66IX/ooYfUtGnT1EcffaS+9a1vqa9//etq+vTpOd4TAAAAAAAA5B+4XwcAgPymoM4cbgQAANDsMhYffvhhVVZWFvr997//ff1FrpWrrrpK31wzRxxxhBo9erT6/e9/r50t5DB577331KhRo9Spp56qb8LpptrknnvuUf/5n/+pVqxYodq2bat/98wzz6gvfelLatWqVap79+6qV69e+ib7hhtu0H/fv3+/Xv6YMWPUk08+qaqrq1WnTp30zfyECRP8ZV922WVq165d6s9//nMO9xYAAAAAAACNC+7XAQCg+YNMdAAAaAEce+yxoZtugm58GXnzyz/zdFCTq6++Wrtg3n33XTV16lR1+umnq4kTJ+q/kdOFpnLyDTlx5JFH6umeCxYs0A8GVPRo/Pjx/t+Li4vV2LFj/SmiixYt0jffJ5xwQmi9e/fuVYcddliD9gMAAAAAAAD5CO7XAQCgeQMRHQAAWgB0kzxkyJCsLIuyGJctW6YdKy+88II6/vjj1TXXXKNuvfXWrCyf8xiffvpp1bt373oVVwIAAAAAAKA5gft1AABo3iATHQAAWgFvv/125Ofhw4c7X09Fii688EI97fTXv/61uvvuu/Xv6T2U00hZi8ybb76pCgsL1YEHHqiqqqpUz5491cyZM/2/0/TQOXPm+D8fdNBB+uZ7+fLl+kFCfvXt2zfLWw4AAAAAAED+g/t1AADIb+BEBwCAFgDlFq5Zsyb0O5qWyQWGqKAQTdGcNGmS+tOf/qRmzZql7r33XuuybrrpJp2HePDBB+vlPvXUU/4NPBU5uvnmm/UN+49+9CO1fv169Y1vfEOdf/75Ol+RuO6669TPfvYzNXToUDVs2DB12223qS1btvjLb9++vfrOd76jcxhpWim1aevWrfrmvrKyUi8bAAAAAACAlgTu1wEAoHkDER0AAFoAzz33nHaUSMhp8sknn+jvf/zjH6tHHnlE/cd//Id+3V/+8hftMLFRUlKibrzxRl3AqLy8XB111FH6vURFRYX697//rW+8Dz/8cP0z5THSjTfz7W9/W+cs0s01OV4uueQSdcYZZ+gbb+YnP/mJds/ccsstavHixapDhw66cBIVVgIAAAAAAKClgft1AABo3hTUceUIAAAALZKCggL1xBNP6IJDAAAAAAAAgPwC9+sAAJD/IBMdAAAAAAAAAAAAAAAAAHAAER0AAAAAAAAAAAAAAAAAcIA4FwAAAAAAAAAAAAAAAADAAZzoAAAAAAAAAAAAAAAAAIADiOgAAAAAAAAAAAAAAAAAgAOI6AAAAAAAAAAAAAAAAACAA4joAAAAAAAAAAAAAAAAAIADiOgAAAAAAAAAAAAAAAAAgAOI6AAAAAAAAAAAAAAAAACAA4joAAAAAAAAAAAAAAAAAIADiOgAAAAAAAAAAAAAAAAAgAOI6AAAAAAAAAAAAAAAAACAsvP/AQRO6w9qt0QwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Playing games with trained agent:\n",
      "\n",
      "--- Starting new game ---\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: []\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses letter: Z\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['z']\n",
      "Wrong guesses: 1/6\n",
      "Step reward: -0.20, Total reward: -0.20\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: N\n",
      "Word: _ n _ _ _ _ _ _ _ n _ _ \n",
      "Guessed letters: ['n', 'z']\n",
      "Wrong guesses: 1/6\n",
      "Step reward: 1.00, Total reward: 0.80\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: L\n",
      "Word: _ n _ _ l l _ _ _ n _ _ \n",
      "Guessed letters: ['l', 'n', 'z']\n",
      "Wrong guesses: 1/6\n",
      "Step reward: 1.00, Total reward: 1.80\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: A\n",
      "Word: _ n _ _ l l _ _ _ n _ _ \n",
      "Guessed letters: ['a', 'l', 'n', 'z']\n",
      "Wrong guesses: 2/6\n",
      "Step reward: -0.20, Total reward: 1.60\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: U\n",
      "Word: _ n _ _ l l _ _ _ n _ _ \n",
      "Guessed letters: ['a', 'l', 'n', 'u', 'z']\n",
      "Wrong guesses: 3/6\n",
      "Step reward: -0.20, Total reward: 1.40\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: Q\n",
      "Word: _ n _ _ l l _ _ _ n _ _ \n",
      "Guessed letters: ['a', 'l', 'n', 'q', 'u', 'z']\n",
      "Wrong guesses: 4/6\n",
      "Step reward: -0.20, Total reward: 1.20\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: M\n",
      "Word: _ n _ _ l l _ _ _ n _ _ \n",
      "Guessed letters: ['a', 'l', 'm', 'n', 'q', 'u', 'z']\n",
      "Wrong guesses: 5/6\n",
      "Step reward: -0.20, Total reward: 1.00\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: C\n",
      "Word: _ n _ _ l l _ _ _ n c _ \n",
      "Guessed letters: ['a', 'c', 'l', 'm', 'n', 'q', 'u', 'z']\n",
      "Wrong guesses: 5/6\n",
      "Step reward: 0.50, Total reward: 1.50\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: G\n",
      "Word: _ n _ _ l l _ g _ n c _ \n",
      "Guessed letters: ['a', 'c', 'g', 'l', 'm', 'n', 'q', 'u', 'z']\n",
      "Wrong guesses: 5/6\n",
      "Step reward: 0.50, Total reward: 2.00\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: E\n",
      "Word: _ n _ e l l _ g e n c e \n",
      "Guessed letters: ['a', 'c', 'e', 'g', 'l', 'm', 'n', 'q', 'u', 'z']\n",
      "Wrong guesses: 5/6\n",
      "Step reward: 1.50, Total reward: 3.50\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: Y\n",
      "Word: _ n _ e l l _ g e n c e \n",
      "Guessed letters: ['a', 'c', 'e', 'g', 'l', 'm', 'n', 'q', 'u', 'y', 'z']\n",
      "Wrong guesses: 6/6\n",
      "You lost! The word was: intelligence\n",
      "Step reward: -1.20, Total reward: 2.30\n",
      "Info: Valid move\n",
      "Game over! Total reward: 2.30\n",
      "The agent LOST! ✗ The word was: intelligence\n",
      "\n",
      "--- Starting new game ---\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: []\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses letter: Y\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['y']\n",
      "Wrong guesses: 1/6\n",
      "Step reward: -0.20, Total reward: -0.20\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: J\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['j', 'y']\n",
      "Wrong guesses: 2/6\n",
      "Step reward: -0.20, Total reward: -0.40\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: N\n",
      "Word: _ _ _ n _ _ _ _ _ _ _ n _ \n",
      "Guessed letters: ['j', 'n', 'y']\n",
      "Wrong guesses: 2/6\n",
      "Step reward: 1.00, Total reward: 0.60\n",
      "Info: Valid move\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 640\u001b[0m\n\u001b[1;32m    637\u001b[0m         play_game_with_agent(env, agent)\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 640\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 637\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlaying games with trained agent:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 637\u001b[0m     \u001b[43mplay_game_with_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 573\u001b[0m, in \u001b[0;36mplay_game_with_agent\u001b[0;34m(env, agent)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    572\u001b[0m     steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 573\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pause for readability\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during gameplay: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hangman Reinforcement Learning with PPO\n",
    "\n",
    "This codebase implements:\n",
    "1. A Hangman game environment\n",
    "2. A PPO agent for learning to play Hangman\n",
    "3. Training infrastructure\n",
    "4. Evaluation code for testing the agent\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "###########################################\n",
    "# 1. Hangman Environment\n",
    "###########################################\n",
    "\n",
    "class HangmanEnv:\n",
    "    def __init__(self, word_list=None, max_wrong_guesses=6, max_word_length=None):\n",
    "        # Default word list if none provided\n",
    "        if word_list is None:\n",
    "            self.word_list = [\n",
    "                \"apple\", \"banana\", \"orange\", \"grape\", \"pineapple\", \n",
    "                \"python\", \"javascript\", \"programming\", \"computer\", \"algorithm\",\n",
    "                \"network\", \"database\", \"machine\", \"learning\", \"intelligence\",\n",
    "                \"hangman\", \"reinforcement\", \"policy\", \"optimization\"\n",
    "            ]\n",
    "        else:\n",
    "            self.word_list = word_list\n",
    "        \n",
    "        # Set max word length - either provided or calculated from word list\n",
    "        if max_word_length is None:\n",
    "            self.max_word_length = max(len(word) for word in self.word_list)\n",
    "        else:\n",
    "            self.max_word_length = max_word_length\n",
    "            \n",
    "        self.max_wrong_guesses = max_wrong_guesses\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment for a new game.\"\"\"\n",
    "        self.target_word = random.choice(self.word_list).lower()\n",
    "        self.guessed_letters = set()\n",
    "        self.wrong_guesses = 0\n",
    "        self.game_over = False\n",
    "        self.won = False\n",
    "        return self._get_state()\n",
    "    \n",
    "    def _get_state(self):\n",
    "        \"\"\"Convert the current game state to a feature vector with fixed dimension.\"\"\"\n",
    "        # Current word state (1 for revealed letters, 0 for hidden)\n",
    "        # Pad or truncate to fixed length\n",
    "        word_state = []\n",
    "        for i in range(self.max_word_length):\n",
    "            if i < len(self.target_word):\n",
    "                word_state.append(1 if self.target_word[i] in self.guessed_letters else 0)\n",
    "            else:\n",
    "                word_state.append(0)  # Padding for shorter words\n",
    "        \n",
    "        # Letters that have been guessed (1 for guessed, 0 for not guessed)\n",
    "        alphabet_state = [1 if c in self.guessed_letters else 0 for c in string.ascii_lowercase]\n",
    "        \n",
    "        # Wrong guesses ratio\n",
    "        wrong_guesses_ratio = self.wrong_guesses / self.max_wrong_guesses\n",
    "        \n",
    "        # Combine all features\n",
    "        state = word_state + alphabet_state + [wrong_guesses_ratio]\n",
    "        \n",
    "        return np.array(state, dtype=np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take an action in the environment.\n",
    "        \n",
    "        Args:\n",
    "            action: An integer between 0-25 representing a letter (a-z)\n",
    "            \n",
    "        Returns:\n",
    "            next_state: The new state after taking the action\n",
    "            reward: The reward for taking the action\n",
    "            done: Whether the episode is done\n",
    "            info: Additional information (for debugging)\n",
    "        \"\"\"\n",
    "        if self.game_over:\n",
    "            return self._get_state(), 0, True, {\"message\": \"Game already over\"}\n",
    "        \n",
    "        # Convert action (0-25) to letter (a-z)\n",
    "        letter = string.ascii_lowercase[action]\n",
    "        \n",
    "        # Check if letter has already been guessed\n",
    "        if letter in self.guessed_letters:\n",
    "            return self._get_state(), -0.1, self.game_over, {\"message\": \"Letter already guessed\"}\n",
    "        \n",
    "        # Add letter to guessed letters\n",
    "        self.guessed_letters.add(letter)\n",
    "        \n",
    "        # Check if letter is in target word\n",
    "        if letter in self.target_word:\n",
    "            # Calculate how many new letters were revealed\n",
    "            newly_revealed = self.target_word.count(letter)\n",
    "            reward = 0.5 * newly_revealed\n",
    "            \n",
    "            # Check if word is complete\n",
    "            if all(c in self.guessed_letters for c in self.target_word):\n",
    "                self.game_over = True\n",
    "                self.won = True\n",
    "                reward += 5.0  # Bonus for winning\n",
    "        else:\n",
    "            self.wrong_guesses += 1\n",
    "            reward = -0.2  # Penalty for wrong guess\n",
    "            \n",
    "            # Check if game is lost\n",
    "            if self.wrong_guesses >= self.max_wrong_guesses:\n",
    "                self.game_over = True\n",
    "                reward -= 1.0  # Additional penalty for losing\n",
    "        \n",
    "        return self._get_state(), reward, self.game_over, {\"message\": \"Valid move\"}\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Display the current state of the game.\"\"\"\n",
    "        # Create a string representation of the current word state\n",
    "        word_display = \"\"\n",
    "        for c in self.target_word:\n",
    "            if c in self.guessed_letters:\n",
    "                word_display += c + \" \"\n",
    "            else:\n",
    "                word_display += \"_ \"\n",
    "        \n",
    "        print(f\"Word: {word_display}\")\n",
    "        print(f\"Guessed letters: {sorted(self.guessed_letters)}\")\n",
    "        print(f\"Wrong guesses: {self.wrong_guesses}/{self.max_wrong_guesses}\")\n",
    "        \n",
    "        if self.game_over:\n",
    "            if self.won:\n",
    "                print(\"You won!\")\n",
    "            else:\n",
    "                print(f\"You lost! The word was: {self.target_word}\")\n",
    "    \n",
    "    def get_valid_actions(self):\n",
    "        \"\"\"Return a mask of valid actions (unguessed letters).\"\"\"\n",
    "        return np.array([0 if c in self.guessed_letters else 1 for c in string.ascii_lowercase])\n",
    "\n",
    "###########################################\n",
    "# 2. PPO Agent\n",
    "###########################################\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=128):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        # Set the state dimension as an instance variable\n",
    "        self.state_dim = state_dim\n",
    "        \n",
    "        # Shared features\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Actor (policy) network\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, action_dim),\n",
    "        )\n",
    "        \n",
    "        # Critic (value) network\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, state):\n",
    "        # Ensure state has the correct shape\n",
    "        if isinstance(state, torch.Tensor):\n",
    "            if state.dim() == 1:\n",
    "                state = state.unsqueeze(0)  # Add batch dimension if missing\n",
    "            \n",
    "            # Check if state dimensions match what the network expects\n",
    "            if state.shape[1] != self.state_dim:\n",
    "                print(f\"Warning: Reshaping state from {state.shape} to match expected dim {self.state_dim}\")\n",
    "                # Resize state to match expected dimensions\n",
    "                if state.shape[1] < self.state_dim:\n",
    "                    # Pad with zeros\n",
    "                    padding = torch.zeros(state.shape[0], self.state_dim - state.shape[1]).to(state.device)\n",
    "                    state = torch.cat([state, padding], dim=1)\n",
    "                else:\n",
    "                    # Truncate\n",
    "                    state = state[:, :self.state_dim]\n",
    "        \n",
    "        features = self.features(state)\n",
    "        action_probs = F.softmax(self.actor(features), dim=-1)\n",
    "        value = self.critic(features)\n",
    "        return action_probs, value\n",
    "    \n",
    "    def act(self, state, valid_actions_mask=None):\n",
    "        # Convert state to tensor if it's not already\n",
    "        if not isinstance(state, torch.Tensor):\n",
    "            state = torch.FloatTensor(state).to(device)\n",
    "        \n",
    "        # Add batch dimension if missing\n",
    "        if state.dim() == 1:\n",
    "            state = state.unsqueeze(0)\n",
    "        \n",
    "        # Ensure state dimensions match what the network expects\n",
    "        if state.shape[1] != self.state_dim:\n",
    "            # Resize state to match expected dimensions\n",
    "            if state.shape[1] < self.state_dim:\n",
    "                # Pad with zeros\n",
    "                padding = torch.zeros(state.shape[0], self.state_dim - state.shape[1]).to(device)\n",
    "                state = torch.cat([state, padding], dim=1)\n",
    "            else:\n",
    "                # Truncate\n",
    "                state = state[:, :self.state_dim]\n",
    "        \n",
    "        action_probs, value = self.forward(state)\n",
    "        \n",
    "        # Apply mask for valid actions\n",
    "        if valid_actions_mask is not None:\n",
    "            mask = torch.FloatTensor(valid_actions_mask).to(device)\n",
    "            action_probs = action_probs * mask\n",
    "            # Re-normalize the probabilities (avoid division by zero)\n",
    "            if action_probs.sum() > 1e-8:\n",
    "                action_probs = action_probs / action_probs.sum()\n",
    "            else:\n",
    "                # If all actions are invalid, use uniform distribution over all actions\n",
    "                action_probs = torch.ones_like(action_probs) / action_probs.size(-1)\n",
    "        \n",
    "        dist = Categorical(action_probs)\n",
    "        action = dist.sample()\n",
    "        action_log_prob = dist.log_prob(action)\n",
    "        \n",
    "        return action.item(), action_log_prob.item(), value.item()\n",
    "    \n",
    "    def evaluate(self, states, actions):\n",
    "        action_probs, values = self.forward(states)\n",
    "        dist = Categorical(action_probs)\n",
    "        action_log_probs = dist.log_prob(actions)\n",
    "        dist_entropy = dist.entropy()\n",
    "        \n",
    "        return action_log_probs, values, dist_entropy\n",
    "        \n",
    "        # Critic (value) network\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.next_states = []\n",
    "        self.action_log_probs = []\n",
    "        self.values = []\n",
    "        self.dones = []\n",
    "        self.valid_actions_masks = []\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, action_log_prob, value, done, valid_actions_mask):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.next_states.append(next_state)\n",
    "        self.action_log_probs.append(action_log_prob)\n",
    "        self.values.append(value)\n",
    "        self.dones.append(done)\n",
    "        self.valid_actions_masks.append(valid_actions_mask)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.next_states = []\n",
    "        self.action_log_probs = []\n",
    "        self.values = []\n",
    "        self.dones = []\n",
    "        self.valid_actions_masks = []\n",
    "    \n",
    "    def get_batch(self):\n",
    "        return (\n",
    "            np.array(self.states),\n",
    "            np.array(self.actions),\n",
    "            np.array(self.rewards),\n",
    "            np.array(self.next_states),\n",
    "            np.array(self.action_log_probs),\n",
    "            np.array(self.values),\n",
    "            np.array(self.dones),\n",
    "            np.array(self.valid_actions_masks)\n",
    "        )\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.states)\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr=0.0003, gamma=0.99, eps_clip=0.2, k_epochs=4, hidden_dim=128):\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.k_epochs = k_epochs\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        print(f\"Initializing PPO with state_dim={state_dim}, action_dim={action_dim}\")\n",
    "        self.policy = ActorCritic(state_dim, action_dim, hidden_dim).to(device)\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        \n",
    "        self.memory = Memory()\n",
    "    \n",
    "    def select_action(self, state, valid_actions_mask=None):\n",
    "        # Check if state dimension matches expected dimension\n",
    "        if len(state) != self.state_dim:\n",
    "            print(f\"Warning: State dimension mismatch. Expected {self.state_dim}, got {len(state)}\")\n",
    "            # Pad or truncate state to match expected dimension\n",
    "            if len(state) < self.state_dim:\n",
    "                # Pad with zeros\n",
    "                state = np.pad(state, (0, self.state_dim - len(state)), 'constant')\n",
    "            else:\n",
    "                # Truncate\n",
    "                state = state[:self.state_dim]\n",
    "        \n",
    "        return self.policy.act(state, valid_actions_mask)\n",
    "    \n",
    "    def update(self):\n",
    "        # Get batch data from memory\n",
    "        states, actions, rewards, next_states, old_log_probs, old_values, dones, _ = self.memory.get_batch()\n",
    "        \n",
    "        # Ensure all states have the correct dimension\n",
    "        for i, state in enumerate(states):\n",
    "            if len(state) != self.state_dim:\n",
    "                if len(state) < self.state_dim:\n",
    "                    states[i] = np.pad(state, (0, self.state_dim - len(state)), 'constant')\n",
    "                else:\n",
    "                    states[i] = state[:self.state_dim]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        states = torch.FloatTensor(states).to(device)\n",
    "        actions = torch.LongTensor(actions).to(device)\n",
    "        old_log_probs = torch.FloatTensor(old_log_probs).to(device)\n",
    "        rewards = torch.FloatTensor(rewards).to(device)\n",
    "        old_values = torch.FloatTensor(old_values).to(device)\n",
    "        dones = torch.FloatTensor(dones).to(device)\n",
    "        \n",
    "        # Print shapes for debugging\n",
    "        print(f\"States shape: {states.shape}\")\n",
    "        print(f\"Actions shape: {actions.shape}\")\n",
    "        \n",
    "        # Compute returns and advantages\n",
    "        returns = []\n",
    "        advantages = []\n",
    "        discounted_reward = 0\n",
    "        \n",
    "        # Compute returns with GAE (Generalized Advantage Estimation)\n",
    "        for reward, value, done in zip(reversed(rewards), reversed(old_values), reversed(dones)):\n",
    "            if done:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward * (1 - done))\n",
    "            returns.insert(0, discounted_reward)\n",
    "        \n",
    "        returns = torch.FloatTensor(returns).to(device)\n",
    "        advantages = returns - old_values\n",
    "        \n",
    "        # Normalize advantages\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "        \n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.k_epochs):\n",
    "            try:\n",
    "                # Get new log probs, values and entropy\n",
    "                new_log_probs, state_values, dist_entropy = self.policy.evaluate(states, actions)\n",
    "                \n",
    "                # Compute ratio (pi_theta / pi_theta__old)\n",
    "                ratios = torch.exp(new_log_probs - old_log_probs.detach())\n",
    "                \n",
    "                # Compute surrogate losses\n",
    "                surr1 = ratios * advantages.detach()\n",
    "                surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages.detach()\n",
    "                \n",
    "                # Final loss with value loss and entropy bonus\n",
    "                actor_loss = -torch.min(surr1, surr2).mean()\n",
    "                critic_loss = F.mse_loss(state_values, returns.detach())\n",
    "                entropy_loss = -0.01 * dist_entropy.mean()  # Encourage exploration\n",
    "                \n",
    "                loss = actor_loss + 0.5 * critic_loss + entropy_loss\n",
    "                \n",
    "                # Take gradient step\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            except Exception as e:\n",
    "                print(f\"Error during policy update: {e}\")\n",
    "                return 0, 0, 0  # Return dummy values on error\n",
    "        \n",
    "        # Clear memory\n",
    "        self.memory.clear()\n",
    "        \n",
    "        return actor_loss.item(), critic_loss.item(), entropy_loss.item()\n",
    "    \n",
    "    def save(self, filepath):\n",
    "        torch.save({\n",
    "            'policy_state_dict': self.policy.state_dict(),\n",
    "            'state_dim': self.state_dim,\n",
    "            'action_dim': self.action_dim\n",
    "        }, filepath)\n",
    "    \n",
    "    def load(self, filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        \n",
    "        # Check if dimensions match\n",
    "        if hasattr(checkpoint, 'state_dim') and checkpoint['state_dim'] != self.state_dim:\n",
    "            print(f\"Warning: Loaded model has state_dim={checkpoint['state_dim']}, but current model has state_dim={self.state_dim}\")\n",
    "            \n",
    "        self.policy.load_state_dict(checkpoint['policy_state_dict'] \n",
    "                                  if 'policy_state_dict' in checkpoint \n",
    "                                  else checkpoint)\n",
    "\n",
    "###########################################\n",
    "# 3. Training Loop\n",
    "###########################################\n",
    "\n",
    "def train(env, agent, max_episodes=1000, max_steps=100, update_interval=20, eval_interval=100):\n",
    "    # Tracking metrics\n",
    "    episode_rewards = []\n",
    "    win_rates = []\n",
    "    losses = []\n",
    "    \n",
    "    # Training loop\n",
    "    for episode in range(1, max_episodes+1):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        \n",
    "        try:\n",
    "            for step in range(1, max_steps+1):\n",
    "                # Get valid actions mask\n",
    "                valid_actions_mask = env.get_valid_actions()\n",
    "                \n",
    "                # Select action\n",
    "                try:\n",
    "                    action, log_prob, value = agent.select_action(state, valid_actions_mask)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error selecting action: {e}\")\n",
    "                    print(f\"State shape: {state.shape if hasattr(state, 'shape') else len(state)}\")\n",
    "                    print(f\"First few state values: {state[:5]}\")\n",
    "                    break\n",
    "                \n",
    "                # Take action\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                \n",
    "                # Store in memory\n",
    "                agent.memory.add(state, action, reward, next_state, log_prob, value, done, valid_actions_mask)\n",
    "                \n",
    "                # Update state and reward\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "                \n",
    "                # Update policy if enough data collected\n",
    "                if agent.memory.size() >= update_interval and done:\n",
    "                    try:\n",
    "                        actor_loss, critic_loss, entropy_loss = agent.update()\n",
    "                        losses.append((actor_loss, critic_loss, entropy_loss))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error during policy update: {e}\")\n",
    "                        agent.memory.clear()  # Clear memory to avoid using problematic data\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            # Track episode reward\n",
    "            episode_rewards.append(episode_reward)\n",
    "            \n",
    "            # Print progress\n",
    "            if episode % 10 == 0:\n",
    "                print(f\"Episode {episode}/{max_episodes}, Reward: {episode_reward:.2f}\")\n",
    "            \n",
    "            # Evaluate agent performance\n",
    "            if episode % eval_interval == 0:\n",
    "                try:\n",
    "                    win_rate = evaluate(env, agent, num_episodes=100)\n",
    "                    win_rates.append(win_rate)\n",
    "                    \n",
    "                    print(f\"Episode {episode}/{max_episodes}, Win Rate: {win_rate:.2f}, Avg Reward: {np.mean(episode_rewards[-100:]):.2f}\")\n",
    "                    \n",
    "                    # Save model\n",
    "                    agent.save(f\"hangman_ppo_model_{episode}.pth\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during evaluation: {e}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in episode {episode}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return episode_rewards, win_rates, losses\n",
    "\n",
    "def evaluate(env, agent, num_episodes=100):\n",
    "    wins = 0\n",
    "    \n",
    "    for _ in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            valid_actions_mask = env.get_valid_actions()\n",
    "            action, _, _ = agent.select_action(state, valid_actions_mask)\n",
    "            state, _, done, _ = env.step(action)\n",
    "            \n",
    "            if done and env.won:\n",
    "                wins += 1\n",
    "    \n",
    "    return wins / num_episodes\n",
    "\n",
    "###########################################\n",
    "# 4. Main Function & Visualization\n",
    "###########################################\n",
    "\n",
    "def plot_metrics(episode_rewards, win_rates, eval_interval):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot episode rewards\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(episode_rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Episode Reward')\n",
    "    plt.title('Episode Rewards')\n",
    "    \n",
    "    # Plot win rates\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot([i * eval_interval for i in range(len(win_rates))], win_rates)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Win Rate')\n",
    "    plt.title('Win Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('hangman_ppo_metrics.png')\n",
    "    plt.show()\n",
    "\n",
    "def play_game_with_agent(env, agent):\n",
    "    \"\"\"Play a game with the agent and render each step.\"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    \n",
    "    print(\"\\n--- Starting new game ---\")\n",
    "    env.render()\n",
    "    \n",
    "    while not done and steps < 26:  # Maximum possible steps is 26 (all letters)\n",
    "        try:\n",
    "            valid_actions_mask = env.get_valid_actions()\n",
    "            action, _, _ = agent.select_action(state, valid_actions_mask)\n",
    "            letter = string.ascii_lowercase[action]\n",
    "            \n",
    "            print(f\"\\nAgent guesses letter: {letter.upper()}\")\n",
    "            \n",
    "            state, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            env.render()\n",
    "            print(f\"Step reward: {reward:.2f}, Total reward: {total_reward:.2f}\")\n",
    "            print(f\"Info: {info['message']}\")\n",
    "            \n",
    "            steps += 1\n",
    "            time.sleep(0.5)  # Pause for readability\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during gameplay: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Game over! Total reward: {total_reward:.2f}\")\n",
    "    if env.won:\n",
    "        print(\"The agent WON! ✓\")\n",
    "    else:\n",
    "        print(f\"The agent LOST! ✗ The word was: {env.target_word}\")\n",
    "    \n",
    "    return env.won, total_reward\n",
    "\n",
    "def main():\n",
    "    # Create environment\n",
    "    env = HangmanEnv()\n",
    "    \n",
    "    # Get state and action dimensions\n",
    "    state = env.reset()\n",
    "    state_dim = len(state)\n",
    "    action_dim = 26  # a-z\n",
    "    \n",
    "    print(f\"State dimension: {state_dim}\")\n",
    "    print(f\"Example state: {state[:10]}... (truncated)\")\n",
    "    print(f\"State contains {len(env.target_word)} values for the word + 26 for alphabet + 1 for wrong_guesses_ratio\")\n",
    "    \n",
    "    # Create agent with proper dimensions\n",
    "    agent = PPO(state_dim, action_dim)\n",
    "    \n",
    "    # Test forward pass with a single state to verify dimensions\n",
    "    try:\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        print(f\"State tensor shape: {state_tensor.shape}\")\n",
    "        action_probs, value = agent.policy.forward(state_tensor)\n",
    "        print(f\"Forward pass successful. Action probs shape: {action_probs.shape}\")\n",
    "        \n",
    "        # Test one action selection\n",
    "        valid_actions_mask = env.get_valid_actions()\n",
    "        action, log_prob, value = agent.select_action(state, valid_actions_mask)\n",
    "        print(f\"Test action selection successful: action={action} ({string.ascii_lowercase[action]})\")\n",
    "        \n",
    "        # Test environment step\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        print(f\"Test environment step successful: reward={reward}, done={done}\")\n",
    "        print(f\"Environment info: {info}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during test: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Train agent\n",
    "    print(\"\\nStarting training...\")\n",
    "    episode_rewards, win_rates, losses = train(env, agent, max_episodes=500, eval_interval=50)\n",
    "    \n",
    "    # Plot metrics\n",
    "    plot_metrics(episode_rewards, win_rates, eval_interval=50)\n",
    "    \n",
    "    # Save final model\n",
    "    agent.save(\"hangman_ppo_final.pth\")\n",
    "    \n",
    "    # Play a few games with the trained agent\n",
    "    print(\"\\nPlaying games with trained agent:\")\n",
    "    for _ in range(3):\n",
    "        play_game_with_agent(env, agent)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a192d6d4-3f1a-49de-bae0-725b3c621670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PPO with state_dim=56, action_dim=26\n",
      "\n",
      "--- Starting new game ---\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: []\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses letter: K\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['k']\n",
      "Wrong guesses: 1/6\n",
      "Step reward: -0.20, Total reward: -0.20\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: O\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['k', 'o']\n",
      "Wrong guesses: 2/6\n",
      "Step reward: -0.20, Total reward: -0.40\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: F\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['f', 'k', 'o']\n",
      "Wrong guesses: 3/6\n",
      "Step reward: -0.20, Total reward: -0.60\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: D\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['d', 'f', 'k', 'o']\n",
      "Wrong guesses: 4/6\n",
      "Step reward: -0.20, Total reward: -0.80\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: X\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['d', 'f', 'k', 'o', 'x']\n",
      "Wrong guesses: 5/6\n",
      "Step reward: -0.20, Total reward: -1.00\n",
      "Info: Valid move\n",
      "\n",
      "Agent guesses letter: R\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Guessed letters: ['d', 'f', 'k', 'o', 'r', 'x']\n",
      "Wrong guesses: 6/6\n",
      "You lost! The word was: tuneableness\n",
      "Step reward: -1.20, Total reward: -2.20\n",
      "Info: Valid move\n",
      "Game over! Total reward: -2.20\n",
      "The agent LOST! ✗ The word was: tuneableness\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, -2.2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = HangmanEnv(words)\n",
    " # Get state and action dimensions\n",
    "state = env.reset()\n",
    "state_dim = len(state)\n",
    "action_dim = 26  # a-z\n",
    "agent = PPO(state_dim, action_dim)\n",
    "play_game_with_agent(env, agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ca0a6d-8d5f-4ba8-ba36-6ae6538c4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words_250000_train.txt\", 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    words = [line.strip().lower() for line in f if line.strip() and all(c in string.ascii_lowercase for c in line.strip().lower())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a94fdbb-f37d-4c85-a048-9e6b6a13ccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 227300 words with max length 29\n",
      "State dimension: 56\n",
      "Agent loaded from best_hangman_agent_v2.pkl\n",
      "Best agent final evaluation - Win Rate: 6.50%, Avg Reward: -9.06\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: __e_____\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: __e____t\n",
      "Guessed: e, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: __e____t\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: __e__o_t\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: __e__o_t\n",
      "Guessed: a, e, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: i_e__o_t\n",
      "Guessed: a, e, i, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: i_e__ost\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: i_e__ost\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: i_e_rost\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: i_e_rost\n",
      "Guessed: a, d, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: i_e_rost\n",
      "Guessed: a, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: ice_rost\n",
      "Guessed: a, c, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: ice_rost\n",
      "Guessed: a, c, d, e, h, i, l, n, o, p, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: icefrost\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: __e_____\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: __e____t\n",
      "Guessed: e, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: __e____t\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: __e__o_t\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: __e__o_t\n",
      "Guessed: a, e, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: i_e__o_t\n",
      "Guessed: a, e, i, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: i_e__ost\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: i_e__ost\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: i_e_rost\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: i_e_rost\n",
      "Guessed: a, d, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: i_e_rost\n",
      "Guessed: a, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: ice_rost\n",
      "Guessed: a, c, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: ice_rost\n",
      "Guessed: a, c, d, e, h, i, l, n, o, p, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: icefrost\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ______\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ______\n",
      "Guessed: e\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: __t___\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: __t___\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: __t_o_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: __t_o_\n",
      "Guessed: a, e, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: __t_on\n",
      "Guessed: a, e, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: __t_on\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: __t_on\n",
      "Guessed: a, e, i, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: __thon\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: __thon\n",
      "Guessed: a, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: python\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _____\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ___e_\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: ___e_\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: ___e_\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _o_e_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: _one_\n",
      "Guessed: a, e, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _one_\n",
      "Guessed: a, e, i, n, o, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _one_\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: _one_\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: _one_\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: money\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: __e_____\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: __e____t\n",
      "Guessed: e, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: __e____t\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: __e__o_t\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: __e__o_t\n",
      "Guessed: a, e, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: i_e__o_t\n",
      "Guessed: a, e, i, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: i_e__ost\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: i_e__ost\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: i_e_rost\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: i_e_rost\n",
      "Guessed: a, d, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: i_e_rost\n",
      "Guessed: a, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: ice_rost\n",
      "Guessed: a, c, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: ice_rost\n",
      "Guessed: a, c, d, e, h, i, l, n, o, p, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: icefrost\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _____\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ___e_\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: ___e_\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: ___e_\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _o_e_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: _one_\n",
      "Guessed: a, e, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _one_\n",
      "Guessed: a, e, i, n, o, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _one_\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: _one_\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: _one_\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: money\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _____\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ___e_\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: ___e_\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: ___e_\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _o_e_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: _one_\n",
      "Guessed: a, e, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _one_\n",
      "Guessed: a, e, i, n, o, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _one_\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: _one_\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: _one_\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: money\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: __e_____\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: __e____t\n",
      "Guessed: e, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: __e____t\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: __e__o_t\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: __e__o_t\n",
      "Guessed: a, e, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: i_e__o_t\n",
      "Guessed: a, e, i, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: i_e__ost\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: i_e__ost\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: i_e_rost\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: i_e_rost\n",
      "Guessed: a, d, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: i_e_rost\n",
      "Guessed: a, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: ice_rost\n",
      "Guessed: a, c, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: ice_rost\n",
      "Guessed: a, c, d, e, h, i, l, n, o, p, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: icefrost\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hangman GFPO (Gradient-Free Policy Optimization) Agent\n",
    "\n",
    "This implementation uses a neural network policy that is trained using a gradient-free\n",
    "evolutionary strategy approach to optimize performance in the Hangman game.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MAX_WRONG_GUESSES = 6  # Standard Hangman rules\n",
    "POPULATION_SIZE = 50   # Number of agents in the population\n",
    "NUM_GENERATIONS = 100  # Number of generations to train\n",
    "ELITE_SIZE = 5         # Number of top agents to keep unchanged\n",
    "MUTATION_RATE = 0.1    # Probability of mutation\n",
    "MUTATION_SCALE = 0.2   # Scale of mutations\n",
    "TOURNAMENT_SIZE = 5    # Tournament selection size\n",
    "NUM_EVAL_GAMES = 100   # Number of games to evaluate each agent\n",
    "\n",
    "# Helper dictionaries for letter frequencies in English\n",
    "LETTER_FREQ = {\n",
    "    'a': 0.082, 'b': 0.015, 'c': 0.028, 'd': 0.043, 'e': 0.127, 'f': 0.022,\n",
    "    'g': 0.020, 'h': 0.061, 'i': 0.070, 'j': 0.002, 'k': 0.008, 'l': 0.040,\n",
    "    'm': 0.024, 'n': 0.067, 'o': 0.075, 'p': 0.019, 'q': 0.001, 'r': 0.060,\n",
    "    's': 0.063, 't': 0.091, 'u': 0.028, 'v': 0.010, 'w': 0.023, 'x': 0.001,\n",
    "    'y': 0.020, 'z': 0.001\n",
    "}\n",
    "\n",
    "# Dictionary providing positions where each letter commonly appears\n",
    "LETTER_POSITIONS = {\n",
    "    'a': [0, 1, 2], 'b': [0], 'c': [0], 'd': [0, 3], 'e': [1, 4], 'f': [0],\n",
    "    'g': [0], 'h': [0, 1], 'i': [1, 2], 'j': [0], 'k': [0, 3], 'l': [0, 3],\n",
    "    'm': [0], 'n': [1, 3], 'o': [1, 2], 'p': [0], 'q': [0], 'r': [0, 2],\n",
    "    's': [0, 4], 't': [0, 3], 'u': [1, 3], 'v': [0], 'w': [0], 'x': [0],\n",
    "    'y': [4], 'z': [0]\n",
    "}\n",
    "\n",
    "# Load a word list, or use a default one if loading fails\n",
    "def load_word_list(filename=\"words_250000_train.txt\"):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return [line.strip().lower() for line in f if line.strip() and all(c.isalpha() for c in line.strip())]\n",
    "    except FileNotFoundError:\n",
    "        # Fallback to a small default list if file not found\n",
    "        return [\"hangman\", \"python\", \"computer\", \"algorithm\", \"neural\", \n",
    "                \"network\", \"machine\", \"learning\", \"artificial\", \"intelligence\",\n",
    "                \"evolution\", \"strategy\", \"gradient\", \"optimization\", \"game\",\n",
    "                \"player\", \"alphabet\", \"language\", \"dictionary\", \"random\",\n",
    "                \"probability\", \"frequency\", \"statistics\", \"reinforcement\",\n",
    "                \"training\", \"simulation\", \"accuracy\", \"performance\", \"example\"]\n",
    "\n",
    "class HangmanEnvironment:\n",
    "    def __init__(self, word_list):\n",
    "        self.word_list = word_list\n",
    "        self.max_word_length = max(len(word) for word in word_list)\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.word = random.choice(self.word_list)\n",
    "        self.guessed_letters = set()\n",
    "        self.wrong_guesses = 0\n",
    "        self.state = self._get_state()\n",
    "        self.done = False\n",
    "        self.won = False\n",
    "        return self.state\n",
    "    \n",
    "    def _get_state(self):\n",
    "        \"\"\"\n",
    "        State representation:\n",
    "        - 26 features for guessed letters (1 if guessed, 0 otherwise)\n",
    "        - Current word representation (1 for revealed letter, 0 for hidden), padded to max length\n",
    "        - Wrong guesses remaining (normalized)\n",
    "        \"\"\"\n",
    "        # Guessed letters\n",
    "        alphabet_state = np.zeros(26)\n",
    "        for letter in self.guessed_letters:\n",
    "            if 'a' <= letter <= 'z':  # Ensure valid index\n",
    "                idx = ord(letter) - ord('a')\n",
    "                if 0 <= idx < 26:  # Double-check index bounds\n",
    "                    alphabet_state[idx] = 1\n",
    "        \n",
    "        # Current word representation - padded to a fixed length\n",
    "        word_state = np.zeros(self.max_word_length)\n",
    "        for i, letter in enumerate(self.word):\n",
    "            if letter in self.guessed_letters:\n",
    "                word_state[i] = 1\n",
    "        \n",
    "        # Wrong guesses remaining (normalized)\n",
    "        wrong_guesses_remaining = (MAX_WRONG_GUESSES - self.wrong_guesses) / MAX_WRONG_GUESSES\n",
    "        \n",
    "        # Return vectorized state with fixed dimensions\n",
    "        return np.concatenate([\n",
    "            alphabet_state,\n",
    "            word_state,\n",
    "            np.array([wrong_guesses_remaining])\n",
    "        ])\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take an action (guess a letter) and return next state, reward, done.\"\"\"\n",
    "        # Convert action index to letter\n",
    "        letter = chr(action + ord('a'))\n",
    "        \n",
    "        # Check if already guessed\n",
    "        if letter in self.guessed_letters:\n",
    "            reward = -0.5  # Penalty for guessing the same letter\n",
    "            return self.state, reward, self.done, {\"won\": self.won}\n",
    "        \n",
    "        # Add letter to guessed set\n",
    "        self.guessed_letters.add(letter)\n",
    "        \n",
    "        # Check if letter is in the word\n",
    "        if letter in self.word:\n",
    "            # Calculate how many instances of the letter were found\n",
    "            occurrences = self.word.count(letter)\n",
    "            reward = occurrences * 1.0  # Reward based on occurrences\n",
    "        else:\n",
    "            # Incorrect guess\n",
    "            self.wrong_guesses += 1\n",
    "            reward = -2.0\n",
    "        \n",
    "        # Update state\n",
    "        self.state = self._get_state()\n",
    "        \n",
    "        # Check if game is over\n",
    "        all_letters_guessed = all(letter in self.guessed_letters for letter in self.word)\n",
    "        if all_letters_guessed:\n",
    "            self.done = True\n",
    "            self.won = True\n",
    "            reward += 5.0  # Bonus for winning\n",
    "        elif self.wrong_guesses >= MAX_WRONG_GUESSES:\n",
    "            self.done = True\n",
    "            self.won = False\n",
    "            reward -= 5.0  # Additional penalty for losing\n",
    "        \n",
    "        return self.state, reward, self.done, {\"won\": self.won}\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Render the current state of the game.\"\"\"\n",
    "        displayed_word = ''.join([letter if letter in self.guessed_letters else '_' for letter in self.word])\n",
    "        guessed = ', '.join(sorted(self.guessed_letters))\n",
    "        print(f\"Word: {displayed_word}\")\n",
    "        print(f\"Guessed: {guessed}\")\n",
    "        print(f\"Wrong guesses: {self.wrong_guesses}/{MAX_WRONG_GUESSES}\")\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.weights = []\n",
    "        \n",
    "        # Input to first hidden layer\n",
    "        self.weights.append(np.random.randn(input_dim, hidden_dims[0]) * 0.1)\n",
    "        self.biases = [np.random.randn(hidden_dims[0]) * 0.1]\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            self.weights.append(np.random.randn(hidden_dims[i], hidden_dims[i+1]) * 0.1)\n",
    "            self.biases.append(np.random.randn(hidden_dims[i+1]) * 0.1)\n",
    "        \n",
    "        # Output layer\n",
    "        self.weights.append(np.random.randn(hidden_dims[-1], output_dim) * 0.1)\n",
    "        self.biases.append(np.random.randn(output_dim) * 0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        activations = [x]\n",
    "        \n",
    "        # Hidden layers with ReLU activation\n",
    "        for i in range(len(self.hidden_dims)):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            a = np.maximum(0, z)  # ReLU activation\n",
    "            activations.append(a)\n",
    "        \n",
    "        # Output layer (linear activation for raw logits)\n",
    "        z_out = np.dot(activations[-1], self.weights[-1]) + self.biases[-1]\n",
    "        \n",
    "        return z_out\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        \"\"\"Get all parameters (weights and biases) as a flat array.\"\"\"\n",
    "        params = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            params.append(w.flatten())\n",
    "            params.append(b.flatten())\n",
    "        return np.concatenate(params)\n",
    "    \n",
    "    def set_parameters(self, params):\n",
    "        \"\"\"Set all parameters (weights and biases) from a flat array.\"\"\"\n",
    "        idx = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            w_shape = self.weights[i].shape\n",
    "            b_shape = self.biases[i].shape\n",
    "            \n",
    "            # Extract and reshape weights\n",
    "            w_size = np.prod(w_shape)\n",
    "            self.weights[i] = params[idx:idx+w_size].reshape(w_shape)\n",
    "            idx += w_size\n",
    "            \n",
    "            # Extract and reshape biases\n",
    "            b_size = np.prod(b_shape)\n",
    "            self.biases[i] = params[idx:idx+b_size].reshape(b_shape)\n",
    "            idx += b_size\n",
    "\n",
    "class HangmanAgent:\n",
    "    def __init__(self, input_dim, word_length_estimate=10):\n",
    "        # Store the input dimension\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Neural network for policy\n",
    "        self.policy_network = NeuralNetwork(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dims=[64, 32],  # Hidden layer dimensions\n",
    "            output_dim=26  # One output per letter\n",
    "        )\n",
    "        \n",
    "        # Parameters for letter frequency heuristic\n",
    "        self.letter_freq_weight = 0.3\n",
    "        self.pattern_weight = 0.4\n",
    "        self.network_weight = 0.3\n",
    "        \n",
    "        # For pattern matching\n",
    "        self.max_word_length = word_length_estimate\n",
    "        \n",
    "    def select_action(self, state, word_length, guessed_letters):\n",
    "        \"\"\"Select an action based on the current state.\"\"\"\n",
    "        # Ensure state has the correct shape for network\n",
    "        if len(state) != self.policy_network.input_dim:\n",
    "            # Pad or truncate state to match expected input dimension\n",
    "            if len(state) < self.policy_network.input_dim:\n",
    "                # Pad with zeros\n",
    "                padded_state = np.zeros(self.policy_network.input_dim)\n",
    "                padded_state[:len(state)] = state\n",
    "                state = padded_state\n",
    "            else:\n",
    "                # Truncate\n",
    "                state = state[:self.policy_network.input_dim]\n",
    "        \n",
    "        # Get neural network logits\n",
    "        network_logits = self.policy_network.forward(state)\n",
    "        \n",
    "        # Create letter frequency scores\n",
    "        letter_scores = np.zeros(26)\n",
    "        for i, letter in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            if chr(i + ord('a')) not in guessed_letters:\n",
    "                letter_scores[i] = LETTER_FREQ.get(letter, 0.01)\n",
    "        \n",
    "        # Create pattern-based scores\n",
    "        pattern_scores = np.zeros(26)\n",
    "        # We don't have direct access to the word here, so use a simplified approach\n",
    "        # Simply boost common letters in general\n",
    "        for i, letter in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            if chr(i + ord('a')) not in guessed_letters:\n",
    "                pattern_scores[i] = LETTER_FREQ.get(letter, 0.01) * 2  # Boost common letters\n",
    "        \n",
    "        # Combine all scores (weighted sum)\n",
    "        combined_scores = (\n",
    "            self.network_weight * network_logits +\n",
    "            self.letter_freq_weight * letter_scores +\n",
    "            self.pattern_weight * pattern_scores\n",
    "        )\n",
    "        \n",
    "        # Mask out already guessed letters\n",
    "        for i, letter in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            if chr(i + ord('a')) in guessed_letters:\n",
    "                combined_scores[i] = float('-inf')\n",
    "        \n",
    "        # Select the best action\n",
    "        return np.argmax(combined_scores)\n",
    "    \n",
    "    def train(self, environment, episodes=100):\n",
    "        \"\"\"Train the agent (used for supervised pre-training if needed)\"\"\"\n",
    "        # Placeholder for potential supervised pre-training\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, environment, num_episodes=100):\n",
    "        \"\"\"Evaluate the agent's performance.\"\"\"\n",
    "        wins = 0\n",
    "        total_reward = 0\n",
    "        \n",
    "        for _ in range(num_episodes):\n",
    "            state = environment.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            \n",
    "            while not done:\n",
    "                # Get word length from the state\n",
    "                word_length = len(environment.word)\n",
    "                \n",
    "                # Select action\n",
    "                action = self.select_action(state, word_length, environment.guessed_letters)\n",
    "                \n",
    "                # Take action\n",
    "                next_state, reward, done, info = environment.step(action)\n",
    "                \n",
    "                # Update stats\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "                \n",
    "                if done and info[\"won\"]:\n",
    "                    wins += 1\n",
    "            \n",
    "            total_reward += episode_reward\n",
    "        \n",
    "        return wins / num_episodes, total_reward / num_episodes\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        \"\"\"Get all trainable parameters.\"\"\"\n",
    "        policy_params = self.policy_network.get_parameters()\n",
    "        heuristic_params = np.array([\n",
    "            self.letter_freq_weight,\n",
    "            self.pattern_weight,\n",
    "            self.network_weight\n",
    "        ])\n",
    "        return np.concatenate([policy_params, heuristic_params])\n",
    "    \n",
    "    def set_parameters(self, params):\n",
    "        \"\"\"Set all trainable parameters.\"\"\"\n",
    "        # Extract neural network parameters\n",
    "        policy_params_count = len(self.policy_network.get_parameters())\n",
    "        policy_params = params[:policy_params_count]\n",
    "        \n",
    "        # Extract heuristic weights\n",
    "        heuristic_params = params[policy_params_count:]\n",
    "        \n",
    "        # Normalize heuristic weights to sum to 1\n",
    "        heuristic_sum = np.sum(heuristic_params)\n",
    "        if heuristic_sum > 0:\n",
    "            heuristic_params = heuristic_params / heuristic_sum\n",
    "        else:\n",
    "            heuristic_params = np.array([0.3, 0.4, 0.3])  # Default values\n",
    "        \n",
    "        # Set parameters\n",
    "        self.policy_network.set_parameters(policy_params)\n",
    "        self.letter_freq_weight = heuristic_params[0]\n",
    "        self.pattern_weight = heuristic_params[1]\n",
    "        self.network_weight = heuristic_params[2]\n",
    "\n",
    "class GFPO:\n",
    "    def __init__(self, env, agent_class, input_dim, word_length_estimate=10):\n",
    "        self.env = env\n",
    "        self.agent_class = agent_class\n",
    "        self.input_dim = input_dim\n",
    "        self.word_length_estimate = word_length_estimate\n",
    "        self.population = []\n",
    "        self.best_agent = None\n",
    "        self.best_fitness = -float('inf')\n",
    "        self.fitness_history = []\n",
    "        \n",
    "        # Initialize population\n",
    "        self._initialize_population()\n",
    "    \n",
    "    def _initialize_population(self):\n",
    "        \"\"\"Initialize the population of agents.\"\"\"\n",
    "        self.population = []\n",
    "        for _ in range(POPULATION_SIZE):\n",
    "            agent = self.agent_class(self.input_dim, self.word_length_estimate)\n",
    "            self.population.append(agent)\n",
    "    \n",
    "    def _evaluate_fitness(self, agent):\n",
    "        \"\"\"Evaluate the fitness of an agent.\"\"\"\n",
    "        win_rate, avg_reward = agent.evaluate(self.env, NUM_EVAL_GAMES)\n",
    "        # Fitness is a combination of win rate and average reward\n",
    "        fitness = 0.8 * win_rate + 0.2 * (avg_reward / 10.0)  # Normalize reward component\n",
    "        return fitness, win_rate\n",
    "    \n",
    "    def _tournament_selection(self):\n",
    "        \"\"\"Select an agent using tournament selection.\"\"\"\n",
    "        tournament = random.sample(list(enumerate(self.population)), TOURNAMENT_SIZE)\n",
    "        fitnesses = []\n",
    "        \n",
    "        for idx, agent in tournament:\n",
    "            fitness, _ = self._evaluate_fitness(agent)\n",
    "            fitnesses.append((idx, fitness))\n",
    "        \n",
    "        # Select the best agent from the tournament\n",
    "        selected_idx, _ = max(fitnesses, key=lambda x: x[1])\n",
    "        return selected_idx\n",
    "    \n",
    "    def _crossover(self, parent1, parent2):\n",
    "        \"\"\"Create a new agent by crossing over two parents.\"\"\"\n",
    "        child = self.agent_class(self.input_dim, self.word_length_estimate)\n",
    "        \n",
    "        # Get parameters from parents\n",
    "        params1 = parent1.get_parameters()\n",
    "        params2 = parent2.get_parameters()\n",
    "        \n",
    "        # Uniform crossover\n",
    "        mask = np.random.rand(len(params1)) < 0.5\n",
    "        child_params = np.where(mask, params1, params2)\n",
    "        \n",
    "        # Set parameters in child\n",
    "        child.set_parameters(child_params)\n",
    "        return child\n",
    "    \n",
    "    def _mutate(self, agent):\n",
    "        \"\"\"Mutate an agent's parameters.\"\"\"\n",
    "        params = agent.get_parameters()\n",
    "        \n",
    "        # Apply random mutations with probability MUTATION_RATE\n",
    "        mask = np.random.rand(len(params)) < MUTATION_RATE\n",
    "        mutations = np.random.randn(len(params)) * MUTATION_SCALE\n",
    "        \n",
    "        # Apply mutations\n",
    "        params = params + mask * mutations\n",
    "        \n",
    "        # Set mutated parameters\n",
    "        agent.set_parameters(params)\n",
    "    \n",
    "    def train(self, generations=NUM_GENERATIONS):\n",
    "        \"\"\"Train the population for a specified number of generations.\"\"\"\n",
    "        for generation in tqdm(range(generations), desc=\"Training Generations\"):\n",
    "            # Evaluate all agents\n",
    "            fitness_results = []\n",
    "            for i, agent in enumerate(self.population):\n",
    "                fitness, win_rate = self._evaluate_fitness(agent)\n",
    "                fitness_results.append((i, fitness, win_rate))\n",
    "            \n",
    "            # Sort by fitness\n",
    "            fitness_results.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Update best agent if we found a better one\n",
    "            if fitness_results[0][1] > self.best_fitness:\n",
    "                self.best_fitness = fitness_results[0][1]\n",
    "                self.best_agent = self.population[fitness_results[0][0]]\n",
    "                best_win_rate = fitness_results[0][2]\n",
    "                print(f\"Generation {generation}: New best agent with fitness {self.best_fitness:.4f}, win rate {best_win_rate:.2%}\")\n",
    "            \n",
    "            # Record best fitness for this generation\n",
    "            self.fitness_history.append(fitness_results[0][1])\n",
    "            \n",
    "            # Create the next generation\n",
    "            next_generation = []\n",
    "            \n",
    "            # Elitism: keep the best agents unchanged\n",
    "            for i in range(ELITE_SIZE):\n",
    "                elite_idx = fitness_results[i][0]\n",
    "                next_generation.append(self.population[elite_idx])\n",
    "            \n",
    "            # Create the rest of the population through selection, crossover, and mutation\n",
    "            while len(next_generation) < POPULATION_SIZE:\n",
    "                # Tournament selection\n",
    "                parent1_idx = self._tournament_selection()\n",
    "                parent2_idx = self._tournament_selection()\n",
    "                \n",
    "                # Crossover\n",
    "                child = self._crossover(self.population[parent1_idx], self.population[parent2_idx])\n",
    "                \n",
    "                # Mutation\n",
    "                self._mutate(child)\n",
    "                \n",
    "                # Add to next generation\n",
    "                next_generation.append(child)\n",
    "            \n",
    "            # Update population\n",
    "            self.population = next_generation\n",
    "            \n",
    "            # Print progress every 10 generations\n",
    "            if (generation + 1) % 10 == 0 or generation == 0:\n",
    "                avg_fitness = np.mean([res[1] for res in fitness_results])\n",
    "                print(f\"Generation {generation + 1}/{generations} - Best Fitness: {self.best_fitness:.4f}, Avg Fitness: {avg_fitness:.4f}\")\n",
    "        \n",
    "        # Final evaluation of best agent\n",
    "        self.best_fitness, win_rate = self._evaluate_fitness(self.best_agent)\n",
    "        print(f\"Training complete. Best agent win rate: {win_rate:.2%}\")\n",
    "        \n",
    "        return self.best_agent\n",
    "    \n",
    "    def plot_training_progress(self):\n",
    "        \"\"\"Plot the training progress.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.fitness_history)\n",
    "        plt.title('Training Progress')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Best Fitness')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('training_progress.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def save_best_agent(self, filename='best_hangman_agent.pkl'):\n",
    "        \"\"\"Save the best agent to a file.\"\"\"\n",
    "        if self.best_agent:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(self.best_agent, f)\n",
    "            print(f\"Best agent saved to {filename}\")\n",
    "    \n",
    "    def load_best_agent(self, filename='best_hangman_agent_v2.pkl'):\n",
    "        \"\"\"Load the best agent from a file.\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.best_agent = pickle.load(f)\n",
    "            print(f\"Agent loaded from {filename}\")\n",
    "            return self.best_agent\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {filename} not found. No agent loaded.\")\n",
    "            return None\n",
    "\n",
    "def play_hangman_interactive(agent, word_list=None):\n",
    "    \"\"\"Play hangman interactively with the trained agent.\"\"\"\n",
    "    if word_list is None:\n",
    "        word_list = load_word_list()\n",
    "    \n",
    "    env = HangmanEnvironment(word_list)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    print(\"Starting a new game of Hangman!\")\n",
    "    env.render()\n",
    "    \n",
    "    while not done:\n",
    "        # Get word length from the state\n",
    "        word_length = len(env.word)\n",
    "        \n",
    "        # Agent selects an action\n",
    "        action = agent.select_action(state, word_length, env.guessed_letters)\n",
    "        letter = chr(action + ord('a'))\n",
    "        \n",
    "        print(f\"\\nAgent guesses: {letter}\")\n",
    "        \n",
    "        # Take action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Update state\n",
    "        state = next_state\n",
    "        \n",
    "        # Render the environment\n",
    "        env.render()\n",
    "        \n",
    "        # Check if game is over\n",
    "        if done:\n",
    "            if info[\"won\"]:\n",
    "                print(\"Agent won!\")\n",
    "            else:\n",
    "                print(f\"Agent lost! The word was: {env.word}\")\n",
    "    \n",
    "    return info[\"won\"]\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load word list\n",
    "    word_list = load_word_list()\n",
    "    print(f\"Loaded {len(word_list)} words with max length {max(len(w) for w in word_list)}\")\n",
    "    \n",
    "    # Create environment\n",
    "    env = HangmanEnvironment(word_list)\n",
    "    \n",
    "    # Get state dimensions\n",
    "    state = env.reset()\n",
    "    input_dim = len(state)\n",
    "    print(f\"State dimension: {input_dim}\")\n",
    "    \n",
    "    # Create and train the GFPO system\n",
    "    max_word_length = max(len(w) for w in word_list)\n",
    "    gfpo = GFPO(env, HangmanAgent, input_dim, word_length_estimate=max_word_length)\n",
    "    \n",
    "    # Check if a trained agent exists\n",
    "    best_agent = gfpo.load_best_agent()\n",
    "    \n",
    "    if best_agent is None:\n",
    "        print(\"Training a new agent...\")\n",
    "        best_agent = gfpo.train(NUM_GENERATIONS)\n",
    "        gfpo.plot_training_progress()\n",
    "        gfpo.save_best_agent()\n",
    "    \n",
    "    # Evaluate best agent\n",
    "    win_rate, avg_reward = best_agent.evaluate(env, 200)\n",
    "    print(f\"Best agent final evaluation - Win Rate: {win_rate:.2%}, Avg Reward: {avg_reward:.2f}\")\n",
    "    \n",
    "    # Play interactive games\n",
    "    while True:\n",
    "        play_again = input(\"\\nDo you want to see the agent play a game? (y/n): \").lower()\n",
    "        if play_again != 'y':\n",
    "            break\n",
    "        wl = ['icefrost','money','python']\n",
    "        play_hangman_interactive(best_agent, wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69a3a935-8447-43ab-97ae-d68a3bd22824",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 227300 words with max length 29\n",
      "State dimension: 56\n",
      "File best_hangman_agent.pkl not found. No agent loaded.\n",
      "Training a new agent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:   0%|                             | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: New best agent with fitness 0.0422, win rate 8.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:   1%|▏                    | 1/100 [00:10<18:07, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/100 - Best Fitness: 0.0422, Avg Fitness: -0.0258\n",
      "Generation 1: New best agent with fitness 0.0892, win rate 11.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:   2%|▍                    | 2/100 [00:22<18:01, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2: New best agent with fitness 0.1026, win rate 13.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:   3%|▋                    | 3/100 [00:33<17:48, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3: New best agent with fitness 0.1072, win rate 12.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:   6%|█▎                   | 6/100 [01:07<17:40, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 6: New best agent with fitness 0.1534, win rate 16.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:   8%|█▋                   | 8/100 [01:30<17:33, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 8: New best agent with fitness 0.1616, win rate 18.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  10%|██                  | 10/100 [01:53<17:33, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 10/100 - Best Fitness: 0.1616, Avg Fitness: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  17%|███▍                | 17/100 [03:17<16:24, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 17: New best agent with fitness 0.1630, win rate 19.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  18%|███▌                | 18/100 [03:29<16:13, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 18: New best agent with fitness 0.1670, win rate 19.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  20%|████                | 20/100 [03:52<15:44, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 20/100 - Best Fitness: 0.1670, Avg Fitness: 0.0482\n",
      "Generation 20: New best agent with fitness 0.1834, win rate 19.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  25%|█████               | 25/100 [04:52<14:54, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 25: New best agent with fitness 0.2366, win rate 25.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  30%|██████              | 30/100 [05:52<13:52, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 30/100 - Best Fitness: 0.2366, Avg Fitness: 0.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  40%|████████            | 40/100 [07:50<11:47, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 40/100 - Best Fitness: 0.2366, Avg Fitness: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  50%|██████████          | 50/100 [09:48<09:48, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 50/100 - Best Fitness: 0.2366, Avg Fitness: 0.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  60%|████████████        | 60/100 [11:46<07:50, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 60/100 - Best Fitness: 0.2366, Avg Fitness: 0.0695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  70%|██████████████      | 70/100 [13:43<05:52, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 70/100 - Best Fitness: 0.2366, Avg Fitness: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  80%|████████████████    | 80/100 [15:40<03:56, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 80/100 - Best Fitness: 0.2366, Avg Fitness: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations:  90%|██████████████████  | 90/100 [17:38<01:57, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 90/100 - Best Fitness: 0.2366, Avg Fitness: 0.0688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Generations: 100%|███████████████████| 100/100 [19:37<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 100/100 - Best Fitness: 0.2366, Avg Fitness: 0.0735\n",
      "Training complete. Best agent win rate: 7.00%\n",
      "Best agent saved to best_hangman_agent.pkl\n",
      "Best agent final evaluation - Win Rate: 12.00%, Avg Reward: -0.30\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ____________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ____________\n",
      "Guessed: e\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: t___________\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: ta____a_____\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: ta____a_____\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: ta____a___i_\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: ta____a_s_i_\n",
      "Guessed: a, e, i, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: ta____a_shi_\n",
      "Guessed: a, e, h, i, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: ta____a_shi_\n",
      "Guessed: a, e, h, i, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: ta____anshi_\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: ta____anshi_\n",
      "Guessed: a, c, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: tall__anshi_\n",
      "Guessed: a, c, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: tall__anshi_\n",
      "Guessed: a, c, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: tall__anship\n",
      "Guessed: a, c, d, e, h, i, l, n, o, p, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: m\n",
      "Word: tall_manship\n",
      "Guessed: a, c, d, e, h, i, l, m, n, o, p, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: u\n",
      "Word: tall_manship\n",
      "Guessed: a, c, d, e, h, i, l, m, n, o, p, r, s, t, u\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: tallymanship\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _____________________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ___e_________________\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: ___e_____t_t_t_______\n",
      "Guessed: e, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: ___e_____t_t_t___a___\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: ___e__o__t_t_t_o_a___\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: ___e__o__tit_tio_a___\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: h__e__o__tit_tio_a___\n",
      "Guessed: a, e, h, i, o, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: h__e__o_stit_tio_a___\n",
      "Guessed: a, e, h, i, o, s, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: h__e__onstit_tiona___\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: h__er_onstit_tiona___\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: h__erconstit_tiona___\n",
      "Guessed: a, c, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: h__erconstit_tionall_\n",
      "Guessed: a, c, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: h__erconstit_tionall_\n",
      "Guessed: a, c, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: h_perconstit_tionall_\n",
      "Guessed: a, c, d, e, h, i, l, n, o, p, r, s, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: m\n",
      "Word: h_perconstit_tionall_\n",
      "Guessed: a, c, d, e, h, i, l, m, n, o, p, r, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: u\n",
      "Word: h_perconstitutionall_\n",
      "Guessed: a, c, d, e, h, i, l, m, n, o, p, r, s, t, u\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: b\n",
      "Word: h_perconstitutionall_\n",
      "Guessed: a, b, c, d, e, h, i, l, m, n, o, p, r, s, t, u\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: g\n",
      "Word: h_perconstitutionall_\n",
      "Guessed: a, b, c, d, e, g, h, i, l, m, n, o, p, r, s, t, u\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: f\n",
      "Word: h_perconstitutionall_\n",
      "Guessed: a, b, c, d, e, f, g, h, i, l, m, n, o, p, r, s, t, u\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: y\n",
      "Word: hyperconstitutionally\n",
      "Guessed: a, b, c, d, e, f, g, h, i, l, m, n, o, p, r, s, t, u, y\n",
      "Wrong guesses: 5/6\n",
      "Agent won!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _______\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: _______\n",
      "Guessed: e\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: _t_____\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: _ta____\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _ta____\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: sta___s\n",
      "Guessed: a, e, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: sta___s\n",
      "Guessed: a, e, i, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: sta_h_s\n",
      "Guessed: a, e, h, i, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: sta_h_s\n",
      "Guessed: a, e, h, i, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: sta_h_s\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: sta_h_s\n",
      "Guessed: a, d, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: stachys\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ___e___e\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: ___e___e\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: ___e___e\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _o_e___e\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _o_e___e\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _o_es__e\n",
      "Guessed: a, e, i, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: _o_es__e\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: _o_es__e\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: _ores__e\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: _ores__e\n",
      "Guessed: a, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: moresque\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: _____e___\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: _____e___\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: _____e___\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _o___e_o_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _o___e_o_\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _o__se_o_\n",
      "Guessed: a, e, i, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: _o_nse_o_\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: _o_nse_o_\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: _o_nse_or\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: _o_nselor\n",
      "Guessed: a, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: _o_nselor\n",
      "Guessed: a, e, h, i, l, n, o, p, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: m\n",
      "Word: _o_nselor\n",
      "Guessed: a, e, h, i, l, m, n, o, p, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: counselor\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _______________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: _______________\n",
      "Guessed: e\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: ___________t___\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: ______a___at___\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _o_o__a___at_o_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _o_o__a_i_atio_\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _o_o__a_i_atio_\n",
      "Guessed: a, e, i, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: _o_o__a_i_atio_\n",
      "Guessed: a, e, h, i, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: nono__ani_ation\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: nonor_ani_ation\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: nonor_ani_ation\n",
      "Guessed: a, c, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: nonor_ani_ation\n",
      "Guessed: a, c, d, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: nonor_ani_ation\n",
      "Guessed: a, c, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: nonorganization\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: __________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: _e_e______\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: _e_et_t___\n",
      "Guessed: e, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: _e_etat___\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _e_etat_o_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _e_etatio_\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _e_etatio_\n",
      "Guessed: a, e, i, o, s, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: _e_etation\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: _e_etation\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: _e_etation\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: _e_etation\n",
      "Guessed: a, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: m\n",
      "Word: _e_etation\n",
      "Guessed: a, e, h, i, l, m, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: _e_etation\n",
      "Guessed: a, e, h, i, l, m, n, o, p, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: vegetation\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ___________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ___________\n",
      "Guessed: e\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: __t________\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: a_t__a_____\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: a_t__a_____\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: a_t__a___i_\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: a_th_a___i_\n",
      "Guessed: a, e, h, i, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: anth_a___in\n",
      "Guessed: a, e, h, i, n, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: anth_a___in\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: anthrar__in\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: m\n",
      "Word: anthrar__in\n",
      "Guessed: a, e, h, i, m, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: anthrar__in\n",
      "Guessed: a, c, e, h, i, m, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: anthrar__in\n",
      "Guessed: a, c, e, h, i, l, m, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: anthrarufin\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _____\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: _e___\n",
      "Guessed: e\n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: _e___\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: _e_a_\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _e_a_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _e_a_\n",
      "Guessed: a, e, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _e_a_\n",
      "Guessed: a, e, i, o, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: _e_a_\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: _e_a_\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: dedal\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _____\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: _____\n",
      "Guessed: e\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: _____\n",
      "Guessed: e, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: _a_a_\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: _a_a_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: _a_a_\n",
      "Guessed: a, e, o, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: _a_a_\n",
      "Guessed: a, e, i, o, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: _a_a_\n",
      "Guessed: a, e, i, n, o, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: rabah\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: ___________\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: ___________\n",
      "Guessed: e\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: _____t_____\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: _____t____a\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: ____ot____a\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: ____ot___ia\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: ____oth__ia\n",
      "Guessed: a, e, h, i, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: ____oth__ia\n",
      "Guessed: a, e, h, i, o, s, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: ____oth__ia\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: ____oth__ia\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: ___loth__ia\n",
      "Guessed: a, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: m\n",
      "Word: ___loth_mia\n",
      "Guessed: a, e, h, i, l, m, n, o, r, s, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: p\n",
      "Word: ___loth_mia\n",
      "Guessed: a, e, h, i, l, m, n, o, p, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: c\n",
      "Word: c_cloth_mia\n",
      "Guessed: a, c, e, h, i, l, m, n, o, p, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: c_cloth_mia\n",
      "Guessed: a, c, d, e, h, i, l, m, n, o, p, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: cyclothymia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to see the agent play a game? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new game of Hangman!\n",
      "Word: _______\n",
      "Guessed: \n",
      "Wrong guesses: 0/6\n",
      "\n",
      "Agent guesses: e\n",
      "Word: _______\n",
      "Guessed: e\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: t\n",
      "Word: ___tt__\n",
      "Guessed: e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: a\n",
      "Word: ___tta_\n",
      "Guessed: a, e, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: o\n",
      "Word: __otta_\n",
      "Guessed: a, e, o, t\n",
      "Wrong guesses: 1/6\n",
      "\n",
      "Agent guesses: i\n",
      "Word: __otta_\n",
      "Guessed: a, e, i, o, t\n",
      "Wrong guesses: 2/6\n",
      "\n",
      "Agent guesses: h\n",
      "Word: __otta_\n",
      "Guessed: a, e, h, i, o, t\n",
      "Wrong guesses: 3/6\n",
      "\n",
      "Agent guesses: n\n",
      "Word: __otta_\n",
      "Guessed: a, e, h, i, n, o, t\n",
      "Wrong guesses: 4/6\n",
      "\n",
      "Agent guesses: s\n",
      "Word: __otta_\n",
      "Guessed: a, e, h, i, n, o, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: r\n",
      "Word: _rotta_\n",
      "Guessed: a, e, h, i, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: l\n",
      "Word: _rottal\n",
      "Guessed: a, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 5/6\n",
      "\n",
      "Agent guesses: d\n",
      "Word: _rottal\n",
      "Guessed: a, d, e, h, i, l, n, o, r, s, t\n",
      "Wrong guesses: 6/6\n",
      "Agent lost! The word was: crottal\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 579\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;66;03m# Play interactive games\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     play_again \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mDo you want to see the agent play a game? (y/n): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m play_again \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hangman GFPO (Gradient-Free Policy Optimization) Agent\n",
    "\n",
    "This implementation uses a neural network policy that is trained using a gradient-free\n",
    "evolutionary strategy approach to optimize performance in the Hangman game.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MAX_WRONG_GUESSES = 6  # Standard Hangman rules\n",
    "POPULATION_SIZE = 50   # Number of agents in the population\n",
    "NUM_GENERATIONS = 100  # Number of generations to train\n",
    "ELITE_SIZE = 5         # Number of top agents to keep unchanged\n",
    "MUTATION_RATE = 0.1    # Probability of mutation\n",
    "MUTATION_SCALE = 0.2   # Scale of mutations\n",
    "TOURNAMENT_SIZE = 5    # Tournament selection size\n",
    "NUM_EVAL_GAMES = 100   # Number of games to evaluate each agent\n",
    "\n",
    "# Helper dictionaries for letter frequencies in English\n",
    "LETTER_FREQ = {\n",
    "    'a': 0.082, 'b': 0.015, 'c': 0.028, 'd': 0.043, 'e': 0.127, 'f': 0.022,\n",
    "    'g': 0.020, 'h': 0.061, 'i': 0.070, 'j': 0.002, 'k': 0.008, 'l': 0.040,\n",
    "    'm': 0.024, 'n': 0.067, 'o': 0.075, 'p': 0.019, 'q': 0.001, 'r': 0.060,\n",
    "    's': 0.063, 't': 0.091, 'u': 0.028, 'v': 0.010, 'w': 0.023, 'x': 0.001,\n",
    "    'y': 0.020, 'z': 0.001\n",
    "}\n",
    "\n",
    "# Dictionary providing positions where each letter commonly appears\n",
    "LETTER_POSITIONS = {\n",
    "    'a': [0, 1, 2], 'b': [0], 'c': [0], 'd': [0, 3], 'e': [1, 4], 'f': [0],\n",
    "    'g': [0], 'h': [0, 1], 'i': [1, 2], 'j': [0], 'k': [0, 3], 'l': [0, 3],\n",
    "    'm': [0], 'n': [1, 3], 'o': [1, 2], 'p': [0], 'q': [0], 'r': [0, 2],\n",
    "    's': [0, 4], 't': [0, 3], 'u': [1, 3], 'v': [0], 'w': [0], 'x': [0],\n",
    "    'y': [4], 'z': [0]\n",
    "}\n",
    "\n",
    "# Load a word list, or use a default one if loading fails\n",
    "def load_word_list(filename=\"words_250000_train.txt\"):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return [line.strip().lower() for line in f if line.strip() and all(c.isalpha() for c in line.strip())]\n",
    "    except FileNotFoundError:\n",
    "        # Fallback to a small default list if file not found\n",
    "        return [\"hangman\", \"python\", \"computer\", \"algorithm\", \"neural\", \n",
    "                \"network\", \"machine\", \"learning\", \"artificial\", \"intelligence\",\n",
    "                \"evolution\", \"strategy\", \"gradient\", \"optimization\", \"game\",\n",
    "                \"player\", \"alphabet\", \"language\", \"dictionary\", \"random\",\n",
    "                \"probability\", \"frequency\", \"statistics\", \"reinforcement\",\n",
    "                \"training\", \"simulation\", \"accuracy\", \"performance\", \"example\"]\n",
    "\n",
    "class HangmanEnvironment:\n",
    "    def __init__(self, word_list):\n",
    "        self.word_list = word_list\n",
    "        self.max_word_length = max(len(word) for word in word_list)\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.word = random.choice(self.word_list)\n",
    "        self.guessed_letters = set()\n",
    "        self.wrong_guesses = 0\n",
    "        self.state = self._get_state()\n",
    "        self.done = False\n",
    "        self.won = False\n",
    "        return self.state\n",
    "    \n",
    "    def _get_state(self):\n",
    "        \"\"\"\n",
    "        State representation:\n",
    "        - 26 features for guessed letters (1 if guessed, 0 otherwise)\n",
    "        - Current word representation (1 for revealed letter, 0 for hidden), padded to max length\n",
    "        - Wrong guesses remaining (normalized)\n",
    "        \"\"\"\n",
    "        # Guessed letters\n",
    "        alphabet_state = np.zeros(26)\n",
    "        for letter in self.guessed_letters:\n",
    "            if 'a' <= letter <= 'z':  # Ensure valid index\n",
    "                idx = ord(letter) - ord('a')\n",
    "                if 0 <= idx < 26:  # Double-check index bounds\n",
    "                    alphabet_state[idx] = 1\n",
    "        \n",
    "        # Current word representation - padded to a fixed length\n",
    "        word_state = np.zeros(self.max_word_length)\n",
    "        for i, letter in enumerate(self.word):\n",
    "            if letter in self.guessed_letters:\n",
    "                word_state[i] = 1\n",
    "        \n",
    "        # Wrong guesses remaining (normalized)\n",
    "        wrong_guesses_remaining = (MAX_WRONG_GUESSES - self.wrong_guesses) / MAX_WRONG_GUESSES\n",
    "        \n",
    "        # Return vectorized state with fixed dimensions\n",
    "        return np.concatenate([\n",
    "            alphabet_state,\n",
    "            word_state,\n",
    "            np.array([wrong_guesses_remaining])\n",
    "        ])\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take an action (guess a letter) and return next state, reward, done.\"\"\"\n",
    "        # Convert action index to letter\n",
    "        letter = chr(action + ord('a'))\n",
    "        \n",
    "        # Check if already guessed\n",
    "        if letter in self.guessed_letters:\n",
    "            reward = -0.5  # Penalty for guessing the same letter\n",
    "            return self.state, reward, self.done, {\"won\": self.won}\n",
    "        \n",
    "        # Add letter to guessed set\n",
    "        self.guessed_letters.add(letter)\n",
    "        \n",
    "        # Check if letter is in the word\n",
    "        if letter in self.word:\n",
    "            # Calculate how many instances of the letter were found\n",
    "            occurrences = self.word.count(letter)\n",
    "            reward = occurrences * 1.0  # Reward based on occurrences\n",
    "        else:\n",
    "            # Incorrect guess\n",
    "            self.wrong_guesses += 1\n",
    "            reward = -1.0\n",
    "        \n",
    "        # Update state\n",
    "        self.state = self._get_state()\n",
    "        \n",
    "        # Check if game is over\n",
    "        all_letters_guessed = all(letter in self.guessed_letters for letter in self.word)\n",
    "        if all_letters_guessed:\n",
    "            self.done = True\n",
    "            self.won = True\n",
    "            reward += 5.0  # Bonus for winning\n",
    "        elif self.wrong_guesses >= MAX_WRONG_GUESSES:\n",
    "            self.done = True\n",
    "            self.won = False\n",
    "            reward -= 2.0  # Additional penalty for losing\n",
    "        \n",
    "        return self.state, reward, self.done, {\"won\": self.won}\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Render the current state of the game.\"\"\"\n",
    "        displayed_word = ''.join([letter if letter in self.guessed_letters else '_' for letter in self.word])\n",
    "        guessed = ', '.join(sorted(self.guessed_letters))\n",
    "        print(f\"Word: {displayed_word}\")\n",
    "        print(f\"Guessed: {guessed}\")\n",
    "        print(f\"Wrong guesses: {self.wrong_guesses}/{MAX_WRONG_GUESSES}\")\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.weights = []\n",
    "        \n",
    "        # Input to first hidden layer\n",
    "        self.weights.append(np.random.randn(input_dim, hidden_dims[0]) * 0.1)\n",
    "        self.biases = [np.random.randn(hidden_dims[0]) * 0.1]\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            self.weights.append(np.random.randn(hidden_dims[i], hidden_dims[i+1]) * 0.1)\n",
    "            self.biases.append(np.random.randn(hidden_dims[i+1]) * 0.1)\n",
    "        \n",
    "        # Output layer\n",
    "        self.weights.append(np.random.randn(hidden_dims[-1], output_dim) * 0.1)\n",
    "        self.biases.append(np.random.randn(output_dim) * 0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        activations = [x]\n",
    "        \n",
    "        # Hidden layers with ReLU activation\n",
    "        for i in range(len(self.hidden_dims)):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            a = np.maximum(0, z)  # ReLU activation\n",
    "            activations.append(a)\n",
    "        \n",
    "        # Output layer (linear activation for raw logits)\n",
    "        z_out = np.dot(activations[-1], self.weights[-1]) + self.biases[-1]\n",
    "        \n",
    "        return z_out\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        \"\"\"Get all parameters (weights and biases) as a flat array.\"\"\"\n",
    "        params = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            params.append(w.flatten())\n",
    "            params.append(b.flatten())\n",
    "        return np.concatenate(params)\n",
    "    \n",
    "    def set_parameters(self, params):\n",
    "        \"\"\"Set all parameters (weights and biases) from a flat array.\"\"\"\n",
    "        idx = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            w_shape = self.weights[i].shape\n",
    "            b_shape = self.biases[i].shape\n",
    "            \n",
    "            # Extract and reshape weights\n",
    "            w_size = np.prod(w_shape)\n",
    "            self.weights[i] = params[idx:idx+w_size].reshape(w_shape)\n",
    "            idx += w_size\n",
    "            \n",
    "            # Extract and reshape biases\n",
    "            b_size = np.prod(b_shape)\n",
    "            self.biases[i] = params[idx:idx+b_size].reshape(b_shape)\n",
    "            idx += b_size\n",
    "\n",
    "class HangmanAgent:\n",
    "    def __init__(self, input_dim, word_length_estimate=10):\n",
    "        # Store the input dimension\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Neural network for policy\n",
    "        self.policy_network = NeuralNetwork(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dims=[64, 32],  # Hidden layer dimensions\n",
    "            output_dim=26  # One output per letter\n",
    "        )\n",
    "        \n",
    "        # Parameters for letter frequency heuristic\n",
    "        self.letter_freq_weight = 0.3\n",
    "        self.pattern_weight = 0.4\n",
    "        self.network_weight = 0.3\n",
    "        \n",
    "        # For pattern matching\n",
    "        self.max_word_length = word_length_estimate\n",
    "        \n",
    "    def select_action(self, state, word_length, guessed_letters):\n",
    "        \"\"\"Select an action based on the current state.\"\"\"\n",
    "        # Ensure state has the correct shape for network\n",
    "        if len(state) != self.policy_network.input_dim:\n",
    "            # Pad or truncate state to match expected input dimension\n",
    "            if len(state) < self.policy_network.input_dim:\n",
    "                # Pad with zeros\n",
    "                padded_state = np.zeros(self.policy_network.input_dim)\n",
    "                padded_state[:len(state)] = state\n",
    "                state = padded_state\n",
    "            else:\n",
    "                # Truncate\n",
    "                state = state[:self.policy_network.input_dim]\n",
    "        \n",
    "        # Get neural network logits\n",
    "        network_logits = self.policy_network.forward(state)\n",
    "        \n",
    "        # Create letter frequency scores\n",
    "        letter_scores = np.zeros(26)\n",
    "        for i, letter in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            if chr(i + ord('a')) not in guessed_letters:\n",
    "                letter_scores[i] = LETTER_FREQ.get(letter, 0.01)\n",
    "        \n",
    "        # Create pattern-based scores\n",
    "        pattern_scores = np.zeros(26)\n",
    "        # We don't have direct access to the word here, so use a simplified approach\n",
    "        # Simply boost common letters in general\n",
    "        for i, letter in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            if chr(i + ord('a')) not in guessed_letters:\n",
    "                pattern_scores[i] = LETTER_FREQ.get(letter, 0.01) * 2  # Boost common letters\n",
    "        \n",
    "        # Combine all scores (weighted sum)\n",
    "        combined_scores = (\n",
    "            self.network_weight * network_logits +\n",
    "            self.letter_freq_weight * letter_scores +\n",
    "            self.pattern_weight * pattern_scores\n",
    "        )\n",
    "        \n",
    "        # Mask out already guessed letters\n",
    "        for i, letter in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            if chr(i + ord('a')) in guessed_letters:\n",
    "                combined_scores[i] = float('-inf')\n",
    "        \n",
    "        # Select the best action\n",
    "        return np.argmax(combined_scores)\n",
    "    \n",
    "    def train(self, environment, episodes=100):\n",
    "        \"\"\"Train the agent (used for supervised pre-training if needed)\"\"\"\n",
    "        # Placeholder for potential supervised pre-training\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, environment, num_episodes=100):\n",
    "        \"\"\"Evaluate the agent's performance.\"\"\"\n",
    "        wins = 0\n",
    "        total_reward = 0\n",
    "        \n",
    "        for _ in range(num_episodes):\n",
    "            state = environment.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            \n",
    "            while not done:\n",
    "                # Get word length from the state\n",
    "                word_length = len(environment.word)\n",
    "                \n",
    "                # Select action\n",
    "                action = self.select_action(state, word_length, environment.guessed_letters)\n",
    "                \n",
    "                # Take action\n",
    "                next_state, reward, done, info = environment.step(action)\n",
    "                \n",
    "                # Update stats\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "                \n",
    "                if done and info[\"won\"]:\n",
    "                    wins += 1\n",
    "            \n",
    "            total_reward += episode_reward\n",
    "        \n",
    "        return wins / num_episodes, total_reward / num_episodes\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        \"\"\"Get all trainable parameters.\"\"\"\n",
    "        policy_params = self.policy_network.get_parameters()\n",
    "        heuristic_params = np.array([\n",
    "            self.letter_freq_weight,\n",
    "            self.pattern_weight,\n",
    "            self.network_weight\n",
    "        ])\n",
    "        return np.concatenate([policy_params, heuristic_params])\n",
    "    \n",
    "    def set_parameters(self, params):\n",
    "        \"\"\"Set all trainable parameters.\"\"\"\n",
    "        # Extract neural network parameters\n",
    "        policy_params_count = len(self.policy_network.get_parameters())\n",
    "        policy_params = params[:policy_params_count]\n",
    "        \n",
    "        # Extract heuristic weights\n",
    "        heuristic_params = params[policy_params_count:]\n",
    "        \n",
    "        # Normalize heuristic weights to sum to 1\n",
    "        heuristic_sum = np.sum(heuristic_params)\n",
    "        if heuristic_sum > 0:\n",
    "            heuristic_params = heuristic_params / heuristic_sum\n",
    "        else:\n",
    "            heuristic_params = np.array([0.3, 0.4, 0.3])  # Default values\n",
    "        \n",
    "        # Set parameters\n",
    "        self.policy_network.set_parameters(policy_params)\n",
    "        self.letter_freq_weight = heuristic_params[0]\n",
    "        self.pattern_weight = heuristic_params[1]\n",
    "        self.network_weight = heuristic_params[2]\n",
    "\n",
    "class GFPO:\n",
    "    def __init__(self, env, agent_class, input_dim, word_length_estimate=10):\n",
    "        self.env = env\n",
    "        self.agent_class = agent_class\n",
    "        self.input_dim = input_dim\n",
    "        self.word_length_estimate = word_length_estimate\n",
    "        self.population = []\n",
    "        self.best_agent = None\n",
    "        self.best_fitness = -float('inf')\n",
    "        self.fitness_history = []\n",
    "        \n",
    "        # Initialize population\n",
    "        self._initialize_population()\n",
    "    \n",
    "    def _initialize_population(self):\n",
    "        \"\"\"Initialize the population of agents.\"\"\"\n",
    "        self.population = []\n",
    "        for _ in range(POPULATION_SIZE):\n",
    "            agent = self.agent_class(self.input_dim, self.word_length_estimate)\n",
    "            self.population.append(agent)\n",
    "    \n",
    "    def _evaluate_fitness(self, agent):\n",
    "        \"\"\"Evaluate the fitness of an agent.\"\"\"\n",
    "        win_rate, avg_reward = agent.evaluate(self.env, NUM_EVAL_GAMES)\n",
    "        # Fitness is a combination of win rate and average reward\n",
    "        fitness = 0.8 * win_rate + 0.2 * (avg_reward / 10.0)  # Normalize reward component\n",
    "        return fitness, win_rate\n",
    "    \n",
    "    def _tournament_selection(self):\n",
    "        \"\"\"Select an agent using tournament selection.\"\"\"\n",
    "        tournament = random.sample(list(enumerate(self.population)), TOURNAMENT_SIZE)\n",
    "        fitnesses = []\n",
    "        \n",
    "        for idx, agent in tournament:\n",
    "            fitness, _ = self._evaluate_fitness(agent)\n",
    "            fitnesses.append((idx, fitness))\n",
    "        \n",
    "        # Select the best agent from the tournament\n",
    "        selected_idx, _ = max(fitnesses, key=lambda x: x[1])\n",
    "        return selected_idx\n",
    "    \n",
    "    def _crossover(self, parent1, parent2):\n",
    "        \"\"\"Create a new agent by crossing over two parents.\"\"\"\n",
    "        child = self.agent_class(self.input_dim, self.word_length_estimate)\n",
    "        \n",
    "        # Get parameters from parents\n",
    "        params1 = parent1.get_parameters()\n",
    "        params2 = parent2.get_parameters()\n",
    "        \n",
    "        # Uniform crossover\n",
    "        mask = np.random.rand(len(params1)) < 0.5\n",
    "        child_params = np.where(mask, params1, params2)\n",
    "        \n",
    "        # Set parameters in child\n",
    "        child.set_parameters(child_params)\n",
    "        return child\n",
    "    \n",
    "    def _mutate(self, agent):\n",
    "        \"\"\"Mutate an agent's parameters.\"\"\"\n",
    "        params = agent.get_parameters()\n",
    "        \n",
    "        # Apply random mutations with probability MUTATION_RATE\n",
    "        mask = np.random.rand(len(params)) < MUTATION_RATE\n",
    "        mutations = np.random.randn(len(params)) * MUTATION_SCALE\n",
    "        \n",
    "        # Apply mutations\n",
    "        params = params + mask * mutations\n",
    "        \n",
    "        # Set mutated parameters\n",
    "        agent.set_parameters(params)\n",
    "    \n",
    "    def train(self, generations=NUM_GENERATIONS):\n",
    "        \"\"\"Train the population for a specified number of generations.\"\"\"\n",
    "        for generation in tqdm(range(generations), desc=\"Training Generations\"):\n",
    "            # Evaluate all agents\n",
    "            fitness_results = []\n",
    "            for i, agent in enumerate(self.population):\n",
    "                fitness, win_rate = self._evaluate_fitness(agent)\n",
    "                fitness_results.append((i, fitness, win_rate))\n",
    "            \n",
    "            # Sort by fitness\n",
    "            fitness_results.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Update best agent if we found a better one\n",
    "            if fitness_results[0][1] > self.best_fitness:\n",
    "                self.best_fitness = fitness_results[0][1]\n",
    "                self.best_agent = self.population[fitness_results[0][0]]\n",
    "                best_win_rate = fitness_results[0][2]\n",
    "                print(f\"Generation {generation}: New best agent with fitness {self.best_fitness:.4f}, win rate {best_win_rate:.2%}\")\n",
    "            \n",
    "            # Record best fitness for this generation\n",
    "            self.fitness_history.append(fitness_results[0][1])\n",
    "            \n",
    "            # Create the next generation\n",
    "            next_generation = []\n",
    "            \n",
    "            # Elitism: keep the best agents unchanged\n",
    "            for i in range(ELITE_SIZE):\n",
    "                elite_idx = fitness_results[i][0]\n",
    "                next_generation.append(self.population[elite_idx])\n",
    "            \n",
    "            # Create the rest of the population through selection, crossover, and mutation\n",
    "            while len(next_generation) < POPULATION_SIZE:\n",
    "                # Tournament selection\n",
    "                parent1_idx = self._tournament_selection()\n",
    "                parent2_idx = self._tournament_selection()\n",
    "                \n",
    "                # Crossover\n",
    "                child = self._crossover(self.population[parent1_idx], self.population[parent2_idx])\n",
    "                \n",
    "                # Mutation\n",
    "                self._mutate(child)\n",
    "                \n",
    "                # Add to next generation\n",
    "                next_generation.append(child)\n",
    "            \n",
    "            # Update population\n",
    "            self.population = next_generation\n",
    "            \n",
    "            # Print progress every 10 generations\n",
    "            if (generation + 1) % 10 == 0 or generation == 0:\n",
    "                avg_fitness = np.mean([res[1] for res in fitness_results])\n",
    "                print(f\"Generation {generation + 1}/{generations} - Best Fitness: {self.best_fitness:.4f}, Avg Fitness: {avg_fitness:.4f}\")\n",
    "        \n",
    "        # Final evaluation of best agent\n",
    "        self.best_fitness, win_rate = self._evaluate_fitness(self.best_agent)\n",
    "        print(f\"Training complete. Best agent win rate: {win_rate:.2%}\")\n",
    "        \n",
    "        return self.best_agent\n",
    "    \n",
    "    def plot_training_progress(self):\n",
    "        \"\"\"Plot the training progress.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.fitness_history)\n",
    "        plt.title('Training Progress')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Best Fitness')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('training_progress.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def save_best_agent(self, filename='best_hangman_agent.pkl'):\n",
    "        \"\"\"Save the best agent to a file.\"\"\"\n",
    "        if self.best_agent:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(self.best_agent, f)\n",
    "            print(f\"Best agent saved to {filename}\")\n",
    "    \n",
    "    def load_best_agent(self, filename='best_hangman_agent.pkl'):\n",
    "        \"\"\"Load the best agent from a file.\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.best_agent = pickle.load(f)\n",
    "            print(f\"Agent loaded from {filename}\")\n",
    "            return self.best_agent\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {filename} not found. No agent loaded.\")\n",
    "            return None\n",
    "\n",
    "def play_hangman_interactive(agent, word_list=None):\n",
    "    \"\"\"Play hangman interactively with the trained agent.\"\"\"\n",
    "    if word_list is None:\n",
    "        word_list = load_word_list()\n",
    "    \n",
    "    env = HangmanEnvironment(word_list)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    print(\"Starting a new game of Hangman!\")\n",
    "    env.render()\n",
    "    \n",
    "    while not done:\n",
    "        # Get word length from the state\n",
    "        word_length = len(env.word)\n",
    "        \n",
    "        # Agent selects an action\n",
    "        action = agent.select_action(state, word_length, env.guessed_letters)\n",
    "        letter = chr(action + ord('a'))\n",
    "        \n",
    "        print(f\"\\nAgent guesses: {letter}\")\n",
    "        \n",
    "        # Take action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Update state\n",
    "        state = next_state\n",
    "        \n",
    "        # Render the environment\n",
    "        env.render()\n",
    "        \n",
    "        # Check if game is over\n",
    "        if done:\n",
    "            if info[\"won\"]:\n",
    "                print(\"Agent won!\")\n",
    "            else:\n",
    "                print(f\"Agent lost! The word was: {env.word}\")\n",
    "    \n",
    "    return info[\"won\"]\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load word list\n",
    "    word_list = load_word_list()\n",
    "    print(f\"Loaded {len(word_list)} words with max length {max(len(w) for w in word_list)}\")\n",
    "    \n",
    "    # Create environment\n",
    "    env = HangmanEnvironment(word_list)\n",
    "    \n",
    "    # Get state dimensions\n",
    "    state = env.reset()\n",
    "    input_dim = len(state)\n",
    "    print(f\"State dimension: {input_dim}\")\n",
    "    \n",
    "    # Create and train the GFPO system\n",
    "    max_word_length = max(len(w) for w in word_list)\n",
    "    gfpo = GFPO(env, HangmanAgent, input_dim, word_length_estimate=max_word_length)\n",
    "    \n",
    "    # Check if a trained agent exists\n",
    "    best_agent = gfpo.load_best_agent()\n",
    "    \n",
    "    if best_agent is None:\n",
    "        print(\"Training a new agent...\")\n",
    "        best_agent = gfpo.train(NUM_GENERATIONS)\n",
    "        gfpo.plot_training_progress()\n",
    "        gfpo.save_best_agent()\n",
    "    \n",
    "    # Evaluate best agent\n",
    "    win_rate, avg_reward = best_agent.evaluate(env, 200)\n",
    "    print(f\"Best agent final evaluation - Win Rate: {win_rate:.2%}, Avg Reward: {avg_reward:.2f}\")\n",
    "    \n",
    "    # Play interactive games\n",
    "    while True:\n",
    "        play_again = input(\"\\nDo you want to see the agent play a game? (y/n): \").lower()\n",
    "        if play_again != 'y':\n",
    "            break\n",
    "        \n",
    "        play_hangman_interactive(best_agent, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a97ad29-3632-4cd1-9403-45f879f6dd42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a new agent...\n",
      "Episode 0, Epsilon: 0.285\n",
      "Episode 1000, Epsilon: 0.271\n",
      "Episode 2000, Epsilon: 0.257\n",
      "Episode 3000, Epsilon: 0.244\n",
      "Episode 4000, Epsilon: 0.232\n",
      "Episode 5000, Epsilon: 0.221\n",
      "Episode 6000, Epsilon: 0.210\n",
      "Episode 7000, Epsilon: 0.199\n",
      "Episode 8000, Epsilon: 0.189\n",
      "Episode 9000, Epsilon: 0.180\n",
      "Episode 10000, Epsilon: 0.171\n",
      "Episode 11000, Epsilon: 0.162\n",
      "Episode 12000, Epsilon: 0.154\n",
      "Episode 13000, Epsilon: 0.146\n",
      "Episode 14000, Epsilon: 0.139\n",
      "Episode 15000, Epsilon: 0.132\n",
      "Episode 16000, Epsilon: 0.125\n",
      "Episode 17000, Epsilon: 0.119\n",
      "Episode 18000, Epsilon: 0.113\n",
      "Episode 19000, Epsilon: 0.108\n",
      "Episode 20000, Epsilon: 0.102\n",
      "Episode 21000, Epsilon: 0.097\n",
      "Episode 22000, Epsilon: 0.092\n",
      "Episode 23000, Epsilon: 0.088\n",
      "Episode 24000, Epsilon: 0.083\n",
      "Episode 25000, Epsilon: 0.079\n",
      "Episode 26000, Epsilon: 0.075\n",
      "Episode 27000, Epsilon: 0.071\n",
      "Episode 28000, Epsilon: 0.068\n",
      "Episode 29000, Epsilon: 0.064\n",
      "Episode 30000, Epsilon: 0.061\n",
      "Episode 31000, Epsilon: 0.058\n",
      "Episode 32000, Epsilon: 0.055\n",
      "Episode 33000, Epsilon: 0.052\n",
      "Episode 34000, Epsilon: 0.050\n",
      "Episode 35000, Epsilon: 0.047\n",
      "Episode 36000, Epsilon: 0.045\n",
      "Episode 37000, Epsilon: 0.043\n",
      "Episode 38000, Epsilon: 0.041\n",
      "Episode 39000, Epsilon: 0.039\n",
      "Episode 40000, Epsilon: 0.037\n",
      "Episode 41000, Epsilon: 0.035\n",
      "Episode 42000, Epsilon: 0.033\n",
      "Episode 43000, Epsilon: 0.031\n",
      "Episode 44000, Epsilon: 0.030\n",
      "Episode 45000, Epsilon: 0.028\n",
      "Episode 46000, Epsilon: 0.027\n",
      "Episode 47000, Epsilon: 0.026\n",
      "Episode 48000, Epsilon: 0.024\n",
      "Episode 49000, Epsilon: 0.023\n",
      "Episode 50000, Epsilon: 0.022\n",
      "Episode 51000, Epsilon: 0.021\n",
      "Episode 52000, Epsilon: 0.020\n",
      "Episode 53000, Epsilon: 0.019\n",
      "Episode 54000, Epsilon: 0.018\n",
      "Episode 55000, Epsilon: 0.017\n",
      "Episode 56000, Epsilon: 0.016\n",
      "Episode 57000, Epsilon: 0.015\n",
      "Episode 58000, Epsilon: 0.015\n",
      "Episode 59000, Epsilon: 0.014\n",
      "Episode 60000, Epsilon: 0.013\n",
      "Episode 61000, Epsilon: 0.012\n",
      "Episode 62000, Epsilon: 0.012\n",
      "Episode 63000, Epsilon: 0.011\n",
      "Episode 64000, Epsilon: 0.011\n",
      "Episode 65000, Epsilon: 0.010\n",
      "Episode 66000, Epsilon: 0.010\n",
      "\n",
      "Episode 1\n",
      "Word: _ _ _ _ _ _ _ _ _ _\n",
      "Guessed letters: \n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: a\n",
      "Word: _ _ _ _ _ _ a _ _ _\n",
      "Guessed letters: a\n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: e\n",
      "Word: _ _ _ _ _ _ a _ _ _\n",
      "Guessed letters: a, e\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: c\n",
      "Word: _ _ _ _ _ _ a _ _ _\n",
      "Guessed letters: a, c, e\n",
      "Attempts left: 4\n",
      "\n",
      "Guessed: l\n",
      "Word: _ _ _ _ _ _ a _ _ _\n",
      "Guessed letters: a, c, e, l\n",
      "Attempts left: 3\n",
      "\n",
      "Guessed: n\n",
      "Word: _ _ _ _ _ _ a _ _ _\n",
      "Guessed letters: a, c, e, l, n\n",
      "Attempts left: 2\n",
      "\n",
      "Guessed: d\n",
      "Word: d _ _ _ _ _ a _ _ _\n",
      "Guessed letters: a, c, d, e, l, n\n",
      "Attempts left: 2\n",
      "\n",
      "Guessed: f\n",
      "Word: d _ _ _ _ _ a _ _ _\n",
      "Guessed letters: a, c, d, e, f, l, n\n",
      "Attempts left: 1\n",
      "\n",
      "Guessed: b\n",
      "Word: d _ _ _ _ _ a _ _ _\n",
      "Guessed letters: a, b, c, d, e, f, l, n\n",
      "Attempts left: 0\n",
      "You lost! The word was: doxography\n",
      "\n",
      "Episode 2\n",
      "Word: _ _ _ _ _ _ _ _\n",
      "Guessed letters: \n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: s\n",
      "Word: s _ _ _ _ _ _ _\n",
      "Guessed letters: s\n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: i\n",
      "Word: s _ _ i _ _ _ _\n",
      "Guessed letters: i, s\n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: e\n",
      "Word: s _ _ i _ _ e _\n",
      "Guessed letters: e, i, s\n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: r\n",
      "Word: s _ _ i _ _ e _\n",
      "Guessed letters: e, i, r, s\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: a\n",
      "Word: s _ _ i _ _ e _\n",
      "Guessed letters: a, e, i, r, s\n",
      "Attempts left: 4\n",
      "\n",
      "Guessed: b\n",
      "Word: s _ _ i b b e _\n",
      "Guessed letters: a, b, e, i, r, s\n",
      "Attempts left: 4\n",
      "\n",
      "Guessed: c\n",
      "Word: s _ _ i b b e _\n",
      "Guessed letters: a, b, c, e, i, r, s\n",
      "Attempts left: 3\n",
      "\n",
      "Guessed: d\n",
      "Word: s _ _ i b b e d\n",
      "Guessed letters: a, b, c, d, e, i, r, s\n",
      "Attempts left: 3\n",
      "\n",
      "Guessed: f\n",
      "Word: s _ _ i b b e d\n",
      "Guessed letters: a, b, c, d, e, f, i, r, s\n",
      "Attempts left: 2\n",
      "\n",
      "Guessed: g\n",
      "Word: s _ _ i b b e d\n",
      "Guessed letters: a, b, c, d, e, f, g, i, r, s\n",
      "Attempts left: 1\n",
      "\n",
      "Guessed: h\n",
      "Word: s _ _ i b b e d\n",
      "Guessed letters: a, b, c, d, e, f, g, h, i, r, s\n",
      "Attempts left: 0\n",
      "You lost! The word was: squibbed\n",
      "\n",
      "Episode 3\n",
      "Word: _ _ _ _ _\n",
      "Guessed letters: \n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: e\n",
      "Word: _ _ _ _ _\n",
      "Guessed letters: e\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: a\n",
      "Word: _ _ _ _ a\n",
      "Guessed letters: a, e\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: o\n",
      "Word: _ _ _ _ a\n",
      "Guessed letters: a, e, o\n",
      "Attempts left: 4\n",
      "\n",
      "Guessed: i\n",
      "Word: _ _ i _ a\n",
      "Guessed letters: a, e, i, o\n",
      "Attempts left: 4\n",
      "\n",
      "Guessed: b\n",
      "Word: _ _ i _ a\n",
      "Guessed letters: a, b, e, i, o\n",
      "Attempts left: 3\n",
      "\n",
      "Guessed: d\n",
      "Word: _ _ i _ a\n",
      "Guessed letters: a, b, d, e, i, o\n",
      "Attempts left: 2\n",
      "\n",
      "Guessed: c\n",
      "Word: _ _ i c a\n",
      "Guessed letters: a, b, c, d, e, i, o\n",
      "Attempts left: 2\n",
      "\n",
      "Guessed: f\n",
      "Word: _ _ i c a\n",
      "Guessed letters: a, b, c, d, e, f, i, o\n",
      "Attempts left: 1\n",
      "\n",
      "Guessed: g\n",
      "Word: _ _ i c a\n",
      "Guessed letters: a, b, c, d, e, f, g, i, o\n",
      "Attempts left: 0\n",
      "You lost! The word was: utica\n",
      "\n",
      "Episode 4\n",
      "Word: _ _ _ _ _\n",
      "Guessed letters: \n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: e\n",
      "Word: _ _ _ _ _\n",
      "Guessed letters: e\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: a\n",
      "Word: a _ _ _ _\n",
      "Guessed letters: a, e\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: v\n",
      "Word: a _ _ _ _\n",
      "Guessed letters: a, e, v\n",
      "Attempts left: 4\n",
      "\n",
      "Guessed: h\n",
      "Word: a _ _ _ _\n",
      "Guessed letters: a, e, h, v\n",
      "Attempts left: 3\n",
      "\n",
      "Guessed: b\n",
      "Word: a _ _ _ _\n",
      "Guessed letters: a, b, e, h, v\n",
      "Attempts left: 2\n",
      "\n",
      "Guessed: c\n",
      "Word: a _ _ _ _\n",
      "Guessed letters: a, b, c, e, h, v\n",
      "Attempts left: 1\n",
      "\n",
      "Guessed: d\n",
      "Word: a _ _ _ _\n",
      "Guessed letters: a, b, c, d, e, h, v\n",
      "Attempts left: 0\n",
      "You lost! The word was: angor\n",
      "\n",
      "Episode 5\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Guessed letters: \n",
      "Attempts left: 6\n",
      "\n",
      "Guessed: a\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Guessed letters: a\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: e\n",
      "Word: _ _ _ _ _ _ _ _ _ e _ _\n",
      "Guessed letters: a, e\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: i\n",
      "Word: _ _ _ _ _ i _ _ _ e _ _\n",
      "Guessed letters: a, e, i\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: o\n",
      "Word: _ o _ _ o i _ _ _ e _ _\n",
      "Guessed letters: a, e, i, o\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: c\n",
      "Word: c o _ _ o i _ _ _ e _ _\n",
      "Guessed letters: a, c, e, i, o\n",
      "Attempts left: 5\n",
      "\n",
      "Guessed: b\n",
      "Word: c o _ _ o i _ _ _ e _ _\n",
      "Guessed letters: a, b, c, e, i, o\n",
      "Attempts left: 4\n",
      "\n",
      "Guessed: f\n",
      "Word: c o _ _ o i _ _ _ e _ _\n",
      "Guessed letters: a, b, c, e, f, i, o\n",
      "Attempts left: 3\n",
      "\n",
      "Guessed: d\n",
      "Word: c o _ _ o i _ _ _ e _ _\n",
      "Guessed letters: a, b, c, d, e, f, i, o\n",
      "Attempts left: 2\n",
      "\n",
      "Guessed: h\n",
      "Word: c o _ _ o i _ _ _ e _ _\n",
      "Guessed letters: a, b, c, d, e, f, h, i, o\n",
      "Attempts left: 1\n",
      "\n",
      "Guessed: g\n",
      "Word: c o _ _ o i _ _ _ e _ _\n",
      "Guessed letters: a, b, c, d, e, f, g, h, i, o\n",
      "Attempts left: 0\n",
      "You lost! The word was: conjointness\n",
      "Win rate: 0.00 (0/100)\n",
      "Welcome to Hangman! The AI will guess letters.\n",
      "Word: _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: a\n",
      "Word: _ _ _ a _ _ _ _ _ a _ _ _ _\n",
      "Guessed letters: a\n",
      "Attempts left: 6\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: c\n",
      "Word: _ _ c a _ _ _ _ _ a _ _ _ _\n",
      "Guessed letters: a, c\n",
      "Attempts left: 6\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: d\n",
      "Word: d _ c a _ _ _ _ _ a _ _ _ _\n",
      "Guessed letters: a, c, d\n",
      "Attempts left: 6\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: e\n",
      "Word: d e c a _ _ _ _ _ a _ _ _ _\n",
      "Guessed letters: a, c, d, e\n",
      "Attempts left: 6\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: g\n",
      "Word: d e c a _ _ _ _ _ a _ _ _ _\n",
      "Guessed letters: a, c, d, e, g\n",
      "Attempts left: 5\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: b\n",
      "Word: d e c a _ _ _ _ _ a _ _ _ _\n",
      "Guessed letters: a, b, c, d, e, g\n",
      "Attempts left: 4\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: h\n",
      "Word: d e c a _ _ _ _ _ a _ _ _ _\n",
      "Guessed letters: a, b, c, d, e, g, h\n",
      "Attempts left: 3\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: f\n",
      "Word: d e c a _ _ _ _ _ a _ _ _ _\n",
      "Guessed letters: a, b, c, d, e, f, g, h\n",
      "Attempts left: 2\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: i\n",
      "Word: d e c a _ _ _ i _ a _ i _ _\n",
      "Guessed letters: a, b, c, d, e, f, g, h, i\n",
      "Attempts left: 2\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: l\n",
      "Word: d e c a _ _ _ i _ a _ i _ _\n",
      "Guessed letters: a, b, c, d, e, f, g, h, i, l\n",
      "Attempts left: 1\n",
      "\n",
      "Agent is thinking...\n",
      "Agent guesses: j\n",
      "Word: d e c a _ _ _ i _ a _ i _ _\n",
      "Guessed letters: a, b, c, d, e, f, g, h, i, j, l\n",
      "Attempts left: 0\n",
      "You lost! The word was: decanonization\n",
      "The agent lost!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import pickle\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "class HangmanEnvironment:\n",
    "    def __init__(self, word_list=None):\n",
    "        if word_list is None:\n",
    "            # Default list of words\n",
    "            self.word_list = ['python', 'machine', 'learning', 'game', 'artificial', 'intelligence', 'algorithm']\n",
    "        else:\n",
    "            self.word_list = word_list\n",
    "        \n",
    "        self.max_attempts = 6\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the game environment.\"\"\"\n",
    "        self.word = random.choice(self.word_list).lower()\n",
    "        self.word_len = len(self.word)\n",
    "        self.revealed = ['_'] * self.word_len\n",
    "        self.guessed_letters = set()\n",
    "        self.attempts_left = self.max_attempts\n",
    "        self.game_over = False\n",
    "        \n",
    "        return self._get_state()\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Take an action (guess a letter) and return the new state, reward, and done flag.\n",
    "        \n",
    "        Args:\n",
    "            action: A letter from a-z\n",
    "            \n",
    "        Returns:\n",
    "            state: Current game state\n",
    "            reward: Reward for the action\n",
    "            done: Whether the game is over\n",
    "            info: Additional information\n",
    "        \"\"\"\n",
    "        if self.game_over:\n",
    "            return self._get_state(), 0, True, {}\n",
    "        \n",
    "        letter = action.lower()\n",
    "        \n",
    "        # Letter already guessed\n",
    "        if letter in self.guessed_letters:\n",
    "            return self._get_state(), -3, self.game_over, {}\n",
    "        \n",
    "        self.guessed_letters.add(letter)\n",
    "        \n",
    "        # Check if letter is in the word\n",
    "        if letter in self.word:\n",
    "            # Update revealed word\n",
    "            for i, char in enumerate(self.word):\n",
    "                if char == letter:\n",
    "                    self.revealed[i] = letter\n",
    "            \n",
    "            # Check if the word is fully revealed\n",
    "            if '_' not in self.revealed:\n",
    "                self.game_over = True\n",
    "                return self._get_state(), 10, True, {'won': True}\n",
    "            \n",
    "            # Reward for correct guess depends on frequency of the letter\n",
    "            letter_count = self.word.count(letter)\n",
    "            return self._get_state(), letter_count * 2, False, {}\n",
    "        else:\n",
    "            # Incorrect guess\n",
    "            self.attempts_left -= 1\n",
    "            \n",
    "            if self.attempts_left == 0:\n",
    "                self.game_over = True\n",
    "                return self._get_state(), -5, True, {'won': False}\n",
    "            \n",
    "            return self._get_state(), -1, False, {}\n",
    "    \n",
    "    def _get_state(self):\n",
    "        \"\"\"Return the current state representation.\"\"\"\n",
    "        return (\n",
    "            ''.join(self.revealed),\n",
    "            ''.join(sorted(self.guessed_letters)),\n",
    "            self.attempts_left\n",
    "        )\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Display the current game state.\"\"\"\n",
    "        print(f\"Word: {' '.join(self.revealed)}\")\n",
    "        print(f\"Guessed letters: {', '.join(sorted(self.guessed_letters))}\")\n",
    "        print(f\"Attempts left: {self.attempts_left}\")\n",
    "        if self.game_over:\n",
    "            if '_' not in self.revealed:\n",
    "                print(\"You won!\")\n",
    "            else:\n",
    "                print(f\"You lost! The word was: {self.word}\")\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.q_table = defaultdict(lambda: np.zeros(26))  # Maps state to Q values for each action\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.letters = string.ascii_lowercase\n",
    "        \n",
    "    def get_action(self, state, guessed_letters):\n",
    "        \"\"\"\n",
    "        Choose an action based on epsilon-greedy policy.\n",
    "        \n",
    "        Args:\n",
    "            state: Current state\n",
    "            guessed_letters: Set of already guessed letters\n",
    "            \n",
    "        Returns:\n",
    "            Chosen letter\n",
    "        \"\"\"\n",
    "        available_letters = [l for l in self.letters if l not in guessed_letters]\n",
    "        \n",
    "        if not available_letters:\n",
    "            return None\n",
    "        \n",
    "        if random.random() < self.epsilon:\n",
    "            # Exploration: choose randomly\n",
    "            return random.choice(available_letters)\n",
    "        else:\n",
    "            # Exploitation: choose best action\n",
    "            q_values = self.q_table[state]\n",
    "            \n",
    "            # Filter out already guessed letters\n",
    "            valid_q = [(l, q_values[ord(l) - ord('a')]) for l in available_letters]\n",
    "            \n",
    "            # Choose the letter with the highest Q-value\n",
    "            return max(valid_q, key=lambda x: x[1])[0]\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Update Q-values based on the Q-learning update rule.\n",
    "        \n",
    "        Args:\n",
    "            state: Current state\n",
    "            action: Taken action (letter)\n",
    "            reward: Received reward\n",
    "            next_state: Next state\n",
    "        \"\"\"\n",
    "        # Convert letter to index\n",
    "        action_idx = ord(action) - ord('a')\n",
    "        \n",
    "        # Current Q-value\n",
    "        old_value = self.q_table[state][action_idx]\n",
    "        \n",
    "        # Maximum Q-value for next state\n",
    "        next_max = np.max(self.q_table[next_state])\n",
    "        \n",
    "        # Update Q-value\n",
    "        new_value = old_value + self.alpha * (reward + self.gamma * next_max - old_value)\n",
    "        self.q_table[state][action_idx] = new_value\n",
    "    \n",
    "    def save(self, filename=\"hangman_agent.pkl\"):\n",
    "        \"\"\"Save the Q-table to a file.\"\"\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(dict(self.q_table), f)\n",
    "    \n",
    "    def load(self, filename=\"hangman.pkl\"):\n",
    "        \"\"\"Load the Q-table from a file.\"\"\"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.q_table = defaultdict(lambda: np.zeros(26), pickle.load(f))\n",
    "\n",
    "\n",
    "def train_agent(agent, env, num_episodes=10000):\n",
    "    \"\"\"Train the agent for the given number of episodes.\"\"\"\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # Get guessed letters from state\n",
    "            guessed_letters = state[1]\n",
    "            \n",
    "            # Choose an action\n",
    "            action = agent.get_action(state, guessed_letters)\n",
    "            \n",
    "            # Take the action\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # Update Q-values\n",
    "            agent.update(state, action, reward, next_state)\n",
    "            \n",
    "            state = next_state\n",
    "        \n",
    "        # Decay epsilon over time for more exploitation later\n",
    "        if episode % 1000 == 0 and agent.epsilon > 0.01:\n",
    "            agent.epsilon *= 0.95\n",
    "            print(f\"Episode {episode}, Epsilon: {agent.epsilon:.3f}\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "\n",
    "def evaluate_agent(agent, env, num_episodes=100, render=False):\n",
    "    \"\"\"Evaluate the agent's performance.\"\"\"\n",
    "    wins = 0\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        if render and episode < 5:  # Only render a few episodes\n",
    "            print(f\"\\nEpisode {episode + 1}\")\n",
    "            env.render()\n",
    "        \n",
    "        while not done:\n",
    "            # Choose the best action (no exploration)\n",
    "            guessed_letters = state[1]\n",
    "            old_epsilon = agent.epsilon\n",
    "            agent.epsilon = 0  # No exploration during evaluation\n",
    "            action = agent.get_action(state, guessed_letters)\n",
    "            agent.epsilon = old_epsilon\n",
    "            \n",
    "            # Take the action\n",
    "            state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if render and episode < 5:\n",
    "                print(f\"\\nGuessed: {action}\")\n",
    "                env.render()\n",
    "        \n",
    "        if '_' not in state[0]:  # Word fully revealed\n",
    "            wins += 1\n",
    "    \n",
    "    win_rate = wins / num_episodes\n",
    "    print(f\"Win rate: {win_rate:.2f} ({wins}/{num_episodes})\")\n",
    "    \n",
    "    return win_rate\n",
    "\n",
    "\n",
    "def play_against_agent(agent, word_list=None):\n",
    "    \"\"\"Let a human play against the trained agent.\"\"\"\n",
    "    env = HangmanEnvironment(word_list)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    print(\"Welcome to Hangman! The AI will guess letters.\")\n",
    "    print(\"Word:\", ' '.join(env.revealed))\n",
    "    \n",
    "    while not done:\n",
    "        # Agent's turn\n",
    "        guessed_letters = state[1]\n",
    "        print(\"\\nAgent is thinking...\")\n",
    "        \n",
    "        # Choose the best action\n",
    "        agent.epsilon = 0  # No exploration\n",
    "        action = agent.get_action(state, guessed_letters)\n",
    "        \n",
    "        print(f\"Agent guesses: {action}\")\n",
    "        \n",
    "        # Take the action\n",
    "        state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Display the state\n",
    "        env.render()\n",
    "    \n",
    "    if '_' not in state[0]:\n",
    "        print(\"The agent won!\")\n",
    "    else:\n",
    "        print(\"The agent lost!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create environment with a larger word list\n",
    "    sample_words = ['python', 'machine', 'learning', 'game', 'artificial', \n",
    "                   'intelligence', 'algorithm', 'neural', 'network', 'data',\n",
    "                   'science', 'computer', 'vision', 'natural', 'language',\n",
    "                   'reinforcement', 'supervised', 'unsupervised', 'model',\n",
    "                   'train', 'test', 'validation', 'accuracy', 'precision']\n",
    "\n",
    "    with open(\"words_250000_train.txt\", 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        words = [line.strip().lower() for line in f if line.strip() and all(c in string.ascii_lowercase for c in line.strip().lower())]\n",
    "    env = HangmanEnvironment(words)\n",
    "    \n",
    "    # Create and train the agent\n",
    "    agent = QLearningAgent(alpha=0.1, gamma=0.9, epsilon=0.3)\n",
    "    \n",
    "    # Try to load a pre-trained agent\n",
    "    # try:\n",
    "    #     agent.load()\n",
    "    #     print(\"Loaded pre-trained agent.\")\n",
    "    # except:\n",
    "    print(\"Training a new agent...\")\n",
    "    train_agent(agent, env, num_episodes=200000)\n",
    "    agent.save()\n",
    "    \n",
    "    # Evaluate the agent\n",
    "    evaluate_agent(agent, env, num_episodes=100, render=True)\n",
    "    \n",
    "    # Play against the agent\n",
    "    play_against_agent(agent,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053de0b-1a18-47a9-bc22-eb1f069cf34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating supervised training data...\n",
      "Starting supervised pretraining...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import pickle\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class HangmanEnvironment:\n",
    "    def __init__(self, word_list=None):\n",
    "        if word_list is None:\n",
    "            # Default list of words\n",
    "            self.word_list = ['python', 'machine', 'learning', 'game', 'artificial', 'intelligence', 'algorithm']\n",
    "        else:\n",
    "            self.word_list = word_list\n",
    "        \n",
    "        self.max_attempts = 6\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the game environment.\"\"\"\n",
    "        self.word = random.choice(self.word_list).lower()\n",
    "        self.word_len = len(self.word)\n",
    "        self.revealed = ['_'] * self.word_len\n",
    "        self.guessed_letters = set()\n",
    "        self.attempts_left = self.max_attempts\n",
    "        self.game_over = False\n",
    "        \n",
    "        return self._get_state()\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Take an action (guess a letter) and return the new state, reward, and done flag.\n",
    "        \n",
    "        Args:\n",
    "            action: A letter from a-z\n",
    "            \n",
    "        Returns:\n",
    "            state: Current game state\n",
    "            reward: Reward for the action\n",
    "            done: Whether the game is over\n",
    "            info: Additional information\n",
    "        \"\"\"\n",
    "        if self.game_over:\n",
    "            return self._get_state(), 0, True, {}\n",
    "        \n",
    "        letter = action.lower()\n",
    "        \n",
    "        # Letter already guessed\n",
    "        if letter in self.guessed_letters:\n",
    "            return self._get_state(), -3, self.game_over, {}\n",
    "        \n",
    "        self.guessed_letters.add(letter)\n",
    "        \n",
    "        # Check if letter is in the word\n",
    "        if letter in self.word:\n",
    "            # Update revealed word\n",
    "            for i, char in enumerate(self.word):\n",
    "                if char == letter:\n",
    "                    self.revealed[i] = letter\n",
    "            \n",
    "            # Check if the word is fully revealed\n",
    "            if '_' not in self.revealed:\n",
    "                self.game_over = True\n",
    "                return self._get_state(), 10, True, {'won': True}\n",
    "            \n",
    "            # Reward for correct guess depends on frequency of the letter\n",
    "            letter_count = self.word.count(letter)\n",
    "            return self._get_state(), letter_count * 2, False, {}\n",
    "        else:\n",
    "            # Incorrect guess\n",
    "            self.attempts_left -= 1\n",
    "            \n",
    "            if self.attempts_left == 0:\n",
    "                self.game_over = True\n",
    "                return self._get_state(), -5, True, {'won': False}\n",
    "            \n",
    "            return self._get_state(), -1, False, {}\n",
    "    \n",
    "    def _get_state(self):\n",
    "        \"\"\"Return the current state representation.\"\"\"\n",
    "        return (\n",
    "            ''.join(self.revealed),\n",
    "            ''.join(sorted(self.guessed_letters)),\n",
    "            self.attempts_left\n",
    "        )\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Display the current game state.\"\"\"\n",
    "        print(f\"Word: {' '.join(self.revealed)}\")\n",
    "        print(f\"Guessed letters: {', '.join(sorted(self.guessed_letters))}\")\n",
    "        print(f\"Attempts left: {self.attempts_left}\")\n",
    "        if self.game_over:\n",
    "            if '_' not in self.revealed:\n",
    "                print(\"You won!\")\n",
    "            else:\n",
    "                print(f\"You lost! The word was: {self.word}\")\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.q_table = defaultdict(lambda: np.zeros(26))  # Maps state to Q values for each action\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.letters = string.ascii_lowercase\n",
    "        \n",
    "    def get_action(self, state, guessed_letters):\n",
    "        \"\"\"\n",
    "        Choose an action based on epsilon-greedy policy.\n",
    "        \n",
    "        Args:\n",
    "            state: Current state\n",
    "            guessed_letters: Set of already guessed letters\n",
    "            \n",
    "        Returns:\n",
    "            Chosen letter\n",
    "        \"\"\"\n",
    "        available_letters = [l for l in self.letters if l not in guessed_letters]\n",
    "        \n",
    "        if not available_letters:\n",
    "            return None\n",
    "        \n",
    "        if random.random() < self.epsilon:\n",
    "            # Exploration: choose randomly\n",
    "            return random.choice(available_letters)\n",
    "        else:\n",
    "            # Exploitation: choose best action\n",
    "            q_values = self.q_table[state]\n",
    "            \n",
    "            # Filter out already guessed letters\n",
    "            valid_q = [(l, q_values[ord(l) - ord('a')]) for l in available_letters]\n",
    "            \n",
    "            # Choose the letter with the highest Q-value\n",
    "            return max(valid_q, key=lambda x: x[1])[0]\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Update Q-values based on the Q-learning update rule.\n",
    "        \n",
    "        Args:\n",
    "            state: Current state\n",
    "            action: Taken action (letter)\n",
    "            reward: Received reward\n",
    "            next_state: Next state\n",
    "        \"\"\"\n",
    "        # Convert letter to index\n",
    "        action_idx = ord(action) - ord('a')\n",
    "        \n",
    "        # Current Q-value\n",
    "        old_value = self.q_table[state][action_idx]\n",
    "        \n",
    "        # Maximum Q-value for next state\n",
    "        next_max = np.max(self.q_table[next_state])\n",
    "        \n",
    "        # Update Q-value\n",
    "        new_value = old_value + self.alpha * (reward + self.gamma * next_max - old_value)\n",
    "        self.q_table[state][action_idx] = new_value\n",
    "    \n",
    "    def save(self, filename=\"hangman_agent.pkl\"):\n",
    "        \"\"\"Save the Q-table to a file.\"\"\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(dict(self.q_table), f)\n",
    "    \n",
    "    def load(self, filename=\"hangman_agent.pkl\"):\n",
    "        \"\"\"Load the Q-table from a file.\"\"\"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.q_table = defaultdict(lambda: np.zeros(26), pickle.load(f))\n",
    "\n",
    "\n",
    "def train_agent(agent, env, num_episodes=10000):\n",
    "    \"\"\"Train the agent for the given number of episodes.\"\"\"\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # Get guessed letters from state\n",
    "            guessed_letters = state[1]\n",
    "            \n",
    "            # Choose an action\n",
    "            action = agent.get_action(state, guessed_letters)\n",
    "            \n",
    "            # Take the action\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # Update Q-values\n",
    "            agent.update(state, action, reward, next_state)\n",
    "            \n",
    "            state = next_state\n",
    "        \n",
    "        # Decay epsilon over time for more exploitation later\n",
    "        if episode % 1000 == 0 and agent.epsilon > 0.01:\n",
    "            agent.epsilon *= 0.95\n",
    "            print(f\"Episode {episode}, Epsilon: {agent.epsilon:.3f}\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "\n",
    "def evaluate_agent(agent, env, num_episodes=100, render=False):\n",
    "    \"\"\"Evaluate the agent's performance.\"\"\"\n",
    "    wins = 0\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        if render and episode < 5:  # Only render a few episodes\n",
    "            print(f\"\\nEpisode {episode + 1}\")\n",
    "            env.render()\n",
    "        \n",
    "        while not done:\n",
    "            # Choose the best action (no exploration)\n",
    "            guessed_letters = state[1]\n",
    "            old_epsilon = agent.epsilon\n",
    "            agent.epsilon = 0  # No exploration during evaluation\n",
    "            action = agent.get_action(state, guessed_letters)\n",
    "            agent.epsilon = old_epsilon\n",
    "            \n",
    "            # Take the action\n",
    "            state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if render and episode < 5:\n",
    "                print(f\"\\nGuessed: {action}\")\n",
    "                env.render()\n",
    "        \n",
    "        if '_' not in state[0]:  # Word fully revealed\n",
    "            wins += 1\n",
    "    \n",
    "    win_rate = wins / num_episodes\n",
    "    print(f\"Win rate: {win_rate:.2f} ({wins}/{num_episodes})\")\n",
    "    \n",
    "    return win_rate\n",
    "\n",
    "\n",
    "def play_against_agent(agent, word_list=None):\n",
    "    \"\"\"Let a human play against the trained agent.\"\"\"\n",
    "    env = HangmanEnvironment(word_list)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    print(\"Welcome to Hangman! The AI will guess letters.\")\n",
    "    print(\"Word:\", ' '.join(env.revealed))\n",
    "    \n",
    "    while not done:\n",
    "        # Agent's turn\n",
    "        guessed_letters = state[1]\n",
    "        print(\"\\nAgent is thinking...\")\n",
    "        \n",
    "        # Choose the best action\n",
    "        agent.epsilon = 0  # No exploration\n",
    "        action = agent.get_action(state, guessed_letters)\n",
    "        \n",
    "        print(f\"Agent guesses: {action}\")\n",
    "        \n",
    "        # Take the action\n",
    "        state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Display the state\n",
    "        env.render()\n",
    "    \n",
    "    if '_' not in state[0]:\n",
    "        print(\"The agent won!\")\n",
    "    else:\n",
    "        print(\"The agent lost!\")\n",
    "\n",
    "\n",
    "def generate_supervised_data(word_list, num_samples=10000):\n",
    "    \"\"\"Generate supervised training data from expert Hangman strategies.\"\"\"\n",
    "    data = []\n",
    "    env = HangmanEnvironment(word_list)\n",
    "    \n",
    "    # Common letter frequencies in English\n",
    "    letter_freq = {\n",
    "        'e': 0.1202, 't': 0.0910, 'a': 0.0812, 'o': 0.0768, 'i': 0.0731,\n",
    "        'n': 0.0695, 's': 0.0628, 'r': 0.0602, 'h': 0.0592, 'd': 0.0432,\n",
    "        'l': 0.0398, 'u': 0.0288, 'c': 0.0271, 'm': 0.0261, 'f': 0.0230,\n",
    "        'y': 0.0211, 'w': 0.0209, 'g': 0.0203, 'p': 0.0182, 'b': 0.0149,\n",
    "        'v': 0.0111, 'k': 0.0069, 'x': 0.0017, 'q': 0.0011, 'j': 0.0010, 'z': 0.0007\n",
    "    }\n",
    "    \n",
    "    # Common vowels to prioritize early\n",
    "    vowels = ['e', 'a', 'o', 'i', 'u']\n",
    "    \n",
    "    def expert_strategy(state, guessed_letters):\n",
    "        \"\"\"Simple expert strategy based on letter frequency and position.\"\"\"\n",
    "        revealed_word, _, attempts_left = state\n",
    "        \n",
    "        # If almost out of attempts, be more conservative\n",
    "        if attempts_left <= 2:\n",
    "            # Look for common patterns in partially revealed words\n",
    "            if '_' in revealed_word:\n",
    "                pattern = revealed_word.replace('_', '.')\n",
    "                # Logic to find most likely letter for the pattern\n",
    "                # This would be more sophisticated in a real implementation\n",
    "        \n",
    "        # First focus on vowels if not many are guessed yet\n",
    "        vowels_guessed = sum(1 for v in vowels if v in guessed_letters)\n",
    "        if vowels_guessed < 3:\n",
    "            for v in vowels:\n",
    "                if v not in guessed_letters:\n",
    "                    return v\n",
    "        \n",
    "        # Then choose based on letter frequency\n",
    "        available_letters = [l for l in string.ascii_lowercase if l not in guessed_letters]\n",
    "        return max(available_letters, key=lambda l: letter_freq.get(l, 0))\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            guessed_letters = state[1]\n",
    "            \n",
    "            # Get expert action\n",
    "            action = expert_strategy(state, guessed_letters)\n",
    "            \n",
    "            # Save state-action pair\n",
    "            state_str = str(state)\n",
    "            action_idx = ord(action) - ord('a')\n",
    "            data.append([state_str, action_idx])\n",
    "            \n",
    "            # Take action\n",
    "            state, _, done, _ = env.step(action)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data, columns=['state', 'action'])\n",
    "    return df\n",
    "\n",
    "def supervised_pretraining(agent, data):\n",
    "    \"\"\"Pretrain the agent using supervised learning data.\"\"\"\n",
    "    print(\"Starting supervised pretraining...\")\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    train_data, val_data = train_test_split(data, test_size=0.2)\n",
    "    \n",
    "    # Learning rate for supervised training\n",
    "    sup_alpha = 0.05\n",
    "    \n",
    "    for epoch in range(100000):  # Multiple epochs over the data\n",
    "        correct = 0\n",
    "        \n",
    "        for _, row in train_data.iterrows():\n",
    "            state_str = row['state']\n",
    "            state = eval(state_str)  # Convert string back to tuple\n",
    "            action_idx = row['action']\n",
    "            action = chr(action_idx + ord('a'))\n",
    "            \n",
    "            # Get current prediction\n",
    "            current_values = agent.q_table[state]\n",
    "            predicted_idx = np.argmax(current_values)\n",
    "            \n",
    "            if predicted_idx == action_idx:\n",
    "                correct += 1\n",
    "            \n",
    "            # Update Q-value towards the expert action\n",
    "            agent.q_table[state][action_idx] += sup_alpha * (1.0 - agent.q_table[state][action_idx])\n",
    "            \n",
    "            # Slightly decrease other actions\n",
    "            for i in range(26):\n",
    "                if i != action_idx:\n",
    "                    agent.q_table[state][i] -= sup_alpha * 0.1 * agent.q_table[state][i]\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_correct = 0\n",
    "        for _, row in val_data.iterrows():\n",
    "            state_str = row['state']\n",
    "            state = eval(state_str)\n",
    "            action_idx = row['action']\n",
    "            \n",
    "            current_values = agent.q_table[state]\n",
    "            predicted_idx = np.argmax(current_values)\n",
    "            \n",
    "            if predicted_idx == action_idx:\n",
    "                val_correct += 1\n",
    "        \n",
    "        train_acc = correct / len(train_data)\n",
    "        val_acc = val_correct / len(val_data)\n",
    "        # print(f\"Epoch {epoch+1}: Train accuracy: {train_acc:.3f}, Validation accuracy: {val_acc:.3f}\")\n",
    "    \n",
    "    print(\"Supervised pretraining completed.\")\n",
    "    return agent\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create environment with a larger word list\n",
    "    sample_words = ['python', 'machine', 'learning', 'game', 'artificial', \n",
    "                   'intelligence', 'algorithm', 'neural', 'network', 'data',\n",
    "                   'science', 'computer', 'vision', 'natural', 'language',\n",
    "                   'reinforcement', 'supervised', 'unsupervised', 'model',\n",
    "                   'train', 'test', 'validation', 'accuracy', 'precision']\n",
    "\n",
    "    with open(\"words_250000_train.txt\", 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        words = [line.strip().lower() for line in f if line.strip() and all(c in string.ascii_lowercase for c in line.strip().lower())]\n",
    "    \n",
    "    env = HangmanEnvironment(words)\n",
    "    \n",
    "    # Create the agent\n",
    "    agent = QLearningAgent(alpha=0.1, gamma=0.9, epsilon=0.3)\n",
    "    \n",
    "    # Try to load a pre-trained agent\n",
    "    # try:\n",
    "    #     agent.load()\n",
    "    #     print(\"Loaded pre-trained agent.\")\n",
    "    # except:\n",
    "    #     print(\"No pre-trained agent found. Starting from scratch.\")\n",
    "        \n",
    "        # Generate supervised training data\n",
    "    print(\"Generating supervised training data...\")\n",
    "    supervised_data = generate_supervised_data(words)\n",
    "        \n",
    "        # Perform supervised pretraining\n",
    "    agent = supervised_pretraining(agent, supervised_data)\n",
    "        \n",
    "        # Continue with reinforcement learning\n",
    "    print(\"Starting reinforcement learning training...\")\n",
    "    train_agent(agent, env, num_episodes=10000)  # Can use fewer episodes thanks to pretraining\n",
    "        \n",
    "        # Save the trained agent\n",
    "    agent.save()\n",
    "    \n",
    "    # Evaluate the agent\n",
    "    evaluate_agent(agent, env, num_episodes=100, render=True)\n",
    "    \n",
    "    # Play against the agent\n",
    "    play_against_agent(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b26b8e-c8f2-4afe-b006-300dd0df8a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a31382-2cf5-4f28-b536-75e3b1b57799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
